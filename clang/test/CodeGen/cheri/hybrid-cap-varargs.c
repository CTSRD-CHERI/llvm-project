// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature
// RUN: %cheri_cc1 -o - -emit-llvm %s | FileCheck %s --check-prefixes=MIPS
// RUN: %riscv32_cheri_cc1 -o - -emit-llvm %s | FileCheck %s --check-prefixes=RV32IXCHERI
// RUN: %riscv64_cheri_cc1 -o - -emit-llvm %s | FileCheck %s --check-prefixes=RV64IXCHERI

// All of these types contain capabilities and thus should be passed indirectly
// for hybrid varargs.

struct single_cap {
  void * __capability cap;
};

struct double_cap {
  void * __capability cap1;
  void * __capability cap2;
};

struct single_cap_array {
  void * __capability cap[1];
};

struct double_cap_array {
  void * __capability cap[2];
};

struct mixed {
  int i;
  void * __capability cap;
};

union int_or_cap {
  int i;
  void * __capability cap;
};

extern void callee(long sel, ...);

extern void * __capability cap;
extern void * __capability uintcap;
extern struct single_cap single_cap;
extern struct double_cap double_cap;
extern struct single_cap_array single_cap_array;
extern struct double_cap_array double_cap_array;
extern struct mixed mixed;
extern union int_or_cap int_or_cap;

// MIPS-LABEL: define {{[^@]+}}@caller() #0
// MIPS-NEXT:  entry:
// MIPS-NEXT:    [[NULL_CAP:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    [[NULL_UINTCAP:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    [[INDIRECT_ARG_TEMP:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    [[INDIRECT_ARG_TEMP1:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    [[INDIRECT_ARG_TEMP2:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    [[INDIRECT_ARG_TEMP3:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    store i8 addrspace(200)* null, i8 addrspace(200)** [[NULL_CAP]], align 16
// MIPS-NEXT:    store i8 addrspace(200)* null, i8 addrspace(200)** [[NULL_UINTCAP]], align 16
// MIPS-NEXT:    [[TMP0:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[NULL_CAP]], align 16
// MIPS-NEXT:    [[TMP1:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[NULL_UINTCAP]], align 16
// MIPS-NEXT:    [[TMP2:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** @cap, align 16
// MIPS-NEXT:    [[TMP3:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** @uintcap, align 16
// MIPS-NEXT:    store i8 addrspace(200)* [[TMP0]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP]], align 16
// MIPS-NEXT:    store i8 addrspace(200)* [[TMP1]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP1]], align 16
// MIPS-NEXT:    store i8 addrspace(200)* [[TMP2]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP2]], align 16
// MIPS-NEXT:    store i8 addrspace(200)* [[TMP3]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP3]], align 16
// MIPS-NEXT:    call void (i64, ...) @callee(i64 signext 0, i8 addrspace(200)** byval(i8 addrspace(200)*) align 16 [[INDIRECT_ARG_TEMP]], i8 addrspace(200)** byval(i8 addrspace(200)*) align 16 [[INDIRECT_ARG_TEMP1]], i8 addrspace(200)** byval(i8 addrspace(200)*) align 16 [[INDIRECT_ARG_TEMP2]], i8 addrspace(200)** byval(i8 addrspace(200)*) align 16 [[INDIRECT_ARG_TEMP3]])
// MIPS-NEXT:    call void (i64, ...) @callee(i64 signext 1, %struct.single_cap* byval(%struct.single_cap) align 16 @single_cap)
// MIPS-NEXT:    call void (i64, ...) @callee(i64 signext 2, %struct.double_cap* byval(%struct.double_cap) align 16 @double_cap)
// MIPS-NEXT:    call void (i64, ...) @callee(i64 signext 3, %struct.single_cap_array* byval(%struct.single_cap_array) align 16 @single_cap_array)
// MIPS-NEXT:    call void (i64, ...) @callee(i64 signext 4, %struct.double_cap_array* byval(%struct.double_cap_array) align 16 @double_cap_array)
// MIPS-NEXT:    call void (i64, ...) @callee(i64 signext 5, %struct.mixed* byval(%struct.mixed) align 16 @mixed)
// MIPS-NEXT:    call void (i64, ...) @callee(i64 signext 6, %union.int_or_cap* byval(%union.int_or_cap) align 16 @int_or_cap)
// MIPS-NEXT:    ret void
//
// RV32IXCHERI-LABEL: define {{[^@]+}}@caller() #0
// RV32IXCHERI-NEXT:  entry:
// RV32IXCHERI-NEXT:    [[NULL_CAP:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[NULL_UINTCAP:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[INDIRECT_ARG_TEMP:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[INDIRECT_ARG_TEMP1:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[INDIRECT_ARG_TEMP2:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[INDIRECT_ARG_TEMP3:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[BYVAL_TEMP:%.*]] = alloca [[STRUCT_SINGLE_CAP:%.*]], align 8
// RV32IXCHERI-NEXT:    [[BYVAL_TEMP4:%.*]] = alloca [[STRUCT_DOUBLE_CAP:%.*]], align 8
// RV32IXCHERI-NEXT:    [[BYVAL_TEMP5:%.*]] = alloca [[STRUCT_SINGLE_CAP_ARRAY:%.*]], align 8
// RV32IXCHERI-NEXT:    [[BYVAL_TEMP6:%.*]] = alloca [[STRUCT_DOUBLE_CAP_ARRAY:%.*]], align 8
// RV32IXCHERI-NEXT:    [[BYVAL_TEMP7:%.*]] = alloca [[STRUCT_MIXED:%.*]], align 8
// RV32IXCHERI-NEXT:    [[BYVAL_TEMP8:%.*]] = alloca [[UNION_INT_OR_CAP:%.*]], align 8
// RV32IXCHERI-NEXT:    store i8 addrspace(200)* null, i8 addrspace(200)** [[NULL_CAP]], align 8
// RV32IXCHERI-NEXT:    store i8 addrspace(200)* null, i8 addrspace(200)** [[NULL_UINTCAP]], align 8
// RV32IXCHERI-NEXT:    [[TMP0:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[NULL_CAP]], align 8
// RV32IXCHERI-NEXT:    [[TMP1:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[NULL_UINTCAP]], align 8
// RV32IXCHERI-NEXT:    [[TMP2:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** @cap, align 8
// RV32IXCHERI-NEXT:    [[TMP3:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** @uintcap, align 8
// RV32IXCHERI-NEXT:    store i8 addrspace(200)* [[TMP0]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP]], align 8
// RV32IXCHERI-NEXT:    store i8 addrspace(200)* [[TMP1]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP1]], align 8
// RV32IXCHERI-NEXT:    store i8 addrspace(200)* [[TMP2]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP2]], align 8
// RV32IXCHERI-NEXT:    store i8 addrspace(200)* [[TMP3]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP3]], align 8
// RV32IXCHERI-NEXT:    call void (i32, ...) @callee(i32 0, i8 addrspace(200)** [[INDIRECT_ARG_TEMP]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP1]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP2]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP3]])
// RV32IXCHERI-NEXT:    [[TMP4:%.*]] = bitcast %struct.single_cap* [[BYVAL_TEMP]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP4]], i8* align 8 bitcast (%struct.single_cap* @single_cap to i8*), i32 8, i1 false)
// RV32IXCHERI-NEXT:    call void (i32, ...) @callee(i32 1, %struct.single_cap* [[BYVAL_TEMP]])
// RV32IXCHERI-NEXT:    [[TMP5:%.*]] = bitcast %struct.double_cap* [[BYVAL_TEMP4]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP5]], i8* align 8 bitcast (%struct.double_cap* @double_cap to i8*), i32 16, i1 false)
// RV32IXCHERI-NEXT:    call void (i32, ...) @callee(i32 2, %struct.double_cap* [[BYVAL_TEMP4]])
// RV32IXCHERI-NEXT:    [[TMP6:%.*]] = bitcast %struct.single_cap_array* [[BYVAL_TEMP5]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP6]], i8* align 8 bitcast (%struct.single_cap_array* @single_cap_array to i8*), i32 8, i1 false)
// RV32IXCHERI-NEXT:    call void (i32, ...) @callee(i32 3, %struct.single_cap_array* [[BYVAL_TEMP5]])
// RV32IXCHERI-NEXT:    [[TMP7:%.*]] = bitcast %struct.double_cap_array* [[BYVAL_TEMP6]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP7]], i8* align 8 bitcast (%struct.double_cap_array* @double_cap_array to i8*), i32 16, i1 false)
// RV32IXCHERI-NEXT:    call void (i32, ...) @callee(i32 4, %struct.double_cap_array* [[BYVAL_TEMP6]])
// RV32IXCHERI-NEXT:    [[TMP8:%.*]] = bitcast %struct.mixed* [[BYVAL_TEMP7]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP8]], i8* align 8 bitcast (%struct.mixed* @mixed to i8*), i32 16, i1 false)
// RV32IXCHERI-NEXT:    call void (i32, ...) @callee(i32 5, %struct.mixed* [[BYVAL_TEMP7]])
// RV32IXCHERI-NEXT:    [[TMP9:%.*]] = bitcast %union.int_or_cap* [[BYVAL_TEMP8]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP9]], i8* align 8 bitcast (%union.int_or_cap* @int_or_cap to i8*), i32 8, i1 false)
// RV32IXCHERI-NEXT:    call void (i32, ...) @callee(i32 6, %union.int_or_cap* [[BYVAL_TEMP8]])
// RV32IXCHERI-NEXT:    ret void
//
// RV64IXCHERI-LABEL: define {{[^@]+}}@caller() #0
// RV64IXCHERI-NEXT:  entry:
// RV64IXCHERI-NEXT:    [[NULL_CAP:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[NULL_UINTCAP:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[INDIRECT_ARG_TEMP:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[INDIRECT_ARG_TEMP1:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[INDIRECT_ARG_TEMP2:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[INDIRECT_ARG_TEMP3:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[BYVAL_TEMP:%.*]] = alloca [[STRUCT_SINGLE_CAP:%.*]], align 16
// RV64IXCHERI-NEXT:    [[BYVAL_TEMP4:%.*]] = alloca [[STRUCT_DOUBLE_CAP:%.*]], align 16
// RV64IXCHERI-NEXT:    [[BYVAL_TEMP5:%.*]] = alloca [[STRUCT_SINGLE_CAP_ARRAY:%.*]], align 16
// RV64IXCHERI-NEXT:    [[BYVAL_TEMP6:%.*]] = alloca [[STRUCT_DOUBLE_CAP_ARRAY:%.*]], align 16
// RV64IXCHERI-NEXT:    [[BYVAL_TEMP7:%.*]] = alloca [[STRUCT_MIXED:%.*]], align 16
// RV64IXCHERI-NEXT:    [[BYVAL_TEMP8:%.*]] = alloca [[UNION_INT_OR_CAP:%.*]], align 16
// RV64IXCHERI-NEXT:    store i8 addrspace(200)* null, i8 addrspace(200)** [[NULL_CAP]], align 16
// RV64IXCHERI-NEXT:    store i8 addrspace(200)* null, i8 addrspace(200)** [[NULL_UINTCAP]], align 16
// RV64IXCHERI-NEXT:    [[TMP0:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[NULL_CAP]], align 16
// RV64IXCHERI-NEXT:    [[TMP1:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[NULL_UINTCAP]], align 16
// RV64IXCHERI-NEXT:    [[TMP2:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** @cap, align 16
// RV64IXCHERI-NEXT:    [[TMP3:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** @uintcap, align 16
// RV64IXCHERI-NEXT:    store i8 addrspace(200)* [[TMP0]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP]], align 16
// RV64IXCHERI-NEXT:    store i8 addrspace(200)* [[TMP1]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP1]], align 16
// RV64IXCHERI-NEXT:    store i8 addrspace(200)* [[TMP2]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP2]], align 16
// RV64IXCHERI-NEXT:    store i8 addrspace(200)* [[TMP3]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP3]], align 16
// RV64IXCHERI-NEXT:    call void (i64, ...) @callee(i64 0, i8 addrspace(200)** [[INDIRECT_ARG_TEMP]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP1]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP2]], i8 addrspace(200)** [[INDIRECT_ARG_TEMP3]])
// RV64IXCHERI-NEXT:    [[TMP4:%.*]] = bitcast %struct.single_cap* [[BYVAL_TEMP]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP4]], i8* align 16 bitcast (%struct.single_cap* @single_cap to i8*), i64 16, i1 false)
// RV64IXCHERI-NEXT:    call void (i64, ...) @callee(i64 1, %struct.single_cap* [[BYVAL_TEMP]])
// RV64IXCHERI-NEXT:    [[TMP5:%.*]] = bitcast %struct.double_cap* [[BYVAL_TEMP4]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP5]], i8* align 16 bitcast (%struct.double_cap* @double_cap to i8*), i64 32, i1 false)
// RV64IXCHERI-NEXT:    call void (i64, ...) @callee(i64 2, %struct.double_cap* [[BYVAL_TEMP4]])
// RV64IXCHERI-NEXT:    [[TMP6:%.*]] = bitcast %struct.single_cap_array* [[BYVAL_TEMP5]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP6]], i8* align 16 bitcast (%struct.single_cap_array* @single_cap_array to i8*), i64 16, i1 false)
// RV64IXCHERI-NEXT:    call void (i64, ...) @callee(i64 3, %struct.single_cap_array* [[BYVAL_TEMP5]])
// RV64IXCHERI-NEXT:    [[TMP7:%.*]] = bitcast %struct.double_cap_array* [[BYVAL_TEMP6]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP7]], i8* align 16 bitcast (%struct.double_cap_array* @double_cap_array to i8*), i64 32, i1 false)
// RV64IXCHERI-NEXT:    call void (i64, ...) @callee(i64 4, %struct.double_cap_array* [[BYVAL_TEMP6]])
// RV64IXCHERI-NEXT:    [[TMP8:%.*]] = bitcast %struct.mixed* [[BYVAL_TEMP7]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP8]], i8* align 16 bitcast (%struct.mixed* @mixed to i8*), i64 32, i1 false)
// RV64IXCHERI-NEXT:    call void (i64, ...) @callee(i64 5, %struct.mixed* [[BYVAL_TEMP7]])
// RV64IXCHERI-NEXT:    [[TMP9:%.*]] = bitcast %union.int_or_cap* [[BYVAL_TEMP8]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP9]], i8* align 16 bitcast (%union.int_or_cap* @int_or_cap to i8*), i64 16, i1 false)
// RV64IXCHERI-NEXT:    call void (i64, ...) @callee(i64 6, %union.int_or_cap* [[BYVAL_TEMP8]])
// RV64IXCHERI-NEXT:    ret void
//
void caller(void) {
  void * __capability null_cap = (void * __capability)0;
  __uintcap_t null_uintcap = 0;

  callee(0, null_cap, null_uintcap, cap, uintcap);
  callee(1, single_cap);
  callee(2, double_cap);
  callee(3, single_cap_array);
  callee(4, double_cap_array);
  callee(5, mixed);
  callee(6, int_or_cap);
}

// MIPS-LABEL: define {{[^@]+}}@callee
// MIPS-SAME: (i64 signext [[SEL:%.*]], ...) #0
// MIPS-NEXT:  entry:
// MIPS-NEXT:    [[SEL_ADDR:%.*]] = alloca i64, align 8
// MIPS-NEXT:    [[NULL_CAP:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    [[NULL_UINTCAP:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    [[CAP:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    [[UINTCAP:%.*]] = alloca i8 addrspace(200)*, align 16
// MIPS-NEXT:    [[SINGLE_CAP:%.*]] = alloca [[STRUCT_SINGLE_CAP:%.*]], align 16
// MIPS-NEXT:    [[DOUBLE_CAP:%.*]] = alloca [[STRUCT_DOUBLE_CAP:%.*]], align 16
// MIPS-NEXT:    [[SINGLE_CAP_ARRAY:%.*]] = alloca [[STRUCT_SINGLE_CAP_ARRAY:%.*]], align 16
// MIPS-NEXT:    [[DOUBLE_CAP_ARRAY:%.*]] = alloca [[STRUCT_DOUBLE_CAP_ARRAY:%.*]], align 16
// MIPS-NEXT:    [[MIXED:%.*]] = alloca [[STRUCT_MIXED:%.*]], align 16
// MIPS-NEXT:    [[INT_OR_CAP:%.*]] = alloca [[UNION_INT_OR_CAP:%.*]], align 16
// MIPS-NEXT:    [[AP:%.*]] = alloca i8*, align 8
// MIPS-NEXT:    store i64 [[SEL]], i64* [[SEL_ADDR]], align 8
// MIPS-NEXT:    [[AP1:%.*]] = bitcast i8** [[AP]] to i8*
// MIPS-NEXT:    call void @llvm.va_start.p0i8(i8* [[AP1]])
// MIPS-NEXT:    [[TMP0:%.*]] = load i64, i64* [[SEL_ADDR]], align 8
// MIPS-NEXT:    switch i64 [[TMP0]], label [[SW_EPILOG:%.*]] [
// MIPS-NEXT:    i64 0, label [[SW_BB:%.*]]
// MIPS-NEXT:    i64 1, label [[SW_BB8:%.*]]
// MIPS-NEXT:    i64 2, label [[SW_BB11:%.*]]
// MIPS-NEXT:    i64 3, label [[SW_BB14:%.*]]
// MIPS-NEXT:    i64 4, label [[SW_BB17:%.*]]
// MIPS-NEXT:    i64 5, label [[SW_BB20:%.*]]
// MIPS-NEXT:    i64 6, label [[SW_BB23:%.*]]
// MIPS-NEXT:    ]
// MIPS:       sw.bb:
// MIPS-NEXT:    [[ARGP_CUR:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP1:%.*]] = bitcast i8* [[ARGP_CUR]] to i8 addrspace(200)***
// MIPS-NEXT:    [[TMP2:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP1]], align 8
// MIPS-NEXT:    [[TMP3:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP2]], align 16
// MIPS-NEXT:    store volatile i8 addrspace(200)* [[TMP3]], i8 addrspace(200)** [[NULL_CAP]], align 16
// MIPS-NEXT:    [[ARGP_CUR2:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT3:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR2]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT3]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP4:%.*]] = bitcast i8* [[ARGP_CUR2]] to i8 addrspace(200)***
// MIPS-NEXT:    [[TMP5:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP4]], align 8
// MIPS-NEXT:    [[TMP6:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP5]], align 16
// MIPS-NEXT:    store volatile i8 addrspace(200)* [[TMP6]], i8 addrspace(200)** [[NULL_UINTCAP]], align 16
// MIPS-NEXT:    [[ARGP_CUR4:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT5:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR4]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT5]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP7:%.*]] = bitcast i8* [[ARGP_CUR4]] to i8 addrspace(200)***
// MIPS-NEXT:    [[TMP8:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP7]], align 8
// MIPS-NEXT:    [[TMP9:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP8]], align 16
// MIPS-NEXT:    store volatile i8 addrspace(200)* [[TMP9]], i8 addrspace(200)** [[CAP]], align 16
// MIPS-NEXT:    [[ARGP_CUR6:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT7:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR6]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT7]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP10:%.*]] = bitcast i8* [[ARGP_CUR6]] to i8 addrspace(200)***
// MIPS-NEXT:    [[TMP11:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP10]], align 8
// MIPS-NEXT:    [[TMP12:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP11]], align 16
// MIPS-NEXT:    store volatile i8 addrspace(200)* [[TMP12]], i8 addrspace(200)** [[UINTCAP]], align 16
// MIPS-NEXT:    br label [[SW_EPILOG]]
// MIPS:       sw.bb8:
// MIPS-NEXT:    [[ARGP_CUR9:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT10:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR9]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT10]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP13:%.*]] = bitcast i8* [[ARGP_CUR9]] to %struct.single_cap**
// MIPS-NEXT:    [[TMP14:%.*]] = load %struct.single_cap*, %struct.single_cap** [[TMP13]], align 8
// MIPS-NEXT:    [[TMP15:%.*]] = bitcast %struct.single_cap* [[SINGLE_CAP]] to i8*
// MIPS-NEXT:    [[TMP16:%.*]] = bitcast %struct.single_cap* [[TMP14]] to i8*
// MIPS-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP15]], i8* align 16 [[TMP16]], i64 16, i1 true)
// MIPS-NEXT:    br label [[SW_EPILOG]]
// MIPS:       sw.bb11:
// MIPS-NEXT:    [[ARGP_CUR12:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT13:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR12]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT13]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP17:%.*]] = bitcast i8* [[ARGP_CUR12]] to %struct.double_cap**
// MIPS-NEXT:    [[TMP18:%.*]] = load %struct.double_cap*, %struct.double_cap** [[TMP17]], align 8
// MIPS-NEXT:    [[TMP19:%.*]] = bitcast %struct.double_cap* [[DOUBLE_CAP]] to i8*
// MIPS-NEXT:    [[TMP20:%.*]] = bitcast %struct.double_cap* [[TMP18]] to i8*
// MIPS-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP19]], i8* align 16 [[TMP20]], i64 32, i1 true)
// MIPS-NEXT:    br label [[SW_EPILOG]]
// MIPS:       sw.bb14:
// MIPS-NEXT:    [[ARGP_CUR15:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT16:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR15]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT16]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP21:%.*]] = bitcast i8* [[ARGP_CUR15]] to %struct.single_cap_array**
// MIPS-NEXT:    [[TMP22:%.*]] = load %struct.single_cap_array*, %struct.single_cap_array** [[TMP21]], align 8
// MIPS-NEXT:    [[TMP23:%.*]] = bitcast %struct.single_cap_array* [[SINGLE_CAP_ARRAY]] to i8*
// MIPS-NEXT:    [[TMP24:%.*]] = bitcast %struct.single_cap_array* [[TMP22]] to i8*
// MIPS-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP23]], i8* align 16 [[TMP24]], i64 16, i1 true)
// MIPS-NEXT:    br label [[SW_EPILOG]]
// MIPS:       sw.bb17:
// MIPS-NEXT:    [[ARGP_CUR18:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT19:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR18]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT19]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP25:%.*]] = bitcast i8* [[ARGP_CUR18]] to %struct.double_cap_array**
// MIPS-NEXT:    [[TMP26:%.*]] = load %struct.double_cap_array*, %struct.double_cap_array** [[TMP25]], align 8
// MIPS-NEXT:    [[TMP27:%.*]] = bitcast %struct.double_cap_array* [[DOUBLE_CAP_ARRAY]] to i8*
// MIPS-NEXT:    [[TMP28:%.*]] = bitcast %struct.double_cap_array* [[TMP26]] to i8*
// MIPS-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP27]], i8* align 16 [[TMP28]], i64 32, i1 true)
// MIPS-NEXT:    br label [[SW_EPILOG]]
// MIPS:       sw.bb20:
// MIPS-NEXT:    [[ARGP_CUR21:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT22:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR21]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT22]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP29:%.*]] = bitcast i8* [[ARGP_CUR21]] to %struct.mixed**
// MIPS-NEXT:    [[TMP30:%.*]] = load %struct.mixed*, %struct.mixed** [[TMP29]], align 8
// MIPS-NEXT:    [[TMP31:%.*]] = bitcast %struct.mixed* [[MIXED]] to i8*
// MIPS-NEXT:    [[TMP32:%.*]] = bitcast %struct.mixed* [[TMP30]] to i8*
// MIPS-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP31]], i8* align 16 [[TMP32]], i64 32, i1 true)
// MIPS-NEXT:    br label [[SW_EPILOG]]
// MIPS:       sw.bb23:
// MIPS-NEXT:    [[ARGP_CUR24:%.*]] = load i8*, i8** [[AP]], align 8
// MIPS-NEXT:    [[ARGP_NEXT25:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR24]], i64 8
// MIPS-NEXT:    store i8* [[ARGP_NEXT25]], i8** [[AP]], align 8
// MIPS-NEXT:    [[TMP33:%.*]] = bitcast i8* [[ARGP_CUR24]] to %union.int_or_cap**
// MIPS-NEXT:    [[TMP34:%.*]] = load %union.int_or_cap*, %union.int_or_cap** [[TMP33]], align 8
// MIPS-NEXT:    [[TMP35:%.*]] = bitcast %union.int_or_cap* [[INT_OR_CAP]] to i8*
// MIPS-NEXT:    [[TMP36:%.*]] = bitcast %union.int_or_cap* [[TMP34]] to i8*
// MIPS-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP35]], i8* align 16 [[TMP36]], i64 16, i1 true)
// MIPS-NEXT:    br label [[SW_EPILOG]]
// MIPS:       sw.epilog:
// MIPS-NEXT:    [[AP26:%.*]] = bitcast i8** [[AP]] to i8*
// MIPS-NEXT:    call void @llvm.va_end.p0i8(i8* [[AP26]])
// MIPS-NEXT:    ret void
//
// RV32IXCHERI-LABEL: define {{[^@]+}}@callee
// RV32IXCHERI-SAME: (i32 [[SEL:%.*]], ...) #0
// RV32IXCHERI-NEXT:  entry:
// RV32IXCHERI-NEXT:    [[SEL_ADDR:%.*]] = alloca i32, align 4
// RV32IXCHERI-NEXT:    [[NULL_CAP:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[NULL_UINTCAP:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[CAP:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[UINTCAP:%.*]] = alloca i8 addrspace(200)*, align 8
// RV32IXCHERI-NEXT:    [[SINGLE_CAP:%.*]] = alloca [[STRUCT_SINGLE_CAP:%.*]], align 8
// RV32IXCHERI-NEXT:    [[DOUBLE_CAP:%.*]] = alloca [[STRUCT_DOUBLE_CAP:%.*]], align 8
// RV32IXCHERI-NEXT:    [[SINGLE_CAP_ARRAY:%.*]] = alloca [[STRUCT_SINGLE_CAP_ARRAY:%.*]], align 8
// RV32IXCHERI-NEXT:    [[DOUBLE_CAP_ARRAY:%.*]] = alloca [[STRUCT_DOUBLE_CAP_ARRAY:%.*]], align 8
// RV32IXCHERI-NEXT:    [[MIXED:%.*]] = alloca [[STRUCT_MIXED:%.*]], align 8
// RV32IXCHERI-NEXT:    [[INT_OR_CAP:%.*]] = alloca [[UNION_INT_OR_CAP:%.*]], align 8
// RV32IXCHERI-NEXT:    [[AP:%.*]] = alloca i8*, align 4
// RV32IXCHERI-NEXT:    store i32 [[SEL]], i32* [[SEL_ADDR]], align 4
// RV32IXCHERI-NEXT:    [[AP1:%.*]] = bitcast i8** [[AP]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.va_start.p0i8(i8* [[AP1]])
// RV32IXCHERI-NEXT:    [[TMP0:%.*]] = load i32, i32* [[SEL_ADDR]], align 4
// RV32IXCHERI-NEXT:    switch i32 [[TMP0]], label [[SW_EPILOG:%.*]] [
// RV32IXCHERI-NEXT:    i32 0, label [[SW_BB:%.*]]
// RV32IXCHERI-NEXT:    i32 1, label [[SW_BB8:%.*]]
// RV32IXCHERI-NEXT:    i32 2, label [[SW_BB11:%.*]]
// RV32IXCHERI-NEXT:    i32 3, label [[SW_BB14:%.*]]
// RV32IXCHERI-NEXT:    i32 4, label [[SW_BB17:%.*]]
// RV32IXCHERI-NEXT:    i32 5, label [[SW_BB20:%.*]]
// RV32IXCHERI-NEXT:    i32 6, label [[SW_BB23:%.*]]
// RV32IXCHERI-NEXT:    ]
// RV32IXCHERI:       sw.bb:
// RV32IXCHERI-NEXT:    [[ARGP_CUR:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP1:%.*]] = bitcast i8* [[ARGP_CUR]] to i8 addrspace(200)***
// RV32IXCHERI-NEXT:    [[TMP2:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP1]], align 4
// RV32IXCHERI-NEXT:    [[TMP3:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP2]], align 8
// RV32IXCHERI-NEXT:    store volatile i8 addrspace(200)* [[TMP3]], i8 addrspace(200)** [[NULL_CAP]], align 8
// RV32IXCHERI-NEXT:    [[ARGP_CUR2:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT3:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR2]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT3]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP4:%.*]] = bitcast i8* [[ARGP_CUR2]] to i8 addrspace(200)***
// RV32IXCHERI-NEXT:    [[TMP5:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP4]], align 4
// RV32IXCHERI-NEXT:    [[TMP6:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP5]], align 8
// RV32IXCHERI-NEXT:    store volatile i8 addrspace(200)* [[TMP6]], i8 addrspace(200)** [[NULL_UINTCAP]], align 8
// RV32IXCHERI-NEXT:    [[ARGP_CUR4:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT5:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR4]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT5]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP7:%.*]] = bitcast i8* [[ARGP_CUR4]] to i8 addrspace(200)***
// RV32IXCHERI-NEXT:    [[TMP8:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP7]], align 4
// RV32IXCHERI-NEXT:    [[TMP9:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP8]], align 8
// RV32IXCHERI-NEXT:    store volatile i8 addrspace(200)* [[TMP9]], i8 addrspace(200)** [[CAP]], align 8
// RV32IXCHERI-NEXT:    [[ARGP_CUR6:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT7:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR6]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT7]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP10:%.*]] = bitcast i8* [[ARGP_CUR6]] to i8 addrspace(200)***
// RV32IXCHERI-NEXT:    [[TMP11:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP10]], align 4
// RV32IXCHERI-NEXT:    [[TMP12:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP11]], align 8
// RV32IXCHERI-NEXT:    store volatile i8 addrspace(200)* [[TMP12]], i8 addrspace(200)** [[UINTCAP]], align 8
// RV32IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV32IXCHERI:       sw.bb8:
// RV32IXCHERI-NEXT:    [[ARGP_CUR9:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT10:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR9]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT10]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP13:%.*]] = bitcast i8* [[ARGP_CUR9]] to %struct.single_cap**
// RV32IXCHERI-NEXT:    [[TMP14:%.*]] = load %struct.single_cap*, %struct.single_cap** [[TMP13]], align 4
// RV32IXCHERI-NEXT:    [[TMP15:%.*]] = bitcast %struct.single_cap* [[SINGLE_CAP]] to i8*
// RV32IXCHERI-NEXT:    [[TMP16:%.*]] = bitcast %struct.single_cap* [[TMP14]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP15]], i8* align 8 [[TMP16]], i32 8, i1 true)
// RV32IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV32IXCHERI:       sw.bb11:
// RV32IXCHERI-NEXT:    [[ARGP_CUR12:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT13:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR12]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT13]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP17:%.*]] = bitcast i8* [[ARGP_CUR12]] to %struct.double_cap**
// RV32IXCHERI-NEXT:    [[TMP18:%.*]] = load %struct.double_cap*, %struct.double_cap** [[TMP17]], align 4
// RV32IXCHERI-NEXT:    [[TMP19:%.*]] = bitcast %struct.double_cap* [[DOUBLE_CAP]] to i8*
// RV32IXCHERI-NEXT:    [[TMP20:%.*]] = bitcast %struct.double_cap* [[TMP18]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP19]], i8* align 8 [[TMP20]], i32 16, i1 true)
// RV32IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV32IXCHERI:       sw.bb14:
// RV32IXCHERI-NEXT:    [[ARGP_CUR15:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT16:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR15]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT16]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP21:%.*]] = bitcast i8* [[ARGP_CUR15]] to %struct.single_cap_array**
// RV32IXCHERI-NEXT:    [[TMP22:%.*]] = load %struct.single_cap_array*, %struct.single_cap_array** [[TMP21]], align 4
// RV32IXCHERI-NEXT:    [[TMP23:%.*]] = bitcast %struct.single_cap_array* [[SINGLE_CAP_ARRAY]] to i8*
// RV32IXCHERI-NEXT:    [[TMP24:%.*]] = bitcast %struct.single_cap_array* [[TMP22]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP23]], i8* align 8 [[TMP24]], i32 8, i1 true)
// RV32IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV32IXCHERI:       sw.bb17:
// RV32IXCHERI-NEXT:    [[ARGP_CUR18:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT19:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR18]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT19]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP25:%.*]] = bitcast i8* [[ARGP_CUR18]] to %struct.double_cap_array**
// RV32IXCHERI-NEXT:    [[TMP26:%.*]] = load %struct.double_cap_array*, %struct.double_cap_array** [[TMP25]], align 4
// RV32IXCHERI-NEXT:    [[TMP27:%.*]] = bitcast %struct.double_cap_array* [[DOUBLE_CAP_ARRAY]] to i8*
// RV32IXCHERI-NEXT:    [[TMP28:%.*]] = bitcast %struct.double_cap_array* [[TMP26]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP27]], i8* align 8 [[TMP28]], i32 16, i1 true)
// RV32IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV32IXCHERI:       sw.bb20:
// RV32IXCHERI-NEXT:    [[ARGP_CUR21:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT22:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR21]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT22]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP29:%.*]] = bitcast i8* [[ARGP_CUR21]] to %struct.mixed**
// RV32IXCHERI-NEXT:    [[TMP30:%.*]] = load %struct.mixed*, %struct.mixed** [[TMP29]], align 4
// RV32IXCHERI-NEXT:    [[TMP31:%.*]] = bitcast %struct.mixed* [[MIXED]] to i8*
// RV32IXCHERI-NEXT:    [[TMP32:%.*]] = bitcast %struct.mixed* [[TMP30]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP31]], i8* align 8 [[TMP32]], i32 16, i1 true)
// RV32IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV32IXCHERI:       sw.bb23:
// RV32IXCHERI-NEXT:    [[ARGP_CUR24:%.*]] = load i8*, i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[ARGP_NEXT25:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR24]], i32 4
// RV32IXCHERI-NEXT:    store i8* [[ARGP_NEXT25]], i8** [[AP]], align 4
// RV32IXCHERI-NEXT:    [[TMP33:%.*]] = bitcast i8* [[ARGP_CUR24]] to %union.int_or_cap**
// RV32IXCHERI-NEXT:    [[TMP34:%.*]] = load %union.int_or_cap*, %union.int_or_cap** [[TMP33]], align 4
// RV32IXCHERI-NEXT:    [[TMP35:%.*]] = bitcast %union.int_or_cap* [[INT_OR_CAP]] to i8*
// RV32IXCHERI-NEXT:    [[TMP36:%.*]] = bitcast %union.int_or_cap* [[TMP34]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i32(i8* align 8 [[TMP35]], i8* align 8 [[TMP36]], i32 8, i1 true)
// RV32IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV32IXCHERI:       sw.epilog:
// RV32IXCHERI-NEXT:    [[AP26:%.*]] = bitcast i8** [[AP]] to i8*
// RV32IXCHERI-NEXT:    call void @llvm.va_end.p0i8(i8* [[AP26]])
// RV32IXCHERI-NEXT:    ret void
//
// RV64IXCHERI-LABEL: define {{[^@]+}}@callee
// RV64IXCHERI-SAME: (i64 [[SEL:%.*]], ...) #0
// RV64IXCHERI-NEXT:  entry:
// RV64IXCHERI-NEXT:    [[SEL_ADDR:%.*]] = alloca i64, align 8
// RV64IXCHERI-NEXT:    [[NULL_CAP:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[NULL_UINTCAP:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[CAP:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[UINTCAP:%.*]] = alloca i8 addrspace(200)*, align 16
// RV64IXCHERI-NEXT:    [[SINGLE_CAP:%.*]] = alloca [[STRUCT_SINGLE_CAP:%.*]], align 16
// RV64IXCHERI-NEXT:    [[DOUBLE_CAP:%.*]] = alloca [[STRUCT_DOUBLE_CAP:%.*]], align 16
// RV64IXCHERI-NEXT:    [[SINGLE_CAP_ARRAY:%.*]] = alloca [[STRUCT_SINGLE_CAP_ARRAY:%.*]], align 16
// RV64IXCHERI-NEXT:    [[DOUBLE_CAP_ARRAY:%.*]] = alloca [[STRUCT_DOUBLE_CAP_ARRAY:%.*]], align 16
// RV64IXCHERI-NEXT:    [[MIXED:%.*]] = alloca [[STRUCT_MIXED:%.*]], align 16
// RV64IXCHERI-NEXT:    [[INT_OR_CAP:%.*]] = alloca [[UNION_INT_OR_CAP:%.*]], align 16
// RV64IXCHERI-NEXT:    [[AP:%.*]] = alloca i8*, align 8
// RV64IXCHERI-NEXT:    store i64 [[SEL]], i64* [[SEL_ADDR]], align 8
// RV64IXCHERI-NEXT:    [[AP1:%.*]] = bitcast i8** [[AP]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.va_start.p0i8(i8* [[AP1]])
// RV64IXCHERI-NEXT:    [[TMP0:%.*]] = load i64, i64* [[SEL_ADDR]], align 8
// RV64IXCHERI-NEXT:    switch i64 [[TMP0]], label [[SW_EPILOG:%.*]] [
// RV64IXCHERI-NEXT:    i64 0, label [[SW_BB:%.*]]
// RV64IXCHERI-NEXT:    i64 1, label [[SW_BB8:%.*]]
// RV64IXCHERI-NEXT:    i64 2, label [[SW_BB11:%.*]]
// RV64IXCHERI-NEXT:    i64 3, label [[SW_BB14:%.*]]
// RV64IXCHERI-NEXT:    i64 4, label [[SW_BB17:%.*]]
// RV64IXCHERI-NEXT:    i64 5, label [[SW_BB20:%.*]]
// RV64IXCHERI-NEXT:    i64 6, label [[SW_BB23:%.*]]
// RV64IXCHERI-NEXT:    ]
// RV64IXCHERI:       sw.bb:
// RV64IXCHERI-NEXT:    [[ARGP_CUR:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP1:%.*]] = bitcast i8* [[ARGP_CUR]] to i8 addrspace(200)***
// RV64IXCHERI-NEXT:    [[TMP2:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP1]], align 8
// RV64IXCHERI-NEXT:    [[TMP3:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP2]], align 16
// RV64IXCHERI-NEXT:    store volatile i8 addrspace(200)* [[TMP3]], i8 addrspace(200)** [[NULL_CAP]], align 16
// RV64IXCHERI-NEXT:    [[ARGP_CUR2:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT3:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR2]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT3]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP4:%.*]] = bitcast i8* [[ARGP_CUR2]] to i8 addrspace(200)***
// RV64IXCHERI-NEXT:    [[TMP5:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP4]], align 8
// RV64IXCHERI-NEXT:    [[TMP6:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP5]], align 16
// RV64IXCHERI-NEXT:    store volatile i8 addrspace(200)* [[TMP6]], i8 addrspace(200)** [[NULL_UINTCAP]], align 16
// RV64IXCHERI-NEXT:    [[ARGP_CUR4:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT5:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR4]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT5]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP7:%.*]] = bitcast i8* [[ARGP_CUR4]] to i8 addrspace(200)***
// RV64IXCHERI-NEXT:    [[TMP8:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP7]], align 8
// RV64IXCHERI-NEXT:    [[TMP9:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP8]], align 16
// RV64IXCHERI-NEXT:    store volatile i8 addrspace(200)* [[TMP9]], i8 addrspace(200)** [[CAP]], align 16
// RV64IXCHERI-NEXT:    [[ARGP_CUR6:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT7:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR6]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT7]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP10:%.*]] = bitcast i8* [[ARGP_CUR6]] to i8 addrspace(200)***
// RV64IXCHERI-NEXT:    [[TMP11:%.*]] = load i8 addrspace(200)**, i8 addrspace(200)*** [[TMP10]], align 8
// RV64IXCHERI-NEXT:    [[TMP12:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)** [[TMP11]], align 16
// RV64IXCHERI-NEXT:    store volatile i8 addrspace(200)* [[TMP12]], i8 addrspace(200)** [[UINTCAP]], align 16
// RV64IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV64IXCHERI:       sw.bb8:
// RV64IXCHERI-NEXT:    [[ARGP_CUR9:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT10:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR9]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT10]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP13:%.*]] = bitcast i8* [[ARGP_CUR9]] to %struct.single_cap**
// RV64IXCHERI-NEXT:    [[TMP14:%.*]] = load %struct.single_cap*, %struct.single_cap** [[TMP13]], align 8
// RV64IXCHERI-NEXT:    [[TMP15:%.*]] = bitcast %struct.single_cap* [[SINGLE_CAP]] to i8*
// RV64IXCHERI-NEXT:    [[TMP16:%.*]] = bitcast %struct.single_cap* [[TMP14]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP15]], i8* align 16 [[TMP16]], i64 16, i1 true)
// RV64IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV64IXCHERI:       sw.bb11:
// RV64IXCHERI-NEXT:    [[ARGP_CUR12:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT13:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR12]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT13]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP17:%.*]] = bitcast i8* [[ARGP_CUR12]] to %struct.double_cap**
// RV64IXCHERI-NEXT:    [[TMP18:%.*]] = load %struct.double_cap*, %struct.double_cap** [[TMP17]], align 8
// RV64IXCHERI-NEXT:    [[TMP19:%.*]] = bitcast %struct.double_cap* [[DOUBLE_CAP]] to i8*
// RV64IXCHERI-NEXT:    [[TMP20:%.*]] = bitcast %struct.double_cap* [[TMP18]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP19]], i8* align 16 [[TMP20]], i64 32, i1 true)
// RV64IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV64IXCHERI:       sw.bb14:
// RV64IXCHERI-NEXT:    [[ARGP_CUR15:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT16:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR15]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT16]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP21:%.*]] = bitcast i8* [[ARGP_CUR15]] to %struct.single_cap_array**
// RV64IXCHERI-NEXT:    [[TMP22:%.*]] = load %struct.single_cap_array*, %struct.single_cap_array** [[TMP21]], align 8
// RV64IXCHERI-NEXT:    [[TMP23:%.*]] = bitcast %struct.single_cap_array* [[SINGLE_CAP_ARRAY]] to i8*
// RV64IXCHERI-NEXT:    [[TMP24:%.*]] = bitcast %struct.single_cap_array* [[TMP22]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP23]], i8* align 16 [[TMP24]], i64 16, i1 true)
// RV64IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV64IXCHERI:       sw.bb17:
// RV64IXCHERI-NEXT:    [[ARGP_CUR18:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT19:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR18]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT19]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP25:%.*]] = bitcast i8* [[ARGP_CUR18]] to %struct.double_cap_array**
// RV64IXCHERI-NEXT:    [[TMP26:%.*]] = load %struct.double_cap_array*, %struct.double_cap_array** [[TMP25]], align 8
// RV64IXCHERI-NEXT:    [[TMP27:%.*]] = bitcast %struct.double_cap_array* [[DOUBLE_CAP_ARRAY]] to i8*
// RV64IXCHERI-NEXT:    [[TMP28:%.*]] = bitcast %struct.double_cap_array* [[TMP26]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP27]], i8* align 16 [[TMP28]], i64 32, i1 true)
// RV64IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV64IXCHERI:       sw.bb20:
// RV64IXCHERI-NEXT:    [[ARGP_CUR21:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT22:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR21]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT22]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP29:%.*]] = bitcast i8* [[ARGP_CUR21]] to %struct.mixed**
// RV64IXCHERI-NEXT:    [[TMP30:%.*]] = load %struct.mixed*, %struct.mixed** [[TMP29]], align 8
// RV64IXCHERI-NEXT:    [[TMP31:%.*]] = bitcast %struct.mixed* [[MIXED]] to i8*
// RV64IXCHERI-NEXT:    [[TMP32:%.*]] = bitcast %struct.mixed* [[TMP30]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP31]], i8* align 16 [[TMP32]], i64 32, i1 true)
// RV64IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV64IXCHERI:       sw.bb23:
// RV64IXCHERI-NEXT:    [[ARGP_CUR24:%.*]] = load i8*, i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[ARGP_NEXT25:%.*]] = getelementptr inbounds i8, i8* [[ARGP_CUR24]], i64 8
// RV64IXCHERI-NEXT:    store i8* [[ARGP_NEXT25]], i8** [[AP]], align 8
// RV64IXCHERI-NEXT:    [[TMP33:%.*]] = bitcast i8* [[ARGP_CUR24]] to %union.int_or_cap**
// RV64IXCHERI-NEXT:    [[TMP34:%.*]] = load %union.int_or_cap*, %union.int_or_cap** [[TMP33]], align 8
// RV64IXCHERI-NEXT:    [[TMP35:%.*]] = bitcast %union.int_or_cap* [[INT_OR_CAP]] to i8*
// RV64IXCHERI-NEXT:    [[TMP36:%.*]] = bitcast %union.int_or_cap* [[TMP34]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[TMP35]], i8* align 16 [[TMP36]], i64 16, i1 true)
// RV64IXCHERI-NEXT:    br label [[SW_EPILOG]]
// RV64IXCHERI:       sw.epilog:
// RV64IXCHERI-NEXT:    [[AP26:%.*]] = bitcast i8** [[AP]] to i8*
// RV64IXCHERI-NEXT:    call void @llvm.va_end.p0i8(i8* [[AP26]])
// RV64IXCHERI-NEXT:    ret void
//
void callee(long sel, ...) {
  void * __capability volatile null_cap;
  volatile __uintcap_t null_uintcap;
  void * __capability volatile cap;
  volatile __uintcap_t uintcap;
  volatile struct single_cap single_cap;
  volatile struct double_cap double_cap;
  volatile struct single_cap_array single_cap_array;
  volatile struct double_cap_array double_cap_array;
  volatile struct mixed mixed;
  volatile union int_or_cap int_or_cap;
  __builtin_va_list ap;

  __builtin_va_start(ap, sel);

  switch (sel) {
  case 0:
    null_cap = __builtin_va_arg(ap, void * __capability);
    null_uintcap = __builtin_va_arg(ap, __uintcap_t);
    cap = __builtin_va_arg(ap, void * __capability);
    uintcap = __builtin_va_arg(ap, __uintcap_t);
    break;
  case 1:
    single_cap = __builtin_va_arg(ap, struct single_cap);
    break;
  case 2:
    double_cap = __builtin_va_arg(ap, struct double_cap);
    break;
  case 3:
    single_cap_array = __builtin_va_arg(ap, struct single_cap_array);
    break;
  case 4:
    double_cap_array = __builtin_va_arg(ap, struct double_cap_array);
    break;
  case 5:
    mixed = __builtin_va_arg(ap, struct mixed);
    break;
  case 6:
    int_or_cap = __builtin_va_arg(ap, union int_or_cap);
    break;
  }

  __builtin_va_end(ap);
}
