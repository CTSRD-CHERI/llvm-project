// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature
// RUN: %riscv64_cheri_cc1 %s -fsanitize=cheri-unrepresentable -disable-O0-optnone -emit-llvm -o - \
// RUN:   | opt -S -mem2reg | FileCheck %s --check-prefixes=HYBRID,HYBRID-RUNTIME
// RUN: %riscv64_cheri_cc1 %s -fsanitize=cheri-unrepresentable -fsanitize-trap=cheri-unrepresentable -disable-O0-optnone -emit-llvm -o - \
// RUN:   | opt -S -mem2reg | FileCheck %s --check-prefixes=HYBRID,HYBRID-TRAP
// RUN: %riscv64_cheri_purecap_cc1 %s -fsanitize=cheri-unrepresentable -disable-O0-optnone -emit-llvm -o - \
// RUN:   | opt -S -mem2reg | FileCheck %s --check-prefixes=PURECAP,PURECAP-RUNTIME
// RUN: %riscv64_cheri_purecap_cc1 %s -fsanitize=cheri-unrepresentable -fsanitize-trap=cheri-unrepresentable -disable-O0-optnone -emit-llvm -o - \
// RUN:   | opt -S -mem2reg | FileCheck %s --check-prefixes=PURECAP,PURECAP-TRAP

// HYBRID-RUNTIME-LABEL: define {{[^@]+}}@maybe_unrepresentable
// HYBRID-RUNTIME-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) #[[ATTR0:[0-9]+]] {
// HYBRID-RUNTIME-NEXT:  entry:
// HYBRID-RUNTIME-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i32, i32 addrspace(200)* [[INPUT]], i64 [[INDEX]]
// HYBRID-RUNTIME-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*, !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TAG_PRE:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP0]]), !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP1:%.*]] = bitcast i32 addrspace(200)* [[ADD_PTR]] to i8 addrspace(200)*, !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TAG_POST:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP1]]), !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP2:%.*]] = icmp eq i1 [[TAG_PRE]], [[TAG_POST]], !nosanitize !4
// HYBRID-RUNTIME-NEXT:    br i1 [[TMP2]], label [[CONT:%.*]], label [[HANDLER_POINTER_OVERFLOW:%.*]], !prof !5, !nosanitize !4
// HYBRID-RUNTIME:       handler.pointer_overflow:
// HYBRID-RUNTIME-NEXT:    [[TMP3:%.*]] = ptrtoint i32 addrspace(200)* [[INPUT]] to i64, !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP4:%.*]] = ptrtoint i32 addrspace(200)* [[ADD_PTR]] to i64, !nosanitize !4
// HYBRID-RUNTIME-NEXT:    call void @__ubsan_handle_pointer_overflow_abort(i8* bitcast ({ { [84 x i8]*, i32, i32 } }* @[[GLOB0:[0-9]+]] to i8*), i64 [[TMP3]], i64 [[TMP4]]) #[[ATTR3:[0-9]+]], !nosanitize !4
// HYBRID-RUNTIME-NEXT:    unreachable, !nosanitize !4
// HYBRID-RUNTIME:       cont:
// HYBRID-RUNTIME-NEXT:    ret i32 addrspace(200)* [[ADD_PTR]]
//
// HYBRID-TRAP-LABEL: define {{[^@]+}}@maybe_unrepresentable
// HYBRID-TRAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) #[[ATTR0:[0-9]+]] {
// HYBRID-TRAP-NEXT:  entry:
// HYBRID-TRAP-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i32, i32 addrspace(200)* [[INPUT]], i64 [[INDEX]]
// HYBRID-TRAP-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*, !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TAG_PRE:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP0]]), !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TMP1:%.*]] = bitcast i32 addrspace(200)* [[ADD_PTR]] to i8 addrspace(200)*, !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TAG_POST:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP1]]), !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TMP2:%.*]] = icmp eq i1 [[TAG_PRE]], [[TAG_POST]], !nosanitize !4
// HYBRID-TRAP-NEXT:    br i1 [[TMP2]], label [[CONT:%.*]], label [[TRAP:%.*]], !nosanitize !4
// HYBRID-TRAP:       trap:
// HYBRID-TRAP-NEXT:    call void @llvm.ubsantrap(i8 19) #[[ATTR3:[0-9]+]], !nosanitize !4
// HYBRID-TRAP-NEXT:    unreachable, !nosanitize !4
// HYBRID-TRAP:       cont:
// HYBRID-TRAP-NEXT:    ret i32 addrspace(200)* [[ADD_PTR]]
//
// PURECAP-RUNTIME-LABEL: define {{[^@]+}}@maybe_unrepresentable
// PURECAP-RUNTIME-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) addrspace(200) #[[ATTR0:[0-9]+]] {
// PURECAP-RUNTIME-NEXT:  entry:
// PURECAP-RUNTIME-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i32, i32 addrspace(200)* [[INPUT]], i64 [[INDEX]]
// PURECAP-RUNTIME-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*, !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TAG_PRE:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP0]]), !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP1:%.*]] = bitcast i32 addrspace(200)* [[ADD_PTR]] to i8 addrspace(200)*, !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TAG_POST:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP1]]), !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP2:%.*]] = icmp eq i1 [[TAG_PRE]], [[TAG_POST]], !nosanitize !4
// PURECAP-RUNTIME-NEXT:    br i1 [[TMP2]], label [[CONT:%.*]], label [[HANDLER_POINTER_OVERFLOW:%.*]], !prof !5, !nosanitize !4
// PURECAP-RUNTIME:       handler.pointer_overflow:
// PURECAP-RUNTIME-NEXT:    [[TMP3:%.*]] = ptrtoint i32 addrspace(200)* [[INPUT]] to i64, !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP4:%.*]] = ptrtoint i32 addrspace(200)* [[ADD_PTR]] to i64, !nosanitize !4
// PURECAP-RUNTIME-NEXT:    call void @__ubsan_handle_pointer_overflow_abort(i8 addrspace(200)* bitcast ({ { [84 x i8] addrspace(200)*, i32, i32 } } addrspace(200)* @[[GLOB0:[0-9]+]] to i8 addrspace(200)*), i64 [[TMP3]], i64 [[TMP4]]) #[[ATTR3:[0-9]+]], !nosanitize !4
// PURECAP-RUNTIME-NEXT:    unreachable, !nosanitize !4
// PURECAP-RUNTIME:       cont:
// PURECAP-RUNTIME-NEXT:    ret i32 addrspace(200)* [[ADD_PTR]]
//
// PURECAP-TRAP-LABEL: define {{[^@]+}}@maybe_unrepresentable
// PURECAP-TRAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) addrspace(200) #[[ATTR0:[0-9]+]] {
// PURECAP-TRAP-NEXT:  entry:
// PURECAP-TRAP-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i32, i32 addrspace(200)* [[INPUT]], i64 [[INDEX]]
// PURECAP-TRAP-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*, !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TAG_PRE:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP0]]), !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TMP1:%.*]] = bitcast i32 addrspace(200)* [[ADD_PTR]] to i8 addrspace(200)*, !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TAG_POST:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP1]]), !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TMP2:%.*]] = icmp eq i1 [[TAG_PRE]], [[TAG_POST]], !nosanitize !4
// PURECAP-TRAP-NEXT:    br i1 [[TMP2]], label [[CONT:%.*]], label [[TRAP:%.*]], !nosanitize !4
// PURECAP-TRAP:       trap:
// PURECAP-TRAP-NEXT:    call void @llvm.ubsantrap(i8 19) #[[ATTR3:[0-9]+]], !nosanitize !4
// PURECAP-TRAP-NEXT:    unreachable, !nosanitize !4
// PURECAP-TRAP:       cont:
// PURECAP-TRAP-NEXT:    ret i32 addrspace(200)* [[ADD_PTR]]
//
int *__capability maybe_unrepresentable(int *__capability input, long index) {
  return input + index;
}

// HYBRID-LABEL: define {{[^@]+}}@maybe_unrepresentable_intcap
// HYBRID-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) #[[ATTR0:[0-9]+]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[MUL:%.*]] = mul i64 [[INDEX]], 8
// HYBRID-NEXT:    [[TMP1:%.*]] = getelementptr i8, i8 addrspace(200)* null, i64 [[MUL]]
// HYBRID-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// HYBRID-NEXT:    [[TMP3:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
// HYBRID-NEXT:    [[ADD:%.*]] = add i64 [[TMP2]], [[TMP3]]
// HYBRID-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[ADD]])
// HYBRID-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// HYBRID-NEXT:    ret i32 addrspace(200)* [[TMP5]]
//
// PURECAP-LABEL: define {{[^@]+}}@maybe_unrepresentable_intcap
// PURECAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) addrspace(200) #[[ATTR0:[0-9]+]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[MUL:%.*]] = mul i64 [[INDEX]], 8
// PURECAP-NEXT:    [[TMP1:%.*]] = getelementptr i8, i8 addrspace(200)* null, i64 [[MUL]]
// PURECAP-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// PURECAP-NEXT:    [[TMP3:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
// PURECAP-NEXT:    [[ADD:%.*]] = add i64 [[TMP2]], [[TMP3]]
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[ADD]])
// PURECAP-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// PURECAP-NEXT:    ret i32 addrspace(200)* [[TMP5]]
//
int *__capability maybe_unrepresentable_intcap(int *__capability input, long index) {
  // No checks generated here since arithmetic on __intcap_t is not required to be inbounds.
  // TODO: generate checks here
  return (int *__capability)((__intcap_t)input + index * sizeof(long));
}

// HYBRID-LABEL: define {{[^@]+}}@bitwise_and_update_address
// HYBRID-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[MASK:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP1:%.*]] = getelementptr i8, i8 addrspace(200)* null, i64 [[MASK]]
// HYBRID-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// HYBRID-NEXT:    [[TMP3:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
// HYBRID-NEXT:    [[AND:%.*]] = and i64 [[TMP2]], [[TMP3]]
// HYBRID-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[AND]])
// HYBRID-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// HYBRID-NEXT:    ret i32 addrspace(200)* [[TMP5]]
//
// PURECAP-LABEL: define {{[^@]+}}@bitwise_and_update_address
// PURECAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[MASK:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP1:%.*]] = getelementptr i8, i8 addrspace(200)* null, i64 [[MASK]]
// PURECAP-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// PURECAP-NEXT:    [[TMP3:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
// PURECAP-NEXT:    [[AND:%.*]] = and i64 [[TMP2]], [[TMP3]]
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[AND]])
// PURECAP-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// PURECAP-NEXT:    ret i32 addrspace(200)* [[TMP5]]
//
int *__capability bitwise_and_update_address(int *__capability input, long mask) {
  // TODO: generate checks here
  return (int *__capability)((__intcap_t)input & mask);
}

// HYBRID-LABEL: define {{[^@]+}}@bitwise_or_update_address
// HYBRID-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[BITS:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP1:%.*]] = getelementptr i8, i8 addrspace(200)* null, i64 [[BITS]]
// HYBRID-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// HYBRID-NEXT:    [[TMP3:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
// HYBRID-NEXT:    [[OR:%.*]] = or i64 [[TMP2]], [[TMP3]]
// HYBRID-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[OR]])
// HYBRID-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// HYBRID-NEXT:    ret i32 addrspace(200)* [[TMP5]]
//
// PURECAP-LABEL: define {{[^@]+}}@bitwise_or_update_address
// PURECAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[BITS:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP1:%.*]] = getelementptr i8, i8 addrspace(200)* null, i64 [[BITS]]
// PURECAP-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// PURECAP-NEXT:    [[TMP3:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
// PURECAP-NEXT:    [[OR:%.*]] = or i64 [[TMP2]], [[TMP3]]
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[OR]])
// PURECAP-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// PURECAP-NEXT:    ret i32 addrspace(200)* [[TMP5]]
//
int *__capability bitwise_or_update_address(int *__capability input, long bits) {
  // TODO: generate checks here
  return (int *__capability)((__intcap_t)input | bits);
}

// HYBRID-LABEL: define {{[^@]+}}@update_address_intrinsic
// HYBRID-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[ADDR:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[ADDR]])
// HYBRID-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i32 addrspace(200)*
// HYBRID-NEXT:    ret i32 addrspace(200)* [[TMP2]]
//
// PURECAP-LABEL: define {{[^@]+}}@update_address_intrinsic
// PURECAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[ADDR:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[ADDR]])
// PURECAP-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i32 addrspace(200)*
// PURECAP-NEXT:    ret i32 addrspace(200)* [[TMP2]]
//
int *__capability update_address_intrinsic(int *__capability input, long addr) {
  // TODO: generate checks here
  return __builtin_cheri_address_set(input, addr);
}

// HYBRID-LABEL: define {{[^@]+}}@update_offset_intrinsic
// HYBRID-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[OFFSET:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[OFFSET]])
// HYBRID-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i32 addrspace(200)*
// HYBRID-NEXT:    ret i32 addrspace(200)* [[TMP2]]
//
// PURECAP-LABEL: define {{[^@]+}}@update_offset_intrinsic
// PURECAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[OFFSET:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[OFFSET]])
// PURECAP-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i32 addrspace(200)*
// PURECAP-NEXT:    ret i32 addrspace(200)* [[TMP2]]
//
int *__capability update_offset_intrinsic(int *__capability input, long offset) {
  // TODO: generate checks here
  return __builtin_cheri_offset_set(input, offset);
}
