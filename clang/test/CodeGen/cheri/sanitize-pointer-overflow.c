// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature
// RUN: %riscv64_cheri_cc1 %s -fsanitize=pointer-overflow -disable-O0-optnone -emit-llvm -o - \
// RUN:   | opt -S -mem2reg | FileCheck %s --check-prefixes=HYBRID,HYBRID-RUNTIME
// RUN: %riscv64_cheri_cc1 %s -fsanitize=pointer-overflow -fsanitize-trap=pointer-overflow -disable-O0-optnone -emit-llvm -o - \
// RUN:   | opt -S -mem2reg | FileCheck %s --check-prefixes=HYBRID,HYBRID-TRAP
// RUN: %riscv64_cheri_purecap_cc1 %s -fsanitize=pointer-overflow -disable-O0-optnone -emit-llvm -o - \
// RUN:   | opt -S -mem2reg | FileCheck %s --check-prefixes=PURECAP,PURECAP-RUNTIME
// RUN: %riscv64_cheri_purecap_cc1 %s -fsanitize=pointer-overflow -fsanitize-trap=pointer-overflow -disable-O0-optnone -emit-llvm -o - \
// RUN:   | opt -S -mem2reg | FileCheck %s --check-prefixes=PURECAP,PURECAP-TRAP

// HYBRID-RUNTIME-LABEL: define {{[^@]+}}@maybe_unrepresentable
// HYBRID-RUNTIME-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) #[[ATTR0:[0-9]+]] {
// HYBRID-RUNTIME-NEXT:  entry:
// HYBRID-RUNTIME-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i32, i32 addrspace(200)* [[INPUT]], i64 [[INDEX]]
// HYBRID-RUNTIME-NEXT:    [[TMP0:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 4, i64 [[INDEX]]), !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP1:%.*]] = extractvalue { i64, i1 } [[TMP0]], 1, !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP0]], 0, !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP3:%.*]] = ptrtoint i32 addrspace(200)* [[INPUT]] to i64, !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP4:%.*]] = add i64 [[TMP3]], [[TMP2]], !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP5:%.*]] = icmp ne i32 addrspace(200)* [[INPUT]], null, !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP6:%.*]] = icmp ne i64 [[TMP4]], 0, !nosanitize !4
// HYBRID-RUNTIME-NEXT:    [[TMP7:%.*]] = and i1 [[TMP5]], [[TMP6]], !nosanitize !4
// HYBRID-RUNTIME-NEXT:    br i1 [[TMP7]], label [[CONT:%.*]], label [[HANDLER_POINTER_OVERFLOW:%.*]], !prof !5, !nosanitize !4
// HYBRID-RUNTIME:       handler.pointer_overflow:
// HYBRID-RUNTIME-NEXT:    call void @__ubsan_handle_pointer_overflow_abort(i8* bitcast ({ { [84 x i8]*, i32, i32 } }* @[[GLOB0:[0-9]+]] to i8*), i64 [[TMP3]], i64 [[TMP4]]) #[[ATTR4:[0-9]+]], !nosanitize !4
// HYBRID-RUNTIME-NEXT:    unreachable, !nosanitize !4
// HYBRID-RUNTIME:       cont:
// HYBRID-RUNTIME-NEXT:    ret i32 addrspace(200)* [[ADD_PTR]]
//
// HYBRID-TRAP-LABEL: define {{[^@]+}}@maybe_unrepresentable
// HYBRID-TRAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) #[[ATTR0:[0-9]+]] {
// HYBRID-TRAP-NEXT:  entry:
// HYBRID-TRAP-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i32, i32 addrspace(200)* [[INPUT]], i64 [[INDEX]]
// HYBRID-TRAP-NEXT:    [[TMP0:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 4, i64 [[INDEX]]), !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TMP1:%.*]] = extractvalue { i64, i1 } [[TMP0]], 1, !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP0]], 0, !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TMP3:%.*]] = ptrtoint i32 addrspace(200)* [[INPUT]] to i64, !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TMP4:%.*]] = add i64 [[TMP3]], [[TMP2]], !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TMP5:%.*]] = icmp ne i32 addrspace(200)* [[INPUT]], null, !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TMP6:%.*]] = icmp ne i64 [[TMP4]], 0, !nosanitize !4
// HYBRID-TRAP-NEXT:    [[TMP7:%.*]] = and i1 [[TMP5]], [[TMP6]], !nosanitize !4
// HYBRID-TRAP-NEXT:    br i1 [[TMP7]], label [[CONT:%.*]], label [[TRAP:%.*]], !nosanitize !4
// HYBRID-TRAP:       trap:
// HYBRID-TRAP-NEXT:    call void @llvm.ubsantrap(i8 19) #[[ATTR4:[0-9]+]], !nosanitize !4
// HYBRID-TRAP-NEXT:    unreachable, !nosanitize !4
// HYBRID-TRAP:       cont:
// HYBRID-TRAP-NEXT:    ret i32 addrspace(200)* [[ADD_PTR]]
//
// PURECAP-RUNTIME-LABEL: define {{[^@]+}}@maybe_unrepresentable
// PURECAP-RUNTIME-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) addrspace(200) #[[ATTR0:[0-9]+]] {
// PURECAP-RUNTIME-NEXT:  entry:
// PURECAP-RUNTIME-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i32, i32 addrspace(200)* [[INPUT]], i64 [[INDEX]]
// PURECAP-RUNTIME-NEXT:    [[TMP0:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 4, i64 [[INDEX]]), !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP1:%.*]] = extractvalue { i64, i1 } [[TMP0]], 1, !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP0]], 0, !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP3:%.*]] = ptrtoint i32 addrspace(200)* [[INPUT]] to i64, !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP4:%.*]] = add i64 [[TMP3]], [[TMP2]], !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP5:%.*]] = icmp ne i32 addrspace(200)* [[INPUT]], null, !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP6:%.*]] = icmp ne i64 [[TMP4]], 0, !nosanitize !4
// PURECAP-RUNTIME-NEXT:    [[TMP7:%.*]] = and i1 [[TMP5]], [[TMP6]], !nosanitize !4
// PURECAP-RUNTIME-NEXT:    br i1 [[TMP7]], label [[CONT:%.*]], label [[HANDLER_POINTER_OVERFLOW:%.*]], !prof !5, !nosanitize !4
// PURECAP-RUNTIME:       handler.pointer_overflow:
// PURECAP-RUNTIME-NEXT:    call void @__ubsan_handle_pointer_overflow_abort(i8 addrspace(200)* bitcast ({ { [84 x i8] addrspace(200)*, i32, i32 } } addrspace(200)* @[[GLOB0:[0-9]+]] to i8 addrspace(200)*), i64 [[TMP3]], i64 [[TMP4]]) #[[ATTR4:[0-9]+]], !nosanitize !4
// PURECAP-RUNTIME-NEXT:    unreachable, !nosanitize !4
// PURECAP-RUNTIME:       cont:
// PURECAP-RUNTIME-NEXT:    ret i32 addrspace(200)* [[ADD_PTR]]
//
// PURECAP-TRAP-LABEL: define {{[^@]+}}@maybe_unrepresentable
// PURECAP-TRAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) addrspace(200) #[[ATTR0:[0-9]+]] {
// PURECAP-TRAP-NEXT:  entry:
// PURECAP-TRAP-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i32, i32 addrspace(200)* [[INPUT]], i64 [[INDEX]]
// PURECAP-TRAP-NEXT:    [[TMP0:%.*]] = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 4, i64 [[INDEX]]), !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TMP1:%.*]] = extractvalue { i64, i1 } [[TMP0]], 1, !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TMP2:%.*]] = extractvalue { i64, i1 } [[TMP0]], 0, !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TMP3:%.*]] = ptrtoint i32 addrspace(200)* [[INPUT]] to i64, !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TMP4:%.*]] = add i64 [[TMP3]], [[TMP2]], !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TMP5:%.*]] = icmp ne i32 addrspace(200)* [[INPUT]], null, !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TMP6:%.*]] = icmp ne i64 [[TMP4]], 0, !nosanitize !4
// PURECAP-TRAP-NEXT:    [[TMP7:%.*]] = and i1 [[TMP5]], [[TMP6]], !nosanitize !4
// PURECAP-TRAP-NEXT:    br i1 [[TMP7]], label [[CONT:%.*]], label [[TRAP:%.*]], !nosanitize !4
// PURECAP-TRAP:       trap:
// PURECAP-TRAP-NEXT:    call void @llvm.ubsantrap(i8 19) #[[ATTR4:[0-9]+]], !nosanitize !4
// PURECAP-TRAP-NEXT:    unreachable, !nosanitize !4
// PURECAP-TRAP:       cont:
// PURECAP-TRAP-NEXT:    ret i32 addrspace(200)* [[ADD_PTR]]
//
int *__capability maybe_unrepresentable(int *__capability input, long index) {
  return input + index;
}

// HYBRID-LABEL: define {{[^@]+}}@maybe_unrepresentable_intcap
// HYBRID-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) #[[ATTR0:[0-9]+]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[MUL:%.*]] = mul i64 [[INDEX]], 8
// HYBRID-NEXT:    [[TMP1:%.*]] = getelementptr i8, i8 addrspace(200)* null, i64 [[MUL]]
// HYBRID-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// HYBRID-NEXT:    [[TMP3:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
// HYBRID-NEXT:    [[ADD:%.*]] = add i64 [[TMP2]], [[TMP3]]
// HYBRID-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[ADD]])
// HYBRID-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// HYBRID-NEXT:    ret i32 addrspace(200)* [[TMP5]]
//
// PURECAP-LABEL: define {{[^@]+}}@maybe_unrepresentable_intcap
// PURECAP-SAME: (i32 addrspace(200)* [[INPUT:%.*]], i64 [[INDEX:%.*]]) addrspace(200) #[[ATTR0:[0-9]+]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[INPUT]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[MUL:%.*]] = mul i64 [[INDEX]], 8
// PURECAP-NEXT:    [[TMP1:%.*]] = getelementptr i8, i8 addrspace(200)* null, i64 [[MUL]]
// PURECAP-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// PURECAP-NEXT:    [[TMP3:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
// PURECAP-NEXT:    [[ADD:%.*]] = add i64 [[TMP2]], [[TMP3]]
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP0]], i64 [[ADD]])
// PURECAP-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// PURECAP-NEXT:    ret i32 addrspace(200)* [[TMP5]]
//
int *__capability maybe_unrepresentable_intcap(int *__capability input, long index) {
  // No checks generated here since arithmentic on __intcap_t is not required to be inbounds.
  return (int *__capability)((__intcap_t)input + index * sizeof(long));
}
