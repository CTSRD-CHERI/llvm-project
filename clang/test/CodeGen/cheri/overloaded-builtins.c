// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature
/// Check that we generate correct code when dealing with overloaded builtins
// RUN: %cheri_purecap_cc1 %s -emit-llvm -o - -disable-O0-optnone | opt -S -mem2reg | FileCheck %s --check-prefixes=PURECAP
// RUN: %cheri_cc1 %s -emit-llvm -o - -disable-O0-optnone | opt -S -mem2reg | FileCheck %s --check-prefixes=HYBRID

typedef __SIZE_TYPE__ size_t;
typedef _Bool bool;

#define call_overloaded_builtins(T, x, x2)                                     \
  size_t result1 = __builtin_cheri_address_get(x);                             \
  T result2 = __builtin_cheri_address_set(x, 1);                               \
  size_t result3 = __builtin_cheri_base_get(x);                                \
  T result4 = __builtin_cheri_bounds_set(x, 1);                                \
  T result5 = __builtin_cheri_bounds_set_exact(x, 1);                          \
  bool result6 = __builtin_cheri_equal_exact(x, x2);                           \
  T result7 = __builtin_cheri_flags_set(x, 1);                                 \
  size_t result8 = __builtin_cheri_flags_get(x);                               \
  size_t result9 = __builtin_cheri_length_get(x);                              \
  size_t result10 = __builtin_cheri_offset_get(x);                             \
  T result11 = __builtin_cheri_offset_increment(x, 1);                         \
  T result12 = __builtin_cheri_offset_set(x, 1);                               \
  T result13 = __builtin_cheri_perms_and(x, 1);                                \
  size_t result14 = __builtin_cheri_perms_get(x);                              \
  T result15 = __builtin_cheri_seal(x, x2);                                    \
  T result16 = __builtin_cheri_seal_entry(x);                                  \
  bool result17 = __builtin_cheri_sealed_get(x);                               \
  bool result18 = __builtin_cheri_subset_test(x, x2);                          \
  T result19 = __builtin_cheri_tag_clear(x);                                   \
  bool result20 = __builtin_cheri_tag_get(x);                                  \
  size_t result21 = __builtin_cheri_type_get(x);                               \
  T result22 = __builtin_cheri_unseal(x, x2);                                  \
  T result23 = __builtin_cheri_conditional_seal(x, x2);                        \
  T result24 = __builtin_cheri_cap_type_copy(x, x2);                           \
  void *__capability result25 = __builtin_cheri_cap_build(x, (__uintcap_t)x2); \
  __builtin_cheri_perms_check(x, 1);                                           \
  __builtin_cheri_type_check(x, x2);

// PURECAP-LABEL: define {{[^@]+}}@test_void_ptr
// PURECAP-SAME: (i8 addrspace(200)* [[ARG:%.*]], i8 addrspace(200)* [[ARG2:%.*]]) addrspace(200) #[[ATTR0:[0-9]+]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP5:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP5]] to i8
// PURECAP-NEXT:    [[TMP6:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP8:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP9:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, i8 addrspace(200)* [[ARG]], i64 1
// PURECAP-NEXT:    [[TMP10:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP12:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP13:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP14:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP15:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP15]] to i8
// PURECAP-NEXT:    [[TMP16:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP16]] to i8
// PURECAP-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP18:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP18]] to i8
// PURECAP-NEXT:    [[TMP19:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP20:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP22:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP23:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    ret void
//
// HYBRID-LABEL: define {{[^@]+}}@test_void_ptr
// HYBRID-SAME: (i8 addrspace(200)* [[ARG:%.*]], i8 addrspace(200)* [[ARG2:%.*]]) #[[ATTR0:[0-9]+]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP5:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP5]] to i8
// HYBRID-NEXT:    [[TMP6:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP8:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP9:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, i8 addrspace(200)* [[ARG]], i64 1
// HYBRID-NEXT:    [[TMP10:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP12:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP13:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP14:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP15:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP15]] to i8
// HYBRID-NEXT:    [[TMP16:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP16]] to i8
// HYBRID-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP18:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP18]] to i8
// HYBRID-NEXT:    [[TMP19:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP20:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP22:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP23:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    ret void
//
void test_void_ptr(void *__capability arg, void *__capability arg2) {
  call_overloaded_builtins(void *__capability, arg, arg2);
}

// PURECAP-LABEL: define {{[^@]+}}@test_const_char_ptr
// PURECAP-SAME: (i8 addrspace(200)* [[ARG:%.*]], i8 addrspace(200)* [[ARG2:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP5:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP5]] to i8
// PURECAP-NEXT:    [[TMP6:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP8:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP9:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, i8 addrspace(200)* [[ARG]], i64 1
// PURECAP-NEXT:    [[TMP10:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP12:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP13:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP14:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP15:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP15]] to i8
// PURECAP-NEXT:    [[TMP16:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP16]] to i8
// PURECAP-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP18:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP18]] to i8
// PURECAP-NEXT:    [[TMP19:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP20:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP22:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP23:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    ret void
//
// HYBRID-LABEL: define {{[^@]+}}@test_const_char_ptr
// HYBRID-SAME: (i8 addrspace(200)* [[ARG:%.*]], i8 addrspace(200)* [[ARG2:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP5:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP5]] to i8
// HYBRID-NEXT:    [[TMP6:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP8:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP9:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, i8 addrspace(200)* [[ARG]], i64 1
// HYBRID-NEXT:    [[TMP10:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP12:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP13:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP14:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP15:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP15]] to i8
// HYBRID-NEXT:    [[TMP16:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP16]] to i8
// HYBRID-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP18:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP18]] to i8
// HYBRID-NEXT:    [[TMP19:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP20:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP22:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP23:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    ret void
//
void test_const_char_ptr(const char *__capability arg, const char *__capability arg2) {
  call_overloaded_builtins(const char *__capability, arg, arg2);
}

// PURECAP-LABEL: define {{[^@]+}}@test_long_ptr
// PURECAP-SAME: (i64 addrspace(200)* [[ARG:%.*]], i64 addrspace(200)* [[ARG2:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP1:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// PURECAP-NEXT:    [[TMP2:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP2]], i64 1)
// PURECAP-NEXT:    [[TMP4:%.*]] = bitcast i8 addrspace(200)* [[TMP3]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP5:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP6:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* [[TMP5]])
// PURECAP-NEXT:    [[TMP7:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP8:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* [[TMP7]], i64 1)
// PURECAP-NEXT:    [[TMP9:%.*]] = bitcast i8 addrspace(200)* [[TMP8]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP10:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* [[TMP10]], i64 1)
// PURECAP-NEXT:    [[TMP12:%.*]] = bitcast i8 addrspace(200)* [[TMP11]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP13:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP14:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP15:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* [[TMP13]], i8 addrspace(200)* [[TMP14]])
// PURECAP-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP15]] to i8
// PURECAP-NEXT:    [[TMP16:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* [[TMP16]], i64 1)
// PURECAP-NEXT:    [[TMP18:%.*]] = bitcast i8 addrspace(200)* [[TMP17]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP19:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP20:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* [[TMP19]])
// PURECAP-NEXT:    [[TMP21:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP22:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* [[TMP21]])
// PURECAP-NEXT:    [[TMP23:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP24:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* [[TMP23]])
// PURECAP-NEXT:    [[TMP25:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, i8 addrspace(200)* [[TMP25]], i64 1
// PURECAP-NEXT:    [[TMP26:%.*]] = bitcast i8 addrspace(200)* [[__BUILTIN_CHERI_OFFSET_INCREMENT]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP27:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP28:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[TMP27]], i64 1)
// PURECAP-NEXT:    [[TMP29:%.*]] = bitcast i8 addrspace(200)* [[TMP28]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP30:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP31:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* [[TMP30]], i64 1)
// PURECAP-NEXT:    [[TMP32:%.*]] = bitcast i8 addrspace(200)* [[TMP31]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP33:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP34:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* [[TMP33]])
// PURECAP-NEXT:    [[TMP35:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP36:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP37:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* [[TMP35]], i8 addrspace(200)* [[TMP36]])
// PURECAP-NEXT:    [[TMP38:%.*]] = bitcast i8 addrspace(200)* [[TMP37]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP39:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP40:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* [[TMP39]])
// PURECAP-NEXT:    [[TMP41:%.*]] = bitcast i8 addrspace(200)* [[TMP40]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP42:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP43:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* [[TMP42]])
// PURECAP-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP43]] to i8
// PURECAP-NEXT:    [[TMP44:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP45:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP46:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* [[TMP44]], i8 addrspace(200)* [[TMP45]])
// PURECAP-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP46]] to i8
// PURECAP-NEXT:    [[TMP47:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP48:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* [[TMP47]])
// PURECAP-NEXT:    [[TMP49:%.*]] = bitcast i8 addrspace(200)* [[TMP48]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP50:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP51:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP50]])
// PURECAP-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP51]] to i8
// PURECAP-NEXT:    [[TMP52:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP53:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* [[TMP52]])
// PURECAP-NEXT:    [[TMP54:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP55:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP56:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* [[TMP54]], i8 addrspace(200)* [[TMP55]])
// PURECAP-NEXT:    [[TMP57:%.*]] = bitcast i8 addrspace(200)* [[TMP56]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP58:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP59:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP60:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* [[TMP58]], i8 addrspace(200)* [[TMP59]])
// PURECAP-NEXT:    [[TMP61:%.*]] = bitcast i8 addrspace(200)* [[TMP60]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP62:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP63:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP64:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* [[TMP62]], i8 addrspace(200)* [[TMP63]])
// PURECAP-NEXT:    [[TMP65:%.*]] = bitcast i8 addrspace(200)* [[TMP64]] to i64 addrspace(200)*
// PURECAP-NEXT:    [[TMP66:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP67:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP68:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* [[TMP66]], i8 addrspace(200)* [[TMP67]])
// PURECAP-NEXT:    [[TMP69:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* [[TMP69]], i64 1)
// PURECAP-NEXT:    [[TMP70:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// PURECAP-NEXT:    [[TMP71:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// PURECAP-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* [[TMP70]], i8 addrspace(200)* [[TMP71]])
// PURECAP-NEXT:    ret void
//
// HYBRID-LABEL: define {{[^@]+}}@test_long_ptr
// HYBRID-SAME: (i64 addrspace(200)* [[ARG:%.*]], i64 addrspace(200)* [[ARG2:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP1:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP0]])
// HYBRID-NEXT:    [[TMP2:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[TMP2]], i64 1)
// HYBRID-NEXT:    [[TMP4:%.*]] = bitcast i8 addrspace(200)* [[TMP3]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP5:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP6:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* [[TMP5]])
// HYBRID-NEXT:    [[TMP7:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP8:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* [[TMP7]], i64 1)
// HYBRID-NEXT:    [[TMP9:%.*]] = bitcast i8 addrspace(200)* [[TMP8]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP10:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* [[TMP10]], i64 1)
// HYBRID-NEXT:    [[TMP12:%.*]] = bitcast i8 addrspace(200)* [[TMP11]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP13:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP14:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP15:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* [[TMP13]], i8 addrspace(200)* [[TMP14]])
// HYBRID-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP15]] to i8
// HYBRID-NEXT:    [[TMP16:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* [[TMP16]], i64 1)
// HYBRID-NEXT:    [[TMP18:%.*]] = bitcast i8 addrspace(200)* [[TMP17]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP19:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP20:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* [[TMP19]])
// HYBRID-NEXT:    [[TMP21:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP22:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* [[TMP21]])
// HYBRID-NEXT:    [[TMP23:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP24:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* [[TMP23]])
// HYBRID-NEXT:    [[TMP25:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, i8 addrspace(200)* [[TMP25]], i64 1
// HYBRID-NEXT:    [[TMP26:%.*]] = bitcast i8 addrspace(200)* [[__BUILTIN_CHERI_OFFSET_INCREMENT]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP27:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP28:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[TMP27]], i64 1)
// HYBRID-NEXT:    [[TMP29:%.*]] = bitcast i8 addrspace(200)* [[TMP28]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP30:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP31:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* [[TMP30]], i64 1)
// HYBRID-NEXT:    [[TMP32:%.*]] = bitcast i8 addrspace(200)* [[TMP31]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP33:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP34:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* [[TMP33]])
// HYBRID-NEXT:    [[TMP35:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP36:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP37:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* [[TMP35]], i8 addrspace(200)* [[TMP36]])
// HYBRID-NEXT:    [[TMP38:%.*]] = bitcast i8 addrspace(200)* [[TMP37]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP39:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP40:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* [[TMP39]])
// HYBRID-NEXT:    [[TMP41:%.*]] = bitcast i8 addrspace(200)* [[TMP40]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP42:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP43:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* [[TMP42]])
// HYBRID-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP43]] to i8
// HYBRID-NEXT:    [[TMP44:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP45:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP46:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* [[TMP44]], i8 addrspace(200)* [[TMP45]])
// HYBRID-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP46]] to i8
// HYBRID-NEXT:    [[TMP47:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP48:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* [[TMP47]])
// HYBRID-NEXT:    [[TMP49:%.*]] = bitcast i8 addrspace(200)* [[TMP48]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP50:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP51:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[TMP50]])
// HYBRID-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP51]] to i8
// HYBRID-NEXT:    [[TMP52:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP53:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* [[TMP52]])
// HYBRID-NEXT:    [[TMP54:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP55:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP56:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* [[TMP54]], i8 addrspace(200)* [[TMP55]])
// HYBRID-NEXT:    [[TMP57:%.*]] = bitcast i8 addrspace(200)* [[TMP56]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP58:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP59:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP60:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* [[TMP58]], i8 addrspace(200)* [[TMP59]])
// HYBRID-NEXT:    [[TMP61:%.*]] = bitcast i8 addrspace(200)* [[TMP60]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP62:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP63:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP64:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* [[TMP62]], i8 addrspace(200)* [[TMP63]])
// HYBRID-NEXT:    [[TMP65:%.*]] = bitcast i8 addrspace(200)* [[TMP64]] to i64 addrspace(200)*
// HYBRID-NEXT:    [[TMP66:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP67:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP68:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* [[TMP66]], i8 addrspace(200)* [[TMP67]])
// HYBRID-NEXT:    [[TMP69:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* [[TMP69]], i64 1)
// HYBRID-NEXT:    [[TMP70:%.*]] = bitcast i64 addrspace(200)* [[ARG]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP71:%.*]] = bitcast i64 addrspace(200)* [[ARG2]] to i8 addrspace(200)*
// HYBRID-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* [[TMP70]], i8 addrspace(200)* [[TMP71]])
// HYBRID-NEXT:    ret void
//
void test_long_ptr(long *__capability arg, long *__capability arg2) {
  call_overloaded_builtins(long *__capability, arg, arg2);
}

// PURECAP-LABEL: define {{[^@]+}}@test_uintcap_t
// PURECAP-SAME: (i8 addrspace(200)* [[ARG:%.*]], i8 addrspace(200)* [[ARG2:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP5:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP5]] to i8
// PURECAP-NEXT:    [[TMP6:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP8:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP9:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, i8 addrspace(200)* [[ARG]], i64 1
// PURECAP-NEXT:    [[TMP10:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    [[TMP12:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP13:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP14:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP15:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP15]] to i8
// PURECAP-NEXT:    [[TMP16:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP16]] to i8
// PURECAP-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP18:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP18]] to i8
// PURECAP-NEXT:    [[TMP19:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* [[ARG]])
// PURECAP-NEXT:    [[TMP20:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP22:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    [[TMP23:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* [[ARG]], i64 1)
// PURECAP-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// PURECAP-NEXT:    ret void
//
// HYBRID-LABEL: define {{[^@]+}}@test_uintcap_t
// HYBRID-SAME: (i8 addrspace(200)* [[ARG:%.*]], i8 addrspace(200)* [[ARG2:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP5:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP5]] to i8
// HYBRID-NEXT:    [[TMP6:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP8:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP9:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[__BUILTIN_CHERI_OFFSET_INCREMENT:%.*]] = getelementptr i8, i8 addrspace(200)* [[ARG]], i64 1
// HYBRID-NEXT:    [[TMP10:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    [[TMP12:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP13:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP14:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP15:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP15]] to i8
// HYBRID-NEXT:    [[TMP16:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP16]] to i8
// HYBRID-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP18:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP18]] to i8
// HYBRID-NEXT:    [[TMP19:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* [[ARG]])
// HYBRID-NEXT:    [[TMP20:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP22:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    [[TMP23:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* [[ARG]], i64 1)
// HYBRID-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* [[ARG]], i8 addrspace(200)* [[ARG2]])
// HYBRID-NEXT:    ret void
//
void test_uintcap_t(__uintcap_t arg, __uintcap_t arg2) {
  call_overloaded_builtins(__uintcap_t, arg, arg2);
}

// PURECAP-LABEL: define {{[^@]+}}@test_null_constant
// PURECAP-SAME: (i8 addrspace(200)* [[ARG:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP1:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP2:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    [[TMP4:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP4]] to i8
// PURECAP-NEXT:    [[TMP5:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    [[TMP6:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP8:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP9:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    [[TMP10:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP12:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP13:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP13]] to i8
// PURECAP-NEXT:    [[TMP14:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP14]] to i8
// PURECAP-NEXT:    [[TMP15:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP16:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP16]] to i8
// PURECAP-NEXT:    [[TMP17:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP18:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP19:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP20:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    ret void
//
// HYBRID-LABEL: define {{[^@]+}}@test_null_constant
// HYBRID-SAME: (i8 addrspace(200)* [[ARG:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP1:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP2:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    [[TMP4:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP4]] to i8
// HYBRID-NEXT:    [[TMP5:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    [[TMP6:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP8:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP9:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    [[TMP10:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP12:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP13:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP13]] to i8
// HYBRID-NEXT:    [[TMP14:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP14]] to i8
// HYBRID-NEXT:    [[TMP15:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP16:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP16]] to i8
// HYBRID-NEXT:    [[TMP17:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP18:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP19:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP20:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    ret void
//
void test_null_constant(__uintcap_t arg) {
  call_overloaded_builtins(void *__capability, (void *)0, (void *)0);
}

// PURECAP-LABEL: define {{[^@]+}}@test_null_int_ptr
// PURECAP-SAME: (i8 addrspace(200)* [[ARG:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP1:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP2:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    [[TMP3:%.*]] = bitcast i8 addrspace(200)* [[TMP2]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP6:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP6]] to i8
// PURECAP-NEXT:    [[TMP7:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    [[TMP8:%.*]] = bitcast i8 addrspace(200)* [[TMP7]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP9:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP10:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP11:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP12:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    [[TMP13:%.*]] = bitcast i8 addrspace(200)* [[TMP12]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP14:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP15:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP16:%.*]] = bitcast i8 addrspace(200)* [[TMP15]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP18:%.*]] = bitcast i8 addrspace(200)* [[TMP17]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP19:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP19]] to i8
// PURECAP-NEXT:    [[TMP20:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP20]] to i8
// PURECAP-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP22:%.*]] = bitcast i8 addrspace(200)* [[TMP21]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP23:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP23]] to i8
// PURECAP-NEXT:    [[TMP24:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP25:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP26:%.*]] = bitcast i8 addrspace(200)* [[TMP25]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP27:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP28:%.*]] = bitcast i8 addrspace(200)* [[TMP27]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP29:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    [[TMP30:%.*]] = bitcast i8 addrspace(200)* [[TMP29]] to i32 addrspace(200)*
// PURECAP-NEXT:    [[TMP31:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* null, i64 1)
// PURECAP-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* null, i8 addrspace(200)* null)
// PURECAP-NEXT:    ret void
//
// HYBRID-LABEL: define {{[^@]+}}@test_null_int_ptr
// HYBRID-SAME: (i8 addrspace(200)* [[ARG:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP1:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP2:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    [[TMP3:%.*]] = bitcast i8 addrspace(200)* [[TMP2]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP6:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP6]] to i8
// HYBRID-NEXT:    [[TMP7:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    [[TMP8:%.*]] = bitcast i8 addrspace(200)* [[TMP7]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP9:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP10:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP11:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP12:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    [[TMP13:%.*]] = bitcast i8 addrspace(200)* [[TMP12]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP14:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP15:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP16:%.*]] = bitcast i8 addrspace(200)* [[TMP15]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP18:%.*]] = bitcast i8 addrspace(200)* [[TMP17]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP19:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP19]] to i8
// HYBRID-NEXT:    [[TMP20:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP20]] to i8
// HYBRID-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP22:%.*]] = bitcast i8 addrspace(200)* [[TMP21]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP23:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP23]] to i8
// HYBRID-NEXT:    [[TMP24:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP25:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP26:%.*]] = bitcast i8 addrspace(200)* [[TMP25]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP27:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP28:%.*]] = bitcast i8 addrspace(200)* [[TMP27]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP29:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP30:%.*]] = bitcast i8 addrspace(200)* [[TMP29]] to i32 addrspace(200)*
// HYBRID-NEXT:    [[TMP31:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* null, i64 1)
// HYBRID-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* null, i8 addrspace(200)* null)
// HYBRID-NEXT:    ret void
//
void test_null_int_ptr(__uintcap_t arg) {
  call_overloaded_builtins(const int *__capability, (const int *__capability)0, (const int *__capability)0);
}

// PURECAP-LABEL: define {{[^@]+}}@test_cap_from_ptr
// PURECAP-SAME: (i8 addrspace(200)* [[AUTHCAP1:%.*]], i8 addrspace(200)* [[AUTHCAP2:%.*]], i64 signext [[L:%.*]], i32 signext [[I:%.*]], i32 signext [[U:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 [[L]])
// PURECAP-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP2]], i64 [[L]])
// PURECAP-NEXT:    [[TMP2:%.*]] = call i8 addrspace(200)* @llvm.cheri.ddc.get()
// PURECAP-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[TMP2]], i64 [[L]])
// PURECAP-NEXT:    [[TMP4:%.*]] = sext i32 [[I]] to i64
// PURECAP-NEXT:    [[TMP5:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 [[TMP4]])
// PURECAP-NEXT:    [[TMP6:%.*]] = zext i32 [[U]] to i64
// PURECAP-NEXT:    [[TMP7:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 [[TMP6]])
// PURECAP-NEXT:    [[TMP8:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 0)
// PURECAP-NEXT:    ret void
//
// HYBRID-LABEL: define {{[^@]+}}@test_cap_from_ptr
// HYBRID-SAME: (i8 addrspace(200)* [[AUTHCAP1:%.*]], i8 addrspace(200)* [[AUTHCAP2:%.*]], i64 signext [[L:%.*]], i32 signext [[I:%.*]], i32 signext [[U:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 [[L]])
// HYBRID-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP2]], i64 [[L]])
// HYBRID-NEXT:    [[TMP2:%.*]] = call i8 addrspace(200)* @llvm.cheri.ddc.get()
// HYBRID-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[TMP2]], i64 [[L]])
// HYBRID-NEXT:    [[TMP4:%.*]] = sext i32 [[I]] to i64
// HYBRID-NEXT:    [[TMP5:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 [[TMP4]])
// HYBRID-NEXT:    [[TMP6:%.*]] = zext i32 [[U]] to i64
// HYBRID-NEXT:    [[TMP7:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 [[TMP6]])
// HYBRID-NEXT:    [[TMP8:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 0)
// HYBRID-NEXT:    [[TMP9:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 0)
// HYBRID-NEXT:    [[TMP10:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.from.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i64 0)
// HYBRID-NEXT:    [[TMP11:%.*]] = bitcast i8 addrspace(200)* [[TMP10]] to i64 addrspace(200)*
// HYBRID-NEXT:    ret void
//
void test_cap_from_ptr(void *__capability authcap1, __uintcap_t authcap2, long l, int i, unsigned u) {
  void *__capability c1 = __builtin_cheri_cap_from_pointer(authcap1, l);
  void *__capability c2 = __builtin_cheri_cap_from_pointer(authcap2, l);
  void *__capability c3 = __builtin_cheri_cap_from_pointer(__builtin_cheri_global_data_get(), l);
  // Check int is extended to i64:
  void *__capability c4 = __builtin_cheri_cap_from_pointer(authcap1, i); // sign-extend
  void *__capability c5 = __builtin_cheri_cap_from_pointer(authcap1, u); // zero-extend
  // Zero argument
  void *__capability c6 = __builtin_cheri_cap_from_pointer(authcap1, 0);
#ifndef __CHERI_PURE_CAPABILITY__
  // pointer type argument
  void *__capability c7 = __builtin_cheri_cap_from_pointer(authcap1, (void *)0);
  // Check that we add a bitcast for the return value:
  long *__capability c8 = __builtin_cheri_cap_from_pointer(authcap1, (long *)0);
#endif
}

#ifndef __CHERI_PURE_CAPABILITY__
// HYBRID-LABEL: define {{[^@]+}}@test_cap_to_ptr
// HYBRID-SAME: (i8 addrspace(200)* [[AUTHCAP1:%.*]], i8 addrspace(200)* [[AUTHCAP2:%.*]], i8 addrspace(200)* [[VCAP:%.*]], i64 addrspace(200)* [[LCAP:%.*]], i32 addrspace(200)* [[ICAP:%.*]]) #[[ATTR0]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.to.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i8 addrspace(200)* [[VCAP]])
// HYBRID-NEXT:    [[TMP1:%.*]] = inttoptr i64 [[TMP0]] to i8*
// HYBRID-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.to.pointer.i64(i8 addrspace(200)* [[AUTHCAP2]], i8 addrspace(200)* [[VCAP]])
// HYBRID-NEXT:    [[TMP3:%.*]] = inttoptr i64 [[TMP2]] to i8*
// HYBRID-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.ddc.get()
// HYBRID-NEXT:    [[TMP5:%.*]] = call i64 @llvm.cheri.cap.to.pointer.i64(i8 addrspace(200)* [[TMP4]], i8 addrspace(200)* [[VCAP]])
// HYBRID-NEXT:    [[TMP6:%.*]] = inttoptr i64 [[TMP5]] to i8*
// HYBRID-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.to.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i8 addrspace(200)* null)
// HYBRID-NEXT:    [[TMP8:%.*]] = inttoptr i64 [[TMP7]] to i8*
// HYBRID-NEXT:    [[TMP9:%.*]] = bitcast i64 addrspace(200)* [[LCAP]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP10:%.*]] = call i64 @llvm.cheri.cap.to.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i8 addrspace(200)* [[TMP9]])
// HYBRID-NEXT:    [[TMP11:%.*]] = inttoptr i64 [[TMP10]] to i64*
// HYBRID-NEXT:    [[TMP12:%.*]] = bitcast i32 addrspace(200)* [[ICAP]] to i8 addrspace(200)*
// HYBRID-NEXT:    [[TMP13:%.*]] = call i64 @llvm.cheri.cap.to.pointer.i64(i8 addrspace(200)* [[AUTHCAP1]], i8 addrspace(200)* [[TMP12]])
// HYBRID-NEXT:    [[TMP14:%.*]] = inttoptr i64 [[TMP13]] to i32*
// HYBRID-NEXT:    ret void
//
void test_cap_to_ptr(void *__capability authcap1, __uintcap_t authcap2, void *__capability vcap,
                     long *__capability lcap, const int *__capability icap) {
  void *c1 = __builtin_cheri_cap_to_pointer(authcap1, vcap);
  void *c2 = __builtin_cheri_cap_to_pointer(authcap2, vcap);
  void *c3 = __builtin_cheri_cap_to_pointer(__builtin_cheri_global_data_get(), vcap);
  // Check zero argument is NULL
  void *c4 = __builtin_cheri_cap_to_pointer(authcap1, 0);
  // Check that we add a bitcast for the return value:
  long *c5 = __builtin_cheri_cap_to_pointer(authcap1, lcap);
  const int *c6 = __builtin_cheri_cap_to_pointer(authcap1, icap);
}
#endif

// Array-decay and function-to-pointer decay only works for purecap
#ifdef __CHERI_PURE_CAPABILITY__

static char global_buffer[16];
static char global_buffer2[32];

// PURECAP-LABEL: define {{[^@]+}}@test_array
// PURECAP-SAME: () addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i64 1)
// PURECAP-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i64 1)
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i64 1)
// PURECAP-NEXT:    [[TMP5:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i8 addrspace(200)* getelementptr inbounds ([32 x i8], [32 x i8] addrspace(200)* @global_buffer2, i64 0, i64 0))
// PURECAP-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP5]] to i8
// PURECAP-NEXT:    [[TMP6:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i64 1)
// PURECAP-NEXT:    [[TMP7:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP8:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP9:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP10:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i64 1)
// PURECAP-NEXT:    [[TMP11:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i64 1)
// PURECAP-NEXT:    [[TMP12:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP13:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i8 addrspace(200)* getelementptr inbounds ([32 x i8], [32 x i8] addrspace(200)* @global_buffer2, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP14:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP15:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP15]] to i8
// PURECAP-NEXT:    [[TMP16:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i8 addrspace(200)* getelementptr inbounds ([32 x i8], [32 x i8] addrspace(200)* @global_buffer2, i64 0, i64 0))
// PURECAP-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP16]] to i8
// PURECAP-NEXT:    [[TMP17:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP18:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP18]] to i8
// PURECAP-NEXT:    [[TMP19:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP20:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i8 addrspace(200)* getelementptr inbounds ([32 x i8], [32 x i8] addrspace(200)* @global_buffer2, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i8 addrspace(200)* getelementptr inbounds ([32 x i8], [32 x i8] addrspace(200)* @global_buffer2, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP22:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i8 addrspace(200)* getelementptr inbounds ([32 x i8], [32 x i8] addrspace(200)* @global_buffer2, i64 0, i64 0))
// PURECAP-NEXT:    [[TMP23:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i8 addrspace(200)* getelementptr inbounds ([32 x i8], [32 x i8] addrspace(200)* @global_buffer2, i64 0, i64 0))
// PURECAP-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i64 1)
// PURECAP-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* getelementptr inbounds ([16 x i8], [16 x i8] addrspace(200)* @global_buffer, i64 0, i64 0), i8 addrspace(200)* getelementptr inbounds ([32 x i8], [32 x i8] addrspace(200)* @global_buffer2, i64 0, i64 0))
// PURECAP-NEXT:    ret void
//
void test_array(void) {
  call_overloaded_builtins(const char *__capability, global_buffer, global_buffer2);
}

typedef void (*__capability fnptr_t)(void);

// PURECAP-LABEL: define {{[^@]+}}@test_function
// PURECAP-SAME: () addrspace(200) #[[ATTR0]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i64 1)
// PURECAP-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP3:%.*]] = call i64 @llvm.cheri.cap.base.get.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP4:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i64 1)
// PURECAP-NEXT:    [[TMP5:%.*]] = bitcast i8 addrspace(200)* [[TMP4]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP6:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i64 1)
// PURECAP-NEXT:    [[TMP7:%.*]] = bitcast i8 addrspace(200)* [[TMP6]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP8:%.*]] = call i1 @llvm.cheri.cap.equal.exact(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i8 addrspace(200)* bitcast (void () addrspace(200)* @test_array to i8 addrspace(200)*))
// PURECAP-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP8]] to i8
// PURECAP-NEXT:    [[TMP9:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.flags.set.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i64 1)
// PURECAP-NEXT:    [[TMP10:%.*]] = bitcast i8 addrspace(200)* [[TMP9]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP11:%.*]] = call i64 @llvm.cheri.cap.flags.get.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP12:%.*]] = call i64 @llvm.cheri.cap.length.get.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP13:%.*]] = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP14:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i64 1)
// PURECAP-NEXT:    [[TMP15:%.*]] = bitcast i8 addrspace(200)* [[TMP14]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP16:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.perms.and.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i64 1)
// PURECAP-NEXT:    [[TMP17:%.*]] = bitcast i8 addrspace(200)* [[TMP16]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP18:%.*]] = call i64 @llvm.cheri.cap.perms.get.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP19:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i8 addrspace(200)* bitcast (void () addrspace(200)* @test_array to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP20:%.*]] = bitcast i8 addrspace(200)* [[TMP19]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP21:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.seal.entry(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP22:%.*]] = bitcast i8 addrspace(200)* [[TMP21]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP23:%.*]] = call i1 @llvm.cheri.cap.sealed.get(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[FROMBOOL1:%.*]] = zext i1 [[TMP23]] to i8
// PURECAP-NEXT:    [[TMP24:%.*]] = call i1 @llvm.cheri.cap.subset.test(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i8 addrspace(200)* bitcast (void () addrspace(200)* @test_array to i8 addrspace(200)*))
// PURECAP-NEXT:    [[FROMBOOL2:%.*]] = zext i1 [[TMP24]] to i8
// PURECAP-NEXT:    [[TMP25:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.tag.clear(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP26:%.*]] = bitcast i8 addrspace(200)* [[TMP25]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP27:%.*]] = call i1 @llvm.cheri.cap.tag.get(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[FROMBOOL3:%.*]] = zext i1 [[TMP27]] to i8
// PURECAP-NEXT:    [[TMP28:%.*]] = call i64 @llvm.cheri.cap.type.get.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP29:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.unseal(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i8 addrspace(200)* bitcast (void () addrspace(200)* @test_array to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP30:%.*]] = bitcast i8 addrspace(200)* [[TMP29]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP31:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.conditional.seal(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i8 addrspace(200)* bitcast (void () addrspace(200)* @test_array to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP32:%.*]] = bitcast i8 addrspace(200)* [[TMP31]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP33:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.type.copy(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i8 addrspace(200)* bitcast (void () addrspace(200)* @test_array to i8 addrspace(200)*))
// PURECAP-NEXT:    [[TMP34:%.*]] = bitcast i8 addrspace(200)* [[TMP33]] to void () addrspace(200)*
// PURECAP-NEXT:    [[TMP35:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.build(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i8 addrspace(200)* bitcast (void () addrspace(200)* @test_array to i8 addrspace(200)*))
// PURECAP-NEXT:    call void @llvm.cheri.cap.perms.check.i64(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i64 1)
// PURECAP-NEXT:    call void @llvm.cheri.cap.type.check(i8 addrspace(200)* bitcast (void () addrspace(200)* @test_function to i8 addrspace(200)*), i8 addrspace(200)* bitcast (void () addrspace(200)* @test_array to i8 addrspace(200)*))
// PURECAP-NEXT:    ret void
//
void test_function(void) {
  call_overloaded_builtins(fnptr_t, test_function, test_array);
}

#endif
