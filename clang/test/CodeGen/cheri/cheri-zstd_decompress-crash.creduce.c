// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature
// Check we can lower __builtin_prefetch to LLVM IR in both hybrid and purecap
// RUN: %cheri_cc1 -O0 -emit-llvm -o - %s | FileCheck %s --check-prefixes HYBRID,HYBRID-128
// RUN: %riscv64_cheri_cc1 -O0 -emit-llvm -o - %s | FileCheck %s --check-prefixes=HYBRID,HYBRID-128
// RUN: %riscv32_cheri_cc1 -O0 -emit-llvm -o - %s | FileCheck %s --check-prefixes=HYBRID,HYBRID-64
// RUN: %cheri_purecap_cc1 -O0 -emit-llvm -o - %s | FileCheck %s --check-prefixes PURECAP,PURECAP-128
// RUN: %riscv64_cheri_purecap_cc1 -O0 -emit-llvm -o - %s | FileCheck %s --check-prefixes=PURECAP,PURECAP-128
// RUN: %riscv32_cheri_purecap_cc1 -O0 -emit-llvm -o - %s | FileCheck %s --check-prefixes=PURECAP,PURECAP-64

#define ZSTD_PREFETCH() __builtin_prefetch(0)

// HYBRID-LABEL: define {{[^@]+}}@fn1
// HYBRID-SAME: () #[[ATTR0:[0-9]+]] {
// HYBRID-NEXT:  entry:
// HYBRID-NEXT:    call void @llvm.prefetch.p0i8(i8* null, i32 0, i32 3, i32 1)
// HYBRID-NEXT:    ret i32 0
//
// PURECAP-LABEL: define {{[^@]+}}@fn1
// PURECAP-SAME: () addrspace(200) #[[ATTR0:[0-9]+]] {
// PURECAP-NEXT:  entry:
// PURECAP-NEXT:    call void @llvm.prefetch.p200i8(i8 addrspace(200)* null, i32 0, i32 3, i32 1)
// PURECAP-NEXT:    ret i32 0
//
int fn1(void) {
  ZSTD_PREFETCH();
  return 0;
}

// Another function to check non-null parameter
// HYBRID-128-LABEL: define {{[^@]+}}@prefetch
// HYBRID-128-SAME: (i8* noundef [[ARG:%.*]]) #[[ATTR0]] {
// HYBRID-128-NEXT:  entry:
// HYBRID-128-NEXT:    [[ARG_ADDR:%.*]] = alloca i8*, align 8
// HYBRID-128-NEXT:    store i8* [[ARG]], i8** [[ARG_ADDR]], align 8
// HYBRID-128-NEXT:    [[TMP0:%.*]] = load i8*, i8** [[ARG_ADDR]], align 8
// HYBRID-128-NEXT:    call void @llvm.prefetch.p0i8(i8* [[TMP0]], i32 0, i32 3, i32 1)
// HYBRID-128-NEXT:    ret void
//
// HYBRID-64-LABEL: define {{[^@]+}}@prefetch
// HYBRID-64-SAME: (i8* noundef [[ARG:%.*]]) #[[ATTR0]] {
// HYBRID-64-NEXT:  entry:
// HYBRID-64-NEXT:    [[ARG_ADDR:%.*]] = alloca i8*, align 4
// HYBRID-64-NEXT:    store i8* [[ARG]], i8** [[ARG_ADDR]], align 4
// HYBRID-64-NEXT:    [[TMP0:%.*]] = load i8*, i8** [[ARG_ADDR]], align 4
// HYBRID-64-NEXT:    call void @llvm.prefetch.p0i8(i8* [[TMP0]], i32 0, i32 3, i32 1)
// HYBRID-64-NEXT:    ret void
//
// PURECAP-128-LABEL: define {{[^@]+}}@prefetch
// PURECAP-128-SAME: (i8 addrspace(200)* noundef [[ARG:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-128-NEXT:  entry:
// PURECAP-128-NEXT:    [[ARG_ADDR:%.*]] = alloca i8 addrspace(200)*, align 16, addrspace(200)
// PURECAP-128-NEXT:    store i8 addrspace(200)* [[ARG]], i8 addrspace(200)* addrspace(200)* [[ARG_ADDR]], align 16
// PURECAP-128-NEXT:    [[TMP0:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[ARG_ADDR]], align 16
// PURECAP-128-NEXT:    call void @llvm.prefetch.p200i8(i8 addrspace(200)* [[TMP0]], i32 0, i32 3, i32 1)
// PURECAP-128-NEXT:    ret void
//
// PURECAP-64-LABEL: define {{[^@]+}}@prefetch
// PURECAP-64-SAME: (i8 addrspace(200)* noundef [[ARG:%.*]]) addrspace(200) #[[ATTR0]] {
// PURECAP-64-NEXT:  entry:
// PURECAP-64-NEXT:    [[ARG_ADDR:%.*]] = alloca i8 addrspace(200)*, align 8, addrspace(200)
// PURECAP-64-NEXT:    store i8 addrspace(200)* [[ARG]], i8 addrspace(200)* addrspace(200)* [[ARG_ADDR]], align 8
// PURECAP-64-NEXT:    [[TMP0:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[ARG_ADDR]], align 8
// PURECAP-64-NEXT:    call void @llvm.prefetch.p200i8(i8 addrspace(200)* [[TMP0]], i32 0, i32 3, i32 1)
// PURECAP-64-NEXT:    ret void
//
void prefetch(void* arg) {
  __builtin_prefetch(arg);
}
