; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: %riscv32_cheri_purecap_opt -cheri-bound-allocas -S < %s | FileCheck %s

target datalayout = "e-m:e-pf200:64:64:64:32-p:32:32-i64:64-n32-S128-A200-P200-G200"

declare i8 addrspace(200)* @llvm.cheri.cap.bounds.set(i8 addrspace(200)*, i32)
declare void @use(i8 addrspace(200)*)

;; Check that overflowing a signed pointer index width offset (here, 32-bit)
;; with offset + size is correctly handled rather than regarding the store as
;; in bounds due to the final byte not exceeding the upper bound.
;; TODO: Fix
define void @test_store(i32 %a) {
; CHECK-LABEL: @test_store(
; CHECK-NEXT:    [[TMP1:%.*]] = alloca [4 x i8], align 1, addrspace(200)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast [4 x i8] addrspace(200)* [[TMP1]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i32(i8 addrspace(200)* [[TMP2]], i32 4)
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i8 addrspace(200)* [[TMP3]] to [4 x i8] addrspace(200)*
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast [4 x i8] addrspace(200)* [[TMP4]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, i8 addrspace(200)* [[TMP5]], i32 2147483646
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i8 addrspace(200)* [[TMP6]] to i32 addrspace(200)*
; CHECK-NEXT:    store volatile i32 [[A:%.*]], i32 addrspace(200)* [[TMP7]], align 2
; CHECK-NEXT:    ret void
;
  %1 = alloca [4 x i8], align 1, addrspace(200)
  %2 = bitcast [4 x i8] addrspace(200)* %1 to i8 addrspace(200)*
  %3 = getelementptr i8, i8 addrspace(200)* %2, i32 2147483646
  %4 = bitcast i8 addrspace(200)* %3 to i32 addrspace(200)*
  store volatile i32 %a, i32 addrspace(200)* %4, align 2
  ret void
}

;; Check that overflowing a signed pointer index width offset (here, 32-bit)
;; with offset + size is correctly handled rather than regarding the setbounds
;; as in bounds due to the final byte not exceeding the upper bound.
;; TODO: Fix
define void @test_setbounds(i32 %a) {
; CHECK-LABEL: @test_setbounds(
; CHECK-NEXT:    [[TMP1:%.*]] = alloca [4 x i8], align 1, addrspace(200)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast [4 x i8] addrspace(200)* [[TMP1]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP3:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i32(i8 addrspace(200)* [[TMP2]], i32 4)
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i8 addrspace(200)* [[TMP3]] to [4 x i8] addrspace(200)*
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast [4 x i8] addrspace(200)* [[TMP4]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, i8 addrspace(200)* [[TMP5]], i32 2147483646
; CHECK-NEXT:    [[TMP7:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i32(i8 addrspace(200)* [[TMP6]], i32 4)
; CHECK-NEXT:    call void @use(i8 addrspace(200)* [[TMP7]])
; CHECK-NEXT:    ret void
;
  %1 = alloca [4 x i8], align 1, addrspace(200)
  %2 = bitcast [4 x i8] addrspace(200)* %1 to i8 addrspace(200)*
  %3 = getelementptr i8, i8 addrspace(200)* %2, i32 2147483646
  %4 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set(i8 addrspace(200)* %3, i32 4)
  call void @use(i8 addrspace(200)* %4)
  ret void
}
