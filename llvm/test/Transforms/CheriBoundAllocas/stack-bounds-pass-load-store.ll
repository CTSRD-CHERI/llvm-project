; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --force-update
; The new CheriBoundedStackPseudo instruction lets us pretend that the incoffset+csetbounds
; is a single trivially rematerizable instruction so it can freely move it around to avoid stack spills.
; we were moving the allocation of the register that is only used later to the beginning

; REQUIRES: asserts,mips-registered-target,riscv-registered-target
; RUN: %cheri_purecap_opt -cheri-bound-allocas %s -o - -S -cheri-stack-bounds=if-needed -debug-only=cheri-bound-allocas 2>%t.dbg | FileCheck %s
; RUN: FileCheck %s -input-file=%t.dbg --check-prefixes=DBG,DBG-TYPED
; RUN: %cheri_purecap_opt -opaque-pointers=1 -instsimplify -cheri-bound-allocas %s -o - -S -cheri-stack-bounds=if-needed -debug-only=cheri-bound-allocas 2>%t.dbg | FileCheck %s --check-prefix=OPAQUE
; RUN: FileCheck %s -input-file=%t.dbg --check-prefixes=DBG,DBG-OPAQUE

target datalayout = "Eme-pf200:128:128:128:64-A200-P200-G200"

@global_leak = addrspace(200) global [16 x i32] addrspace(200)* zeroinitializer, align 16
@global_leak2 = addrspace(200) global i8 addrspace(200)* zeroinitializer, align 16


define void @store_stack_to_global() addrspace(200) nounwind {
; CHECK-LABEL: @store_stack_to_global(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [16 x i32] addrspace(200)* [[X]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i64(i8 addrspace(200)* [[TMP0]], i64 64)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to [16 x i32] addrspace(200)*
; CHECK-NEXT:    store [16 x i32] addrspace(200)* [[TMP2]], [16 x i32] addrspace(200)* addrspace(200)* @global_leak, align 16
; CHECK-NEXT:    ret void
;
; OPAQUE-LABEL: @store_stack_to_global(
; OPAQUE-NEXT:  entry:
; OPAQUE-NEXT:    [[X:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; OPAQUE-NEXT:    [[TMP0:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[X]], i64 64)
; OPAQUE-NEXT:    store ptr addrspace(200) [[TMP0]], ptr addrspace(200) @global_leak, align 16
; OPAQUE-NEXT:    ret void
;
entry:
  %x = alloca [16 x i32], align 4, addrspace(200)
  store [16 x i32] addrspace(200)* %x, [16 x i32] addrspace(200)* addrspace(200)* @global_leak, align 16
  ret void
}

; DBG-LABEL: Checking function store_stack_to_global
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store
; DBG-TYPED-SAME: [16 x i32] addrspace(200)* %x, [16 x i32] addrspace(200)* addrspace(200)* @global_leak, align 16
; DBG-OPAQUE-SAME: ptr addrspace(200) %x, ptr addrspace(200) @global_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Stack slot used as value and not pointer -> must set bounds
; DBG-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:
; DBG-TYPED-SAME:   store [16 x i32] addrspace(200)* %x, [16 x i32] addrspace(200)* addrspace(200)* @global_leak, align 16
; DBG-OPAQUE-SAME:  store ptr addrspace(200) %x, ptr addrspace(200) @global_leak, align 16
; DBG-NEXT: cheri-bound-allocas: store_stack_to_global: 1 of 1 users need bounds for   %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: store_stack_to_global: setting bounds on stack alloca to 64  %x = alloca [16 x i32], align 4, addrspace(200)

define void @store_stack_to_global_with_offset() addrspace(200) nounwind {
; CHECK-LABEL: @store_stack_to_global_with_offset(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [16 x i32] addrspace(200)* [[X]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i64(i8 addrspace(200)* [[TMP0]], i64 64)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to [16 x i32] addrspace(200)*
; CHECK-NEXT:    [[X_I8:%.*]] = bitcast [16 x i32] addrspace(200)* [[TMP2]] to i8 addrspace(200)*
; CHECK-NEXT:    [[X_PLUS_4:%.*]] = getelementptr inbounds i8, i8 addrspace(200)* [[X_I8]], i32 4
; CHECK-NEXT:    store i8 addrspace(200)* [[X_PLUS_4]], i8 addrspace(200)* addrspace(200)* @global_leak2, align 16
; CHECK-NEXT:    ret void
;
; OPAQUE-LABEL: @store_stack_to_global_with_offset(
; OPAQUE-NEXT:  entry:
; OPAQUE-NEXT:    [[X:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; OPAQUE-NEXT:    [[TMP0:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[X]], i64 64)
; OPAQUE-NEXT:    [[X_PLUS_4:%.*]] = getelementptr inbounds i8, ptr addrspace(200) [[TMP0]], i32 4
; OPAQUE-NEXT:    store ptr addrspace(200) [[X_PLUS_4]], ptr addrspace(200) @global_leak2, align 16
; OPAQUE-NEXT:    ret void
;
entry:
  %x = alloca [16 x i32], align 4, addrspace(200)
  %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
  %x_plus_4 = getelementptr inbounds i8, i8 addrspace(200)* %x_i8, i32 4
  store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* @global_leak2, align 16
  ret void
}

; DBG-LABEL: Checking function store_stack_to_global_with_offset
; DBG-TYPED-NEXT: cheri-bound-allocas:  -Checking if bitcast needs stack bounds:   %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
; DBG-NEXT:       cheri-bound-allocas:   -Checking if getelementptr needs stack bounds:   %x_plus_4 = getelementptr inbounds i8, {{.+}} [[X_I8:%x(_i8)?]], i32 4
; DBG-NEXT:       cheri-bound-allocas:    -Checking if load/store needs bounds (GEP offset is 4):   store {{.+}} %x_plus_4, {{.+}} @global_leak2, align 16
; DBG-NEXT:       cheri-bound-allocas:     -Stack slot used as value and not pointer -> must set bounds
; DBG-NEXT:       cheri-bound-allocas:   -Adding stack bounds since getelementptr user needs bounds:   store {{.+}} %x_plus_4, {{.+}} @global_leak2, align 16
; DBG-TYPED-NEXT: cheri-bound-allocas:  -Adding stack bounds since bitcast user needs bounds:   %x_plus_4 = getelementptr inbounds i8, i8 addrspace(200)* %x_i8, i32 4
; DBG-TYPED-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:   %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
; DBG-OPAQUE-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:   %x_plus_4 = getelementptr inbounds i8, ptr addrspace(200) %x, i32 4
; DBG-NEXT: cheri-bound-allocas: store_stack_to_global_with_offset: 1 of 1 users need bounds for   %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: store_stack_to_global_with_offset: setting bounds on stack alloca to 64  %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-EMPTY:

define [16 x i32] addrspace(200)* @store_stack_to_other_slot() addrspace(200) nounwind {
; CHECK-LABEL: @store_stack_to_other_slot(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[SLOT_SRC:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; CHECK-NEXT:    [[SLOT_LEAK:%.*]] = alloca [16 x i32] addrspace(200)*, align 16, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [16 x i32] addrspace(200)* [[SLOT_SRC]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i64(i8 addrspace(200)* [[TMP0]], i64 64)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to [16 x i32] addrspace(200)*
; CHECK-NEXT:    store [16 x i32] addrspace(200)* [[TMP2]], [16 x i32] addrspace(200)* addrspace(200)* [[SLOT_LEAK]], align 16
; CHECK-NEXT:    [[LEAKED_VALUE:%.*]] = load [16 x i32] addrspace(200)*, [16 x i32] addrspace(200)* addrspace(200)* [[SLOT_LEAK]], align 16
; CHECK-NEXT:    ret [16 x i32] addrspace(200)* [[LEAKED_VALUE]]
;
; OPAQUE-LABEL: @store_stack_to_other_slot(
; OPAQUE-NEXT:  entry:
; OPAQUE-NEXT:    [[SLOT_SRC:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; OPAQUE-NEXT:    [[SLOT_LEAK:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
; OPAQUE-NEXT:    [[TMP0:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[SLOT_SRC]], i64 64)
; OPAQUE-NEXT:    store ptr addrspace(200) [[TMP0]], ptr addrspace(200) [[SLOT_LEAK]], align 16
; OPAQUE-NEXT:    [[LEAKED_VALUE:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[SLOT_LEAK]], align 16
; OPAQUE-NEXT:    ret ptr addrspace(200) [[LEAKED_VALUE]]
;
entry:
  %slot_src = alloca [16 x i32], align 4, addrspace(200)
  %slot_leak = alloca [16 x i32] addrspace(200)*, align 16, addrspace(200)
  store [16 x i32] addrspace(200)* %slot_src, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
  %leaked_value = load [16 x i32] addrspace(200)*, [16 x i32] addrspace(200)* addrspace(200)* %slot_leak, align 16
  ret [16 x i32] addrspace(200)* %leaked_value
}

; DBG-LABEL: Checking function store_stack_to_other_slot
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store {{.+}} %slot_src, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Stack slot used as value and not pointer -> must set bounds
; DBG-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:   store {{.+}} %slot_src, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas: store_stack_to_other_slot: 1 of 1 users need bounds for   %slot_src = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: store_stack_to_other_slot: setting bounds on stack alloca to 64  %slot_src = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   %leaked_value = load {{.+}}, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for {{.+}}
; DBG-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   %leaked_value = load {{.+}}, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store {{.+}} %{{[0-9]+}}, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for {{.+}}
; DBG-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   store {{.+}} %{{[0-9]+}}, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas: store_stack_to_other_slot: 0 of 2 users need bounds for   %slot_leak = alloca {{.+}}, align 16, addrspace(200)
; DBG-NEXT: cheri-bound-allocas: No need to set bounds on stack alloca  %slot_leak = alloca {{.+}}, align 16, addrspace(200)

define i8 addrspace(200)* @store_stack_to_other_slot_with_offset() addrspace(200) nounwind {
; CHECK-LABEL: @store_stack_to_other_slot_with_offset(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [16 x i32] addrspace(200)* [[X]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i64(i8 addrspace(200)* [[TMP0]], i64 64)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to [16 x i32] addrspace(200)*
; CHECK-NEXT:    [[X_I8:%.*]] = bitcast [16 x i32] addrspace(200)* [[TMP2]] to i8 addrspace(200)*
; CHECK-NEXT:    [[X_PLUS_4:%.*]] = getelementptr inbounds i8, i8 addrspace(200)* [[X_I8]], i32 4
; CHECK-NEXT:    [[SLOT_LEAK:%.*]] = alloca i8 addrspace(200)*, align 16, addrspace(200)
; CHECK-NEXT:    store i8 addrspace(200)* [[X_PLUS_4]], i8 addrspace(200)* addrspace(200)* [[SLOT_LEAK]], align 16
; CHECK-NEXT:    [[LEAKED_VALUE:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[SLOT_LEAK]], align 16
; CHECK-NEXT:    ret i8 addrspace(200)* [[LEAKED_VALUE]]
;
; OPAQUE-LABEL: @store_stack_to_other_slot_with_offset(
; OPAQUE-NEXT:  entry:
; OPAQUE-NEXT:    [[X:%.*]] = alloca [16 x i32], align 4, addrspace(200)
; OPAQUE-NEXT:    [[TMP0:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[X]], i64 64)
; OPAQUE-NEXT:    [[X_PLUS_4:%.*]] = getelementptr inbounds i8, ptr addrspace(200) [[TMP0]], i32 4
; OPAQUE-NEXT:    [[SLOT_LEAK:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
; OPAQUE-NEXT:    store ptr addrspace(200) [[X_PLUS_4]], ptr addrspace(200) [[SLOT_LEAK]], align 16
; OPAQUE-NEXT:    [[LEAKED_VALUE:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[SLOT_LEAK]], align 16
; OPAQUE-NEXT:    ret ptr addrspace(200) [[LEAKED_VALUE]]
;
entry:
  %x = alloca [16 x i32], align 4, addrspace(200)
  %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
  %x_plus_4 = getelementptr inbounds i8, i8 addrspace(200)* %x_i8, i32 4
  %slot_leak = alloca i8 addrspace(200)*, align 16, addrspace(200)
  store i8 addrspace(200)* %x_plus_4, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
  %leaked_value = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* %slot_leak, align 16
  ret i8 addrspace(200)* %leaked_value
}

; DBG-LABEL: Checking function store_stack_to_other_slot_with_offset
; DBG-TYPED-NEXT: cheri-bound-allocas:  -Checking if bitcast needs stack bounds:   %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
; DBG-NEXT: cheri-bound-allocas:   -Checking if getelementptr needs stack bounds:   %x_plus_4 = getelementptr inbounds i8, {{.+}} [[X_I8:%x(_i8)?]], i32 4
; DBG-NEXT: cheri-bound-allocas:    -Checking if load/store needs bounds (GEP offset is 4):   store {{.+}} %x_plus_4, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:     -Stack slot used as value and not pointer -> must set bounds
; DBG-NEXT: cheri-bound-allocas:   -Adding stack bounds since getelementptr user needs bounds:   store {{.+}} %x_plus_4, {{.+}} %slot_leak, align 16
; DBG-TYPED-NEXT: cheri-bound-allocas:  -Adding stack bounds since bitcast user needs bounds:   %x_plus_4 = getelementptr inbounds i8, {{.+}} [[X_I8]], i32 4
; DBG-TYPED-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:   %x_i8 = bitcast [16 x i32] addrspace(200)* %x to i8 addrspace(200)*
; DBG-OPAQUE-NEXT: cheri-bound-allocas: Found alloca use that needs bounds: %x_plus_4 = getelementptr inbounds i8, ptr addrspace(200) %x, i32 4
; DBG-NEXT: cheri-bound-allocas: store_stack_to_other_slot_with_offset: 1 of 1 users need bounds for   %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: store_stack_to_other_slot_with_offset: setting bounds on stack alloca to 64  %x = alloca [16 x i32], align 4, addrspace(200)
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   %leaked_value = load {{.+}}, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for {{.+}}
; DBG-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   %leaked_value = load {{.+}}, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store {{.+}} %x_plus_4, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for {{.+}}
; DBG-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   store {{.+}} %x_plus_4, {{.+}} %slot_leak, align 16
; DBG-NEXT: cheri-bound-allocas: store_stack_to_other_slot_with_offset: 0 of 2 users need bounds for   %slot_leak = alloca {{.+}}, align 16, addrspace(200)
; DBG-NEXT: cheri-bound-allocas: No need to set bounds on stack alloca  %slot_leak = alloca {{.+}}, align 16, addrspace(200)


; This is a regression test for opaque pointers breaking the "is value being stored" analysis
define i8 addrspace(200)* @store_stack_to_self() addrspace(200) nounwind {
; CHECK-LABEL: @store_stack_to_self(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[SLOT_SELF:%.*]] = alloca i8 addrspace(200)*, align 16, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i8 addrspace(200)* addrspace(200)* [[SLOT_SELF]] to i8 addrspace(200)*
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.bounded.stack.cap.i64(i8 addrspace(200)* [[TMP0]], i64 16)
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i8 addrspace(200)* addrspace(200)*
; CHECK-NEXT:    [[LEAK:%.*]] = bitcast i8 addrspace(200)* addrspace(200)* [[TMP2]] to i8 addrspace(200)*
; CHECK-NEXT:    store i8 addrspace(200)* [[LEAK]], i8 addrspace(200)* addrspace(200)* [[SLOT_SELF]], align 16
; CHECK-NEXT:    [[LEAKED_VALUE:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[SLOT_SELF]], align 16
; CHECK-NEXT:    ret i8 addrspace(200)* [[LEAKED_VALUE]]
;
; OPAQUE-LABEL: @store_stack_to_self(
; OPAQUE-NEXT:  entry:
; OPAQUE-NEXT:    [[SLOT_SELF:%.*]] = alloca ptr addrspace(200), align 16, addrspace(200)
; OPAQUE-NEXT:    [[TMP0:%.*]] = call ptr addrspace(200) @llvm.cheri.bounded.stack.cap.i64(ptr addrspace(200) [[SLOT_SELF]], i64 16)
; OPAQUE-NEXT:    store ptr addrspace(200) [[TMP0]], ptr addrspace(200) [[SLOT_SELF]], align 16
; OPAQUE-NEXT:    [[LEAKED_VALUE:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[SLOT_SELF]], align 16
; OPAQUE-NEXT:    ret ptr addrspace(200) [[LEAKED_VALUE]]
;
entry:
  %slot_self = alloca i8 addrspace(200)*, align 16, addrspace(200)
  %leak = bitcast i8 addrspace(200)* addrspace(200)* %slot_self to i8 addrspace(200)*
  store i8 addrspace(200)* %leak, i8 addrspace(200)* addrspace(200)* %slot_self, align 16
  %leaked_value = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* %slot_self, align 16
  ret i8 addrspace(200)* %leaked_value
}

; DBG-LABEL: Checking function store_stack_to_self
; DBG-TYPED-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   %leaked_value = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* %slot_self, align 16
; DBG-TYPED-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for i8 addrspace(200)*
; DBG-TYPED-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   %leaked_value = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* %slot_self, align 16
; DBG-TYPED-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store i8 addrspace(200)* %leak, i8 addrspace(200)* addrspace(200)* %slot_self, align 16
; DBG-TYPED-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for i8 addrspace(200)*
; DBG-TYPED-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   store i8 addrspace(200)* %leak, i8 addrspace(200)* addrspace(200)* %slot_self, align 16
; DBG-TYPED-NEXT: cheri-bound-allocas:  -Checking if bitcast needs stack bounds:   %leak = bitcast i8 addrspace(200)* addrspace(200)* %slot_self to i8 addrspace(200)*
; DBG-TYPED-NEXT: cheri-bound-allocas:   -Checking if load/store needs bounds (GEP offset is 0):   store i8 addrspace(200)* %leak, i8 addrspace(200)* addrspace(200)* %slot_self, align 16
; DBG-TYPED-NEXT: cheri-bound-allocas:    -Stack slot used as value and not pointer -> must set bounds
; DBG-TYPED-NEXT: cheri-bound-allocas:  -Adding stack bounds since bitcast user needs bounds:   store i8 addrspace(200)* %leak, i8 addrspace(200)* addrspace(200)* %slot_self, align 16
; DBG-TYPED-NEXT: cheri-bound-allocas: Found alloca use that needs bounds: %leak = bitcast i8 addrspace(200)* addrspace(200)* %slot_self to i8 addrspace(200)*
; DBG-OPAQUE-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store ptr addrspace(200) %slot_self, ptr addrspace(200) %slot_self, align 16
; DBG-OPAQUE-NEXT: cheri-bound-allocas:   -Stack slot used as value and not pointer -> must set bounds
; DBG-OPAQUE-NEXT: cheri-bound-allocas: Found alloca use that needs bounds:   store ptr addrspace(200) %slot_self, ptr addrspace(200) %slot_self, align 16
; DBG-OPAQUE-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   %leaked_value = load ptr addrspace(200), ptr addrspace(200) %slot_self, align 16
; DBG-OPAQUE-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for ptr addrspace(200)
; DBG-OPAQUE-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   %leaked_value = load ptr addrspace(200), ptr addrspace(200) %slot_self, align 16
; DBG-OPAQUE-NEXT: cheri-bound-allocas:  -Checking if load/store needs bounds (GEP offset is 0):   store ptr addrspace(200) %slot_self, ptr addrspace(200) %slot_self, align 16
; DBG-OPAQUE-NEXT: cheri-bound-allocas:   -Load/store size=16, alloca size=16, current GEP offset=0 for ptr addrspace(200)
; DBG-OPAQUE-NEXT: cheri-bound-allocas:   -Load/store is in bounds -> can reuse $csp for   store ptr addrspace(200) %slot_self, ptr addrspace(200) %slot_self, align 16
; DBG-NEXT: cheri-bound-allocas: store_stack_to_self: 1 of 3 users need bounds for   %slot_self = alloca {{.+}}, align 16, addrspace(200)
; DBG-NEXT: store_stack_to_self: setting bounds on stack alloca to 16  %slot_self = alloca {{.+}}, align 16, addrspace(200)
