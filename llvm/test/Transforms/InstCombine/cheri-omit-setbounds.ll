; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUNnot: opt -passes=instcombine -S %s -o - -debug-only=instcombine
; RUN: opt -passes=instcombine -S %s -o - | FileCheck %s -check-prefixes CHECK
; RUNnot: %cheri_purecap_llc %s -o -
target datalayout = "E-m:e-pf200:128:128:128:64-i8:8:32-i16:16:32-i64:64-n32:64-S128-A200-P200-G200"
target triple = "cheri-unknown-freebsd"

declare i64 @llvm.cheri.cap.diff.i64(i8 addrspace(200)*, i8 addrspace(200)*) addrspace(200) #1
declare i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)*, i64) addrspace(200) #1
declare i8 addrspace(200)* @llvm.cheri.cap.bounds.set.exact.i64(i8 addrspace(200)*, i64) addrspace(200) #1
declare i8 addrspace(200)* @llvm.cheri.cap.address.set.i64(i8 addrspace(200)*, i64) addrspace(200) #1

declare void @use(i8 addrspace(200)*) addrspace(200) #1


define signext i32 @stack_int_inlined() local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @stack_int_inlined(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    ret i32 2
;
entry:
  %value = alloca i32, align 4, addrspace(200)
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 4)
  %address.with.bounds = bitcast i8 addrspace(200)* %1 to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %2 = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %2
}

; Can't omit the bounds here:
define signext i32 @stack_int_inlined_escapes() local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @stack_int_inlined_escapes(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VALUE:%.*]] = alloca i32, align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[VALUE]] to i8 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 4)
; CHECK-NEXT:    call void @use(i8 addrspace(200)* nonnull [[TMP1]])
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 2
;
entry:
  %value = alloca i32, align 4, addrspace(200)
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 4)
  call void @use(i8 addrspace(200)* nonnull %1)
  %address.with.bounds = bitcast i8 addrspace(200)* %1 to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %2 = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %2
}

; Can omit bounds here since we know the original size
define signext i32 @used_by_smaller_setbounds() local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @used_by_smaller_setbounds(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VALUE:%.*]] = alloca i32, align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[VALUE]] to i8 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 4)
; CHECK-NEXT:    call void @use(i8 addrspace(200)* nonnull [[TMP1]])
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 2
;
entry:
  %value = alloca i32, align 4, addrspace(200)
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 4)
  call void @use(i8 addrspace(200)* nonnull %1)
  %address.with.bounds = bitcast i8 addrspace(200)* %1 to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %2 = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %2
}

; Must set bounds here since we would trap:
define signext i32 @used_by_out_of_bounds_load() local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @used_by_out_of_bounds_load(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VALUE:%.*]] = alloca i32, align 4, addrspace(200)
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[VALUE]] to i8 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 3)
; CHECK-NEXT:    [[ADDRESS_WITH_BOUNDS:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[ADDRESS_WITH_BOUNDS]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 [[TMP2]]
;
entry:
  %value = alloca i32, align 4, addrspace(200)
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 3) ; 3 < 4 -> load will trap
  %address.with.bounds = bitcast i8 addrspace(200)* %1 to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %2 = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %2
}

define signext i32 @bounded_arg(i32 addrspace(200)* %value) local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @bounded_arg(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[VALUE:%.*]] to i8 addrspace(200)*
; CHECK-NEXT:    [[LARGE_BOUNDS:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 8)
; CHECK-NEXT:    [[SMALL_BITCAST:%.*]] = bitcast i8 addrspace(200)* [[LARGE_BOUNDS]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[SMALL_BITCAST]], align 4
; CHECK-NEXT:    [[RESULT:%.*]] = load i32, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 [[RESULT]]
;
entry:
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  %large_bounds = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 8)
  %large_bitcast = bitcast i8 addrspace(200)* %large_bounds to i32 addrspace(200)*
  store i32 1, i32 addrspace(200)* %large_bitcast, align 4
  %small_bounds = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %large_bounds, i64 4)
  %small_bitcast = bitcast i8 addrspace(200)* %small_bounds to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %small_bitcast, align 4
  %result = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %result
}

define signext i32 @bounded_arg_too_small(i32 addrspace(200)* %value) local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @bounded_arg_too_small(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[VALUE:%.*]] to i8 addrspace(200)*
; CHECK-NEXT:    [[LARGE_BOUNDS:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 3)
; CHECK-NEXT:    [[LARGE_BITCAST:%.*]] = bitcast i8 addrspace(200)* [[LARGE_BOUNDS]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[LARGE_BITCAST]], align 4
; CHECK-NEXT:    [[SMALL_BOUNDS:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[LARGE_BOUNDS]], i64 4)
; CHECK-NEXT:    [[SMALL_BITCAST:%.*]] = bitcast i8 addrspace(200)* [[SMALL_BOUNDS]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[SMALL_BITCAST]], align 4
; CHECK-NEXT:    [[RESULT:%.*]] = load i32, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 [[RESULT]]
;
entry:
  %0 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  %large_bounds = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 3)
  %large_bitcast = bitcast i8 addrspace(200)* %large_bounds to i32 addrspace(200)*
  store i32 1, i32 addrspace(200)* %large_bitcast, align 4
  %small_bounds = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %large_bounds, i64 4)
  %small_bitcast = bitcast i8 addrspace(200)* %small_bounds to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %small_bitcast, align 4
  %result = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %result
}


; Here we know that the final store is within the bounds of the setbounds(5) so we can use the source value (setbounds(10)) instead
define signext i32 @csetbounds_sequence(i32 addrspace(200)* %value) local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @csetbounds_sequence(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[I8:%.*]] = bitcast i32 addrspace(200)* [[VALUE:%.*]] to i8 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[I8]], i64 10)
; CHECK-NEXT:    [[ADDRESS_WITH_BOUNDS:%.*]] = bitcast i8 addrspace(200)* [[TMP0]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[ADDRESS_WITH_BOUNDS]], align 4
; CHECK-NEXT:    [[RESULT:%.*]] = load i32, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 [[RESULT]]
;
entry:
  %i8 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %0 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %i8, i64 10)
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 9)
  %2 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %1, i64 8)
  %3 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %2, i64 7)
  %4 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %3, i64 6)
  %final_bounded_value = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %4, i64 5)
  %address.with.bounds = bitcast i8 addrspace(200)* %final_bounded_value to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %result = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %result
}


; However, we can't if the store is OOB: now we need the original (largest) setbounds and the one at the end.
; We don't remove the first one since the check if there are at least 10 bytes accessible might be intentional.
; TODO: could probably remove csetbounds(10) and just do csetbounds(3) since the resulting value is never used...
define signext i32 @csetbounds_sequence_oob(i32 addrspace(200)* %value) local_unnamed_addr addrspace(200) #5 {
; CHECK-LABEL: @csetbounds_sequence_oob(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[I8:%.*]] = bitcast i32 addrspace(200)* [[VALUE:%.*]] to i8 addrspace(200)*
; CHECK-NEXT:    store i32 1, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[I8]], i64 10)
; CHECK-NEXT:    [[FINAL_BOUNDED_VALUE:%.*]] = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 3)
; CHECK-NEXT:    [[ADDRESS_WITH_BOUNDS:%.*]] = bitcast i8 addrspace(200)* [[FINAL_BOUNDED_VALUE]] to i32 addrspace(200)*
; CHECK-NEXT:    store i32 2, i32 addrspace(200)* [[ADDRESS_WITH_BOUNDS]], align 4
; CHECK-NEXT:    [[RESULT:%.*]] = load i32, i32 addrspace(200)* [[VALUE]], align 4
; CHECK-NEXT:    ret i32 [[RESULT]]
;
entry:
  %i8 = bitcast i32 addrspace(200)* %value to i8 addrspace(200)*
  store i32 1, i32 addrspace(200)* %value, align 4
  %0 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %i8, i64 10)
  %1 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 9)
  %2 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %1, i64 8)
  %3 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %2, i64 7)
  %4 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %3, i64 6)
  %5 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %4, i64 5)
  %6 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %5, i64 4)
  %final_bounded_value = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %6, i64 3)
  %address.with.bounds = bitcast i8 addrspace(200)* %final_bounded_value to i32 addrspace(200)*
  store i32 2, i32 addrspace(200)* %address.with.bounds, align 4
  %result = load i32, i32 addrspace(200)* %value, align 4
  ret i32 %result
}
