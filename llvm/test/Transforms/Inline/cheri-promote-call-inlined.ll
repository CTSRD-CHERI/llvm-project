; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes
; When compiling for purecap C++, Clang misses many opportunities to devirtualize calls via pointers to members.
; The equivalent code for hybrid correctly converts both functions to ret 1/2 just in calling the inliner pass.
; This is most likely a problem in Transforms/Utils/CloneFunction.cpp that fails to simplify the purecap
; pointer-to-member call (possibly because of the @llvm.cheri.cap.address.get.i64 call).
; Test case is based on clang/test/CodeGenCXX/member-function-pointer-calls.cpp
; RUN: opt -enable-new-pm=1 -S "-passes=cgscc(inline)" < %s | FileCheck %s --check-prefixes=INLINE-ONLY
; The -O2 pipeline eventually manages to devirtualize the second call but misses the first one:
; RUN: opt -enable-new-pm=1 -S "-passes=default<O2>" < %s | FileCheck %s --check-prefixes=FULL
target datalayout = "e-m:e-pf200:128:128:128:64-p:64:64-i64:64-i128:128-n64-S128-A200-P200-G200"
target triple = "riscv64-unknown-freebsd"

%struct.A = type { i64 (...) addrspace(200)* addrspace(200)* }
@_ZTV1A = private unnamed_addr addrspace(200) constant { [4 x i8 addrspace(200)*] } { [4 x i8 addrspace(200)*]
  [ i8 addrspace(200)* null,
  i8 addrspace(200)* bitcast ({ i8 addrspace(200)*, i8 addrspace(200)* } addrspace(200)* @_ZTI1A to i8 addrspace(200)*),
  i8 addrspace(200)* bitcast (i64 (%struct.A addrspace(200)*) addrspace(200)* @member_function_1 to i8 addrspace(200)*),
  i8 addrspace(200)* bitcast (i64 (%struct.A addrspace(200)*) addrspace(200)* @member_function_2 to i8 addrspace(200)*)
  ] }, align 16
@_ZTI1A = external addrspace(200) constant { i8 addrspace(200)*, i8 addrspace(200)* }, align 16

declare i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)*)

define internal i64 @call_member_fn_ptr_indirect_arg(%struct.A addrspace(200)* %a, { i8 addrspace(200)*, i64 } addrspace(200)* %0) {
entry:
  %fp = load { i8 addrspace(200)*, i64 }, { i8 addrspace(200)*, i64 } addrspace(200)* %0, align 16
  %memptr.adj = extractvalue { i8 addrspace(200)*, i64 } %fp, 1
  %1 = bitcast %struct.A addrspace(200)* %a to i8 addrspace(200)*
  %2 = getelementptr inbounds i8, i8 addrspace(200)* %1, i64 %memptr.adj
  %this.adjusted = bitcast i8 addrspace(200)* %2 to %struct.A addrspace(200)*
  %memptr.ptr = extractvalue { i8 addrspace(200)*, i64 } %fp, 0
  %memptr.ptr.addr = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* %memptr.ptr)
  %3 = and i64 %memptr.ptr.addr, 1
  %memptr.isvirtual = icmp ne i64 %3, 0
  br i1 %memptr.isvirtual, label %memptr.virtual, label %memptr.nonvirtual

memptr.virtual:                                   ; preds = %entry
  %4 = bitcast i8 addrspace(200)* %2 to i8 addrspace(200)* addrspace(200)*
  %vtable = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* %4, align 16
  %memptr.vtable.offset = ptrtoint i8 addrspace(200)* %memptr.ptr to i64
  %5 = sub i64 %memptr.vtable.offset, 1
  %6 = getelementptr i8, i8 addrspace(200)* %vtable, i64 %5
  %7 = bitcast i8 addrspace(200)* %6 to i64 (%struct.A addrspace(200)*) addrspace(200)* addrspace(200)*
  %memptr.virtualfn = load i64 (%struct.A addrspace(200)*) addrspace(200)*, i64 (%struct.A addrspace(200)*) addrspace(200)* addrspace(200)* %7, align 16
  br label %memptr.end

memptr.nonvirtual:                                ; preds = %entry
  %memptr.nonvirtualfn = bitcast i8 addrspace(200)* %memptr.ptr to i64 (%struct.A addrspace(200)*) addrspace(200)*
  br label %memptr.end

memptr.end:                                       ; preds = %memptr.nonvirtual, %memptr.virtual
  %8 = phi i64 (%struct.A addrspace(200)*) addrspace(200)* [ %memptr.virtualfn, %memptr.virtual ], [ %memptr.nonvirtualfn, %memptr.nonvirtual ]
  %call = call i64 %8(%struct.A addrspace(200)* nonnull align 16 dereferenceable(16) %this.adjusted)
  ret i64 %call
}


define dso_local i64 @call_f1_via_member_ptr() {
; INLINE-ONLY-LABEL: define {{[^@]+}}@call_f1_via_member_ptr() addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    [[A:%.*]] = alloca [[STRUCT_A:%.*]], align 16, addrspace(200)
; INLINE-ONLY-NEXT:    [[INDIRECT_ARG_TEMP:%.*]] = alloca { i8 addrspace(200)*, i64 }, align 16, addrspace(200)
; INLINE-ONLY-NEXT:    [[TMP0:%.*]] = bitcast [[STRUCT_A]] addrspace(200)* [[A]] to i64 (...) addrspace(200)* addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    store i64 (...) addrspace(200)* addrspace(200)* bitcast (i8 addrspace(200)* addrspace(200)* getelementptr inbounds ({ [4 x i8 addrspace(200)*] }, { [4 x i8 addrspace(200)*] } addrspace(200)* @_ZTV1A, i32 0, inrange i32 0, i32 2) to i64 (...) addrspace(200)* addrspace(200)*), i64 (...) addrspace(200)* addrspace(200)* addrspace(200)* [[TMP0]], align 16
; INLINE-ONLY-NEXT:    store { i8 addrspace(200)*, i64 } { i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 1), i64 0 }, { i8 addrspace(200)*, i64 } addrspace(200)* [[INDIRECT_ARG_TEMP]], align 16
; INLINE-ONLY-NEXT:    [[FP_I:%.*]] = load { i8 addrspace(200)*, i64 }, { i8 addrspace(200)*, i64 } addrspace(200)* [[INDIRECT_ARG_TEMP]], align 16
; INLINE-ONLY-NEXT:    [[MEMPTR_ADJ_I:%.*]] = extractvalue { i8 addrspace(200)*, i64 } [[FP_I]], 1
; INLINE-ONLY-NEXT:    [[TMP1:%.*]] = bitcast [[STRUCT_A]] addrspace(200)* [[A]] to i8 addrspace(200)*
; INLINE-ONLY-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, i8 addrspace(200)* [[TMP1]], i64 [[MEMPTR_ADJ_I]]
; INLINE-ONLY-NEXT:    [[THIS_ADJUSTED_I:%.*]] = bitcast i8 addrspace(200)* [[TMP2]] to [[STRUCT_A]] addrspace(200)*
; INLINE-ONLY-NEXT:    [[MEMPTR_PTR_I:%.*]] = extractvalue { i8 addrspace(200)*, i64 } [[FP_I]], 0
; INLINE-ONLY-NEXT:    [[MEMPTR_PTR_ADDR_I:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[MEMPTR_PTR_I]])
; INLINE-ONLY-NEXT:    [[TMP3:%.*]] = and i64 [[MEMPTR_PTR_ADDR_I]], 1
; INLINE-ONLY-NEXT:    [[MEMPTR_ISVIRTUAL_I:%.*]] = icmp ne i64 [[TMP3]], 0
; INLINE-ONLY-NEXT:    br i1 [[MEMPTR_ISVIRTUAL_I]], label [[MEMPTR_VIRTUAL_I:%.*]], label [[MEMPTR_NONVIRTUAL_I:%.*]]
; INLINE-ONLY:       memptr.virtual.i:
; INLINE-ONLY-NEXT:    [[TMP4:%.*]] = bitcast i8 addrspace(200)* [[TMP2]] to i8 addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    [[VTABLE_I:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[TMP4]], align 16
; INLINE-ONLY-NEXT:    [[MEMPTR_VTABLE_OFFSET_I:%.*]] = ptrtoint i8 addrspace(200)* [[MEMPTR_PTR_I]] to i64
; INLINE-ONLY-NEXT:    [[TMP5:%.*]] = sub i64 [[MEMPTR_VTABLE_OFFSET_I]], 1
; INLINE-ONLY-NEXT:    [[TMP6:%.*]] = getelementptr i8, i8 addrspace(200)* [[VTABLE_I]], i64 [[TMP5]]
; INLINE-ONLY-NEXT:    [[TMP7:%.*]] = bitcast i8 addrspace(200)* [[TMP6]] to i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    [[MEMPTR_VIRTUALFN_I:%.*]] = load i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)*, i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* addrspace(200)* [[TMP7]], align 16
; INLINE-ONLY-NEXT:    br label [[CALL_MEMBER_FN_PTR_INDIRECT_ARG_EXIT:%.*]]
; INLINE-ONLY:       memptr.nonvirtual.i:
; INLINE-ONLY-NEXT:    [[MEMPTR_NONVIRTUALFN_I:%.*]] = bitcast i8 addrspace(200)* [[MEMPTR_PTR_I]] to i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)*
; INLINE-ONLY-NEXT:    br label [[CALL_MEMBER_FN_PTR_INDIRECT_ARG_EXIT]]
; INLINE-ONLY:       call_member_fn_ptr_indirect_arg.exit:
; INLINE-ONLY-NEXT:    [[TMP8:%.*]] = phi i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* [ [[MEMPTR_VIRTUALFN_I]], [[MEMPTR_VIRTUAL_I]] ], [ [[MEMPTR_NONVIRTUALFN_I]], [[MEMPTR_NONVIRTUAL_I]] ]
; INLINE-ONLY-NEXT:    [[CALL_I:%.*]] = call i64 [[TMP8]]([[STRUCT_A]] addrspace(200)* nonnull align 16 dereferenceable(16) [[THIS_ADJUSTED_I]])
; INLINE-ONLY-NEXT:    ret i64 [[CALL_I]]
;
; FULL-LABEL: define {{[^@]+}}@call_f1_via_member_ptr
; FULL-SAME: () local_unnamed_addr addrspace(200) #[[ATTR0:[0-9]+]] {
; FULL-NEXT:  call_member_fn_ptr_indirect_arg.exit:
; FULL-NEXT:    ret i64 1
;
entry:
  %a = alloca %struct.A, align 16, addrspace(200)
  %indirect-arg-temp = alloca { i8 addrspace(200)*, i64 }, align 16, addrspace(200)
  call void @_ZN1AC1Ev(%struct.A addrspace(200)* nonnull align 16 dereferenceable(16) %a)
  store { i8 addrspace(200)*, i64 } { i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 1), i64 0 }, { i8 addrspace(200)*, i64 } addrspace(200)* %indirect-arg-temp, align 16
  %call = call i64 @call_member_fn_ptr_indirect_arg(%struct.A addrspace(200)* %a, { i8 addrspace(200)*, i64 } addrspace(200)* %indirect-arg-temp)
  ret i64 %call
}


define dso_local i64 @call_f2_via_member_ptr() {
; INLINE-ONLY-LABEL: define {{[^@]+}}@call_f2_via_member_ptr() addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    [[A:%.*]] = alloca [[STRUCT_A:%.*]], align 16, addrspace(200)
; INLINE-ONLY-NEXT:    [[INDIRECT_ARG_TEMP:%.*]] = alloca { i8 addrspace(200)*, i64 }, align 16, addrspace(200)
; INLINE-ONLY-NEXT:    [[TMP0:%.*]] = bitcast [[STRUCT_A]] addrspace(200)* [[A]] to i64 (...) addrspace(200)* addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    store i64 (...) addrspace(200)* addrspace(200)* bitcast (i8 addrspace(200)* addrspace(200)* getelementptr inbounds ({ [4 x i8 addrspace(200)*] }, { [4 x i8 addrspace(200)*] } addrspace(200)* @_ZTV1A, i32 0, inrange i32 0, i32 2) to i64 (...) addrspace(200)* addrspace(200)*), i64 (...) addrspace(200)* addrspace(200)* addrspace(200)* [[TMP0]], align 16
; INLINE-ONLY-NEXT:    store { i8 addrspace(200)*, i64 } { i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 17), i64 0 }, { i8 addrspace(200)*, i64 } addrspace(200)* [[INDIRECT_ARG_TEMP]], align 16
; INLINE-ONLY-NEXT:    [[FP_I:%.*]] = load { i8 addrspace(200)*, i64 }, { i8 addrspace(200)*, i64 } addrspace(200)* [[INDIRECT_ARG_TEMP]], align 16
; INLINE-ONLY-NEXT:    [[MEMPTR_ADJ_I:%.*]] = extractvalue { i8 addrspace(200)*, i64 } [[FP_I]], 1
; INLINE-ONLY-NEXT:    [[TMP1:%.*]] = bitcast [[STRUCT_A]] addrspace(200)* [[A]] to i8 addrspace(200)*
; INLINE-ONLY-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, i8 addrspace(200)* [[TMP1]], i64 [[MEMPTR_ADJ_I]]
; INLINE-ONLY-NEXT:    [[THIS_ADJUSTED_I:%.*]] = bitcast i8 addrspace(200)* [[TMP2]] to [[STRUCT_A]] addrspace(200)*
; INLINE-ONLY-NEXT:    [[MEMPTR_PTR_I:%.*]] = extractvalue { i8 addrspace(200)*, i64 } [[FP_I]], 0
; INLINE-ONLY-NEXT:    [[MEMPTR_PTR_ADDR_I:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[MEMPTR_PTR_I]])
; INLINE-ONLY-NEXT:    [[TMP3:%.*]] = and i64 [[MEMPTR_PTR_ADDR_I]], 1
; INLINE-ONLY-NEXT:    [[MEMPTR_ISVIRTUAL_I:%.*]] = icmp ne i64 [[TMP3]], 0
; INLINE-ONLY-NEXT:    br i1 [[MEMPTR_ISVIRTUAL_I]], label [[MEMPTR_VIRTUAL_I:%.*]], label [[MEMPTR_NONVIRTUAL_I:%.*]]
; INLINE-ONLY:       memptr.virtual.i:
; INLINE-ONLY-NEXT:    [[TMP4:%.*]] = bitcast i8 addrspace(200)* [[TMP2]] to i8 addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    [[VTABLE_I:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[TMP4]], align 16
; INLINE-ONLY-NEXT:    [[MEMPTR_VTABLE_OFFSET_I:%.*]] = ptrtoint i8 addrspace(200)* [[MEMPTR_PTR_I]] to i64
; INLINE-ONLY-NEXT:    [[TMP5:%.*]] = sub i64 [[MEMPTR_VTABLE_OFFSET_I]], 1
; INLINE-ONLY-NEXT:    [[TMP6:%.*]] = getelementptr i8, i8 addrspace(200)* [[VTABLE_I]], i64 [[TMP5]]
; INLINE-ONLY-NEXT:    [[TMP7:%.*]] = bitcast i8 addrspace(200)* [[TMP6]] to i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    [[MEMPTR_VIRTUALFN_I:%.*]] = load i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)*, i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* addrspace(200)* [[TMP7]], align 16
; INLINE-ONLY-NEXT:    br label [[CALL_MEMBER_FN_PTR_INDIRECT_ARG_EXIT:%.*]]
; INLINE-ONLY:       memptr.nonvirtual.i:
; INLINE-ONLY-NEXT:    [[MEMPTR_NONVIRTUALFN_I:%.*]] = bitcast i8 addrspace(200)* [[MEMPTR_PTR_I]] to i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)*
; INLINE-ONLY-NEXT:    br label [[CALL_MEMBER_FN_PTR_INDIRECT_ARG_EXIT]]
; INLINE-ONLY:       call_member_fn_ptr_indirect_arg.exit:
; INLINE-ONLY-NEXT:    [[TMP8:%.*]] = phi i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* [ [[MEMPTR_VIRTUALFN_I]], [[MEMPTR_VIRTUAL_I]] ], [ [[MEMPTR_NONVIRTUALFN_I]], [[MEMPTR_NONVIRTUAL_I]] ]
; INLINE-ONLY-NEXT:    [[CALL_I:%.*]] = call i64 [[TMP8]]([[STRUCT_A]] addrspace(200)* nonnull align 16 dereferenceable(16) [[THIS_ADJUSTED_I]])
; INLINE-ONLY-NEXT:    ret i64 [[CALL_I]]
;
; FULL-LABEL: define {{[^@]+}}@call_f2_via_member_ptr
; FULL-SAME: () local_unnamed_addr addrspace(200) #[[ATTR0]] {
; FULL-NEXT:  call_member_fn_ptr_indirect_arg.exit:
; FULL-NEXT:    ret i64 2
;
entry:
  %a = alloca %struct.A, align 16, addrspace(200)
  %indirect-arg-temp = alloca { i8 addrspace(200)*, i64 }, align 16, addrspace(200)
  call void @_ZN1AC1Ev(%struct.A addrspace(200)* nonnull align 16 dereferenceable(16) %a) #3
  store { i8 addrspace(200)*, i64 } { i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 17), i64 0 }, { i8 addrspace(200)*, i64 } addrspace(200)* %indirect-arg-temp, align 16
  %call = call i64 @call_member_fn_ptr_indirect_arg(%struct.A addrspace(200)* %a, { i8 addrspace(200)*, i64 } addrspace(200)* %indirect-arg-temp)
  ret i64 %call
}

define internal i64 @call_member_fn_ptr_direct_arg(%struct.A addrspace(200)* %a, { i8 addrspace(200)*, i64 } %fp) {
  %memptr.adj = extractvalue { i8 addrspace(200)*, i64 } %fp, 1
  %1 = bitcast %struct.A addrspace(200)* %a to i8 addrspace(200)*
  %2 = getelementptr inbounds i8, i8 addrspace(200)* %1, i64 %memptr.adj
  %this.adjusted = bitcast i8 addrspace(200)* %2 to %struct.A addrspace(200)*
  %memptr.ptr = extractvalue { i8 addrspace(200)*, i64 } %fp, 0
  %memptr.ptr.addr = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* %memptr.ptr)
  %3 = and i64 %memptr.ptr.addr, 1
  %memptr.isvirtual = icmp ne i64 %3, 0
  br i1 %memptr.isvirtual, label %memptr.virtual, label %memptr.nonvirtual

memptr.virtual:                                   ; preds = %entry
  %4 = bitcast i8 addrspace(200)* %2 to i8 addrspace(200)* addrspace(200)*
  %vtable = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* %4, align 16
  %memptr.vtable.offset = ptrtoint i8 addrspace(200)* %memptr.ptr to i64
  %5 = sub i64 %memptr.vtable.offset, 1
  %6 = getelementptr i8, i8 addrspace(200)* %vtable, i64 %5
  %7 = bitcast i8 addrspace(200)* %6 to i64 (%struct.A addrspace(200)*) addrspace(200)* addrspace(200)*
  %memptr.virtualfn = load i64 (%struct.A addrspace(200)*) addrspace(200)*, i64 (%struct.A addrspace(200)*) addrspace(200)* addrspace(200)* %7, align 16
  br label %memptr.end

memptr.nonvirtual:                                ; preds = %entry
  %memptr.nonvirtualfn = bitcast i8 addrspace(200)* %memptr.ptr to i64 (%struct.A addrspace(200)*) addrspace(200)*
  br label %memptr.end

memptr.end:                                       ; preds = %memptr.nonvirtual, %memptr.virtual
  %8 = phi i64 (%struct.A addrspace(200)*) addrspace(200)* [ %memptr.virtualfn, %memptr.virtual ], [ %memptr.nonvirtualfn, %memptr.nonvirtual ]
  %call = call i64 %8(%struct.A addrspace(200)* nonnull align 16 dereferenceable(16) %this.adjusted)
  ret i64 %call
}

define dso_local i64 @call_f1_via_member_ptr_direct_arg() {
; INLINE-ONLY-LABEL: define {{[^@]+}}@call_f1_via_member_ptr_direct_arg() addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    [[A:%.*]] = alloca [[STRUCT_A:%.*]], align 16, addrspace(200)
; INLINE-ONLY-NEXT:    [[TMP0:%.*]] = bitcast [[STRUCT_A]] addrspace(200)* [[A]] to i64 (...) addrspace(200)* addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    store i64 (...) addrspace(200)* addrspace(200)* bitcast (i8 addrspace(200)* addrspace(200)* getelementptr inbounds ({ [4 x i8 addrspace(200)*] }, { [4 x i8 addrspace(200)*] } addrspace(200)* @_ZTV1A, i32 0, inrange i32 0, i32 2) to i64 (...) addrspace(200)* addrspace(200)*), i64 (...) addrspace(200)* addrspace(200)* addrspace(200)* [[TMP0]], align 16
; INLINE-ONLY-NEXT:    [[TMP1:%.*]] = bitcast [[STRUCT_A]] addrspace(200)* [[A]] to i8 addrspace(200)*
; INLINE-ONLY-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i8 addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    [[VTABLE_I:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[TMP2]], align 16
; INLINE-ONLY-NEXT:    [[TMP3:%.*]] = bitcast i8 addrspace(200)* [[VTABLE_I]] to i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    [[MEMPTR_VIRTUALFN_I:%.*]] = load i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)*, i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* addrspace(200)* [[TMP3]], align 16
; INLINE-ONLY-NEXT:    ret i64 1
;
; FULL-LABEL: define {{[^@]+}}@call_f1_via_member_ptr_direct_arg
; FULL-SAME: () local_unnamed_addr addrspace(200) #[[ATTR1:[0-9]+]] {
; FULL-NEXT:  entry:
; FULL-NEXT:    ret i64 1
;
entry:
  %a = alloca %struct.A, align 16, addrspace(200)
  call void @_ZN1AC1Ev(%struct.A addrspace(200)* nonnull align 16 dereferenceable(16) %a)
  %call = call i64 @call_member_fn_ptr_direct_arg(%struct.A addrspace(200)* %a, { i8 addrspace(200)*, i64 } { i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 1), i64 0 })
  ret i64 %call
}

define dso_local i64 @call_f2_via_member_ptr_direct_arg() {
; INLINE-ONLY-LABEL: define {{[^@]+}}@call_f2_via_member_ptr_direct_arg() addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    [[A:%.*]] = alloca [[STRUCT_A:%.*]], align 16, addrspace(200)
; INLINE-ONLY-NEXT:    [[TMP0:%.*]] = bitcast [[STRUCT_A]] addrspace(200)* [[A]] to i64 (...) addrspace(200)* addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    store i64 (...) addrspace(200)* addrspace(200)* bitcast (i8 addrspace(200)* addrspace(200)* getelementptr inbounds ({ [4 x i8 addrspace(200)*] }, { [4 x i8 addrspace(200)*] } addrspace(200)* @_ZTV1A, i32 0, inrange i32 0, i32 2) to i64 (...) addrspace(200)* addrspace(200)*), i64 (...) addrspace(200)* addrspace(200)* addrspace(200)* [[TMP0]], align 16
; INLINE-ONLY-NEXT:    [[TMP1:%.*]] = bitcast [[STRUCT_A]] addrspace(200)* [[A]] to i8 addrspace(200)*
; INLINE-ONLY-NEXT:    [[TMP2:%.*]] = bitcast i8 addrspace(200)* [[TMP1]] to i8 addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    [[VTABLE_I:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[TMP2]], align 16
; INLINE-ONLY-NEXT:    [[TMP3:%.*]] = getelementptr i8, i8 addrspace(200)* [[VTABLE_I]], i64 16
; INLINE-ONLY-NEXT:    [[TMP4:%.*]] = bitcast i8 addrspace(200)* [[TMP3]] to i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* addrspace(200)*
; INLINE-ONLY-NEXT:    [[MEMPTR_VIRTUALFN_I:%.*]] = load i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)*, i64 ([[STRUCT_A]] addrspace(200)*) addrspace(200)* addrspace(200)* [[TMP4]], align 16
; INLINE-ONLY-NEXT:    ret i64 2
;
; FULL-LABEL: define {{[^@]+}}@call_f2_via_member_ptr_direct_arg
; FULL-SAME: () local_unnamed_addr addrspace(200) #[[ATTR1]] {
; FULL-NEXT:  entry:
; FULL-NEXT:    ret i64 2
;
entry:
  %a = alloca %struct.A, align 16, addrspace(200)
  call void @_ZN1AC1Ev(%struct.A addrspace(200)* nonnull align 16 dereferenceable(16) %a) #3
  %call = call i64 @call_member_fn_ptr_direct_arg(%struct.A addrspace(200)* %a, { i8 addrspace(200)*, i64 } { i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 17), i64 0 })
  ret i64 %call
}


define internal void @_ZN1AC2Ev(%struct.A addrspace(200)* nonnull align 16 dereferenceable(16) %this) {
entry:
  %0 = bitcast %struct.A addrspace(200)* %this to i64 (...) addrspace(200)* addrspace(200)* addrspace(200)*
  store i64 (...) addrspace(200)* addrspace(200)* bitcast (i8 addrspace(200)* addrspace(200)* getelementptr inbounds ({ [4 x i8 addrspace(200)*] }, { [4 x i8 addrspace(200)*] } addrspace(200)* @_ZTV1A, i32 0, inrange i32 0, i32 2) to i64 (...) addrspace(200)* addrspace(200)*), i64 (...) addrspace(200)* addrspace(200)* addrspace(200)* %0, align 16
  ret void
}

define internal void @_ZN1AC1Ev(%struct.A addrspace(200)* nonnull align 16 dereferenceable(16) %this) unnamed_addr addrspace(200) {
entry:
  call void @_ZN1AC2Ev(%struct.A addrspace(200)* nonnull align 16 dereferenceable(16) %this)
  ret void
}

define internal i64 @member_function_1(%struct.A addrspace(200)* nocapture nonnull readnone align 16 dereferenceable(16) %this) {
; INLINE-ONLY-LABEL: define {{[^@]+}}@member_function_1
; INLINE-ONLY-SAME: ([[STRUCT_A:%.*]] addrspace(200)* nocapture nonnull readnone align 16 dereferenceable(16) [[THIS:%.*]]) addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    ret i64 1
;
entry:
  ret i64 1
}

define internal i64 @member_function_2(%struct.A addrspace(200)* nocapture nonnull readnone align 16 dereferenceable(16) %this) {
; INLINE-ONLY-LABEL: define {{[^@]+}}@member_function_2
; INLINE-ONLY-SAME: ([[STRUCT_A:%.*]] addrspace(200)* nocapture nonnull readnone align 16 dereferenceable(16) [[THIS:%.*]]) addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    ret i64 2
;
entry:
  ret i64 2
}
