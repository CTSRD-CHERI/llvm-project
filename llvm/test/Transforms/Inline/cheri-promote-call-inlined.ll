; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes
; When compiling for purecap C++, Clang misses many opportunities to devirtualize calls via pointers to members.
; The equivalent code for hybrid correctly converts both functions to ret 1/2 just in calling the inliner pass.
; This is most likely a problem in Transforms/Utils/CloneFunction.cpp that fails to simplify the purecap
; pointer-to-member call (possibly because of the @llvm.cheri.cap.address.get.i64 call).
; Test case is based on clang/test/CodeGenCXX/member-function-pointer-calls.cpp
; RUN: opt -S "-passes=cgscc(inline)" < %s | FileCheck %s --check-prefixes=INLINE-ONLY
; The -O2 pipeline eventually manages to devirtualize the second call but misses the first one:
; RUN: opt -S "-passes=default<O2>" < %s | FileCheck %s --check-prefixes=FULL
target datalayout = "e-m:e-pf200:128:128:128:64-p:64:64-i64:64-i128:128-n64-S128-A200-P200-G200"
target triple = "riscv64-unknown-freebsd"

%struct.A = type { ptr addrspace(200) }

@_ZTV1A = private unnamed_addr addrspace(200) constant { [4 x ptr addrspace(200)] } { [4 x ptr addrspace(200)] [ptr addrspace(200) null, ptr addrspace(200) @_ZTI1A, ptr addrspace(200) @member_function_1, ptr addrspace(200) @member_function_2] }, align 16
@_ZTI1A = external addrspace(200) constant { ptr addrspace(200), ptr addrspace(200) }, align 16

declare i64 @llvm.cheri.cap.address.get.i64(ptr addrspace(200)) addrspace(200) #0

define internal i64 @call_member_fn_ptr_indirect_arg(ptr addrspace(200) %a, ptr addrspace(200) %0) addrspace(200) {
entry:
  %fp = load { ptr addrspace(200), i64 }, ptr addrspace(200) %0, align 16
  %memptr.adj = extractvalue { ptr addrspace(200), i64 } %fp, 1
  %1 = bitcast ptr addrspace(200) %a to ptr addrspace(200)
  %2 = getelementptr inbounds i8, ptr addrspace(200) %1, i64 %memptr.adj
  %this.adjusted = bitcast ptr addrspace(200) %2 to ptr addrspace(200)
  %memptr.ptr = extractvalue { ptr addrspace(200), i64 } %fp, 0
  %memptr.ptr.addr = call i64 @llvm.cheri.cap.address.get.i64(ptr addrspace(200) %memptr.ptr)
  %3 = and i64 %memptr.ptr.addr, 1
  %memptr.isvirtual = icmp ne i64 %3, 0
  br i1 %memptr.isvirtual, label %memptr.virtual, label %memptr.nonvirtual

memptr.virtual:                                   ; preds = %entry
  %4 = bitcast ptr addrspace(200) %2 to ptr addrspace(200)
  %vtable = load ptr addrspace(200), ptr addrspace(200) %4, align 16
  %memptr.vtable.offset = ptrtoint ptr addrspace(200) %memptr.ptr to i64
  %5 = sub i64 %memptr.vtable.offset, 1
  %6 = getelementptr i8, ptr addrspace(200) %vtable, i64 %5
  %7 = bitcast ptr addrspace(200) %6 to ptr addrspace(200)
  %memptr.virtualfn = load ptr addrspace(200), ptr addrspace(200) %7, align 16
  br label %memptr.end

memptr.nonvirtual:                                ; preds = %entry
  %memptr.nonvirtualfn = bitcast ptr addrspace(200) %memptr.ptr to ptr addrspace(200)
  br label %memptr.end

memptr.end:                                       ; preds = %memptr.nonvirtual, %memptr.virtual
  %8 = phi ptr addrspace(200) [ %memptr.virtualfn, %memptr.virtual ], [ %memptr.nonvirtualfn, %memptr.nonvirtual ]
  %call = call i64 %8(ptr addrspace(200) nonnull align 16 dereferenceable(16) %this.adjusted)
  ret i64 %call
}

define dso_local i64 @call_f1_via_member_ptr() addrspace(200) {
; INLINE-ONLY-LABEL: define {{[^@]+}}@call_f1_via_member_ptr() addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    [[A:%.*]] = alloca [[STRUCT_A:%.*]], align 16, addrspace(200)
; INLINE-ONLY-NEXT:    [[INDIRECT_ARG_TEMP:%.*]] = alloca { ptr addrspace(200), i64 }, align 16, addrspace(200)
; INLINE-ONLY-NEXT:    store ptr addrspace(200) getelementptr inbounds ({ [4 x ptr addrspace(200)] }, ptr addrspace(200) @_ZTV1A, i32 0, inrange i32 0, i32 2), ptr addrspace(200) [[A]], align 16
; INLINE-ONLY-NEXT:    store { ptr addrspace(200), i64 } { ptr addrspace(200) getelementptr (i8, ptr addrspace(200) null, i64 1), i64 0 }, ptr addrspace(200) [[INDIRECT_ARG_TEMP]], align 16
; INLINE-ONLY-NEXT:    [[FP_I:%.*]] = load { ptr addrspace(200), i64 }, ptr addrspace(200) [[INDIRECT_ARG_TEMP]], align 16
; INLINE-ONLY-NEXT:    [[MEMPTR_ADJ_I:%.*]] = extractvalue { ptr addrspace(200), i64 } [[FP_I]], 1
; INLINE-ONLY-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr addrspace(200) [[A]], i64 [[MEMPTR_ADJ_I]]
; INLINE-ONLY-NEXT:    [[MEMPTR_PTR_I:%.*]] = extractvalue { ptr addrspace(200), i64 } [[FP_I]], 0
; INLINE-ONLY-NEXT:    [[MEMPTR_PTR_ADDR_I:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(ptr addrspace(200) [[MEMPTR_PTR_I]])
; INLINE-ONLY-NEXT:    [[TMP1:%.*]] = and i64 [[MEMPTR_PTR_ADDR_I]], 1
; INLINE-ONLY-NEXT:    [[MEMPTR_ISVIRTUAL_I:%.*]] = icmp ne i64 [[TMP1]], 0
; INLINE-ONLY-NEXT:    br i1 [[MEMPTR_ISVIRTUAL_I]], label [[MEMPTR_VIRTUAL_I:%.*]], label [[MEMPTR_NONVIRTUAL_I:%.*]]
; INLINE-ONLY:       memptr.virtual.i:
; INLINE-ONLY-NEXT:    [[VTABLE_I:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[TMP0]], align 16
; INLINE-ONLY-NEXT:    [[MEMPTR_VTABLE_OFFSET_I:%.*]] = ptrtoint ptr addrspace(200) [[MEMPTR_PTR_I]] to i64
; INLINE-ONLY-NEXT:    [[TMP2:%.*]] = sub i64 [[MEMPTR_VTABLE_OFFSET_I]], 1
; INLINE-ONLY-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr addrspace(200) [[VTABLE_I]], i64 [[TMP2]]
; INLINE-ONLY-NEXT:    [[MEMPTR_VIRTUALFN_I:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[TMP3]], align 16
; INLINE-ONLY-NEXT:    br label [[CALL_MEMBER_FN_PTR_INDIRECT_ARG_EXIT:%.*]]
; INLINE-ONLY:       memptr.nonvirtual.i:
; INLINE-ONLY-NEXT:    br label [[CALL_MEMBER_FN_PTR_INDIRECT_ARG_EXIT]]
; INLINE-ONLY:       call_member_fn_ptr_indirect_arg.exit:
; INLINE-ONLY-NEXT:    [[TMP4:%.*]] = phi ptr addrspace(200) [ [[MEMPTR_VIRTUALFN_I]], [[MEMPTR_VIRTUAL_I]] ], [ [[MEMPTR_PTR_I]], [[MEMPTR_NONVIRTUAL_I]] ]
; INLINE-ONLY-NEXT:    [[CALL_I:%.*]] = call i64 [[TMP4]](ptr addrspace(200) nonnull align 16 dereferenceable(16) [[TMP0]])
; INLINE-ONLY-NEXT:    ret i64 [[CALL_I]]
;
; FULL-LABEL: define {{[^@]+}}@call_f1_via_member_ptr
; FULL-SAME: () local_unnamed_addr addrspace(200) #[[ATTR0:[0-9]+]] {
; FULL-NEXT:  call_member_fn_ptr_indirect_arg.exit:
; FULL-NEXT:    ret i64 1
;
entry:
  %a = alloca %struct.A, align 16, addrspace(200)
  %indirect-arg-temp = alloca { ptr addrspace(200), i64 }, align 16, addrspace(200)
  call void @_ZN1AC1Ev(ptr addrspace(200) nonnull align 16 dereferenceable(16) %a)
  store { ptr addrspace(200), i64 } { ptr addrspace(200) getelementptr (i8, ptr addrspace(200) null, i64 1), i64 0 }, ptr addrspace(200) %indirect-arg-temp, align 16
  %call = call i64 @call_member_fn_ptr_indirect_arg(ptr addrspace(200) %a, ptr addrspace(200) %indirect-arg-temp)
  ret i64 %call
}

define dso_local i64 @call_f2_via_member_ptr() addrspace(200) {
; INLINE-ONLY-LABEL: define {{[^@]+}}@call_f2_via_member_ptr() addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    [[A:%.*]] = alloca [[STRUCT_A:%.*]], align 16, addrspace(200)
; INLINE-ONLY-NEXT:    [[INDIRECT_ARG_TEMP:%.*]] = alloca { ptr addrspace(200), i64 }, align 16, addrspace(200)
; INLINE-ONLY-NEXT:    store ptr addrspace(200) getelementptr inbounds ({ [4 x ptr addrspace(200)] }, ptr addrspace(200) @_ZTV1A, i32 0, inrange i32 0, i32 2), ptr addrspace(200) [[A]], align 16
; INLINE-ONLY-NEXT:    store { ptr addrspace(200), i64 } { ptr addrspace(200) getelementptr (i8, ptr addrspace(200) null, i64 17), i64 0 }, ptr addrspace(200) [[INDIRECT_ARG_TEMP]], align 16
; INLINE-ONLY-NEXT:    [[FP_I:%.*]] = load { ptr addrspace(200), i64 }, ptr addrspace(200) [[INDIRECT_ARG_TEMP]], align 16
; INLINE-ONLY-NEXT:    [[MEMPTR_ADJ_I:%.*]] = extractvalue { ptr addrspace(200), i64 } [[FP_I]], 1
; INLINE-ONLY-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr addrspace(200) [[A]], i64 [[MEMPTR_ADJ_I]]
; INLINE-ONLY-NEXT:    [[MEMPTR_PTR_I:%.*]] = extractvalue { ptr addrspace(200), i64 } [[FP_I]], 0
; INLINE-ONLY-NEXT:    [[MEMPTR_PTR_ADDR_I:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(ptr addrspace(200) [[MEMPTR_PTR_I]])
; INLINE-ONLY-NEXT:    [[TMP1:%.*]] = and i64 [[MEMPTR_PTR_ADDR_I]], 1
; INLINE-ONLY-NEXT:    [[MEMPTR_ISVIRTUAL_I:%.*]] = icmp ne i64 [[TMP1]], 0
; INLINE-ONLY-NEXT:    br i1 [[MEMPTR_ISVIRTUAL_I]], label [[MEMPTR_VIRTUAL_I:%.*]], label [[MEMPTR_NONVIRTUAL_I:%.*]]
; INLINE-ONLY:       memptr.virtual.i:
; INLINE-ONLY-NEXT:    [[VTABLE_I:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[TMP0]], align 16
; INLINE-ONLY-NEXT:    [[MEMPTR_VTABLE_OFFSET_I:%.*]] = ptrtoint ptr addrspace(200) [[MEMPTR_PTR_I]] to i64
; INLINE-ONLY-NEXT:    [[TMP2:%.*]] = sub i64 [[MEMPTR_VTABLE_OFFSET_I]], 1
; INLINE-ONLY-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr addrspace(200) [[VTABLE_I]], i64 [[TMP2]]
; INLINE-ONLY-NEXT:    [[MEMPTR_VIRTUALFN_I:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[TMP3]], align 16
; INLINE-ONLY-NEXT:    br label [[CALL_MEMBER_FN_PTR_INDIRECT_ARG_EXIT:%.*]]
; INLINE-ONLY:       memptr.nonvirtual.i:
; INLINE-ONLY-NEXT:    br label [[CALL_MEMBER_FN_PTR_INDIRECT_ARG_EXIT]]
; INLINE-ONLY:       call_member_fn_ptr_indirect_arg.exit:
; INLINE-ONLY-NEXT:    [[TMP4:%.*]] = phi ptr addrspace(200) [ [[MEMPTR_VIRTUALFN_I]], [[MEMPTR_VIRTUAL_I]] ], [ [[MEMPTR_PTR_I]], [[MEMPTR_NONVIRTUAL_I]] ]
; INLINE-ONLY-NEXT:    [[CALL_I:%.*]] = call i64 [[TMP4]](ptr addrspace(200) nonnull align 16 dereferenceable(16) [[TMP0]])
; INLINE-ONLY-NEXT:    ret i64 [[CALL_I]]
;
; FULL-LABEL: define {{[^@]+}}@call_f2_via_member_ptr
; FULL-SAME: () local_unnamed_addr addrspace(200) #[[ATTR0]] {
; FULL-NEXT:  call_member_fn_ptr_indirect_arg.exit:
; FULL-NEXT:    ret i64 2
;
entry:
  %a = alloca %struct.A, align 16, addrspace(200)
  %indirect-arg-temp = alloca { ptr addrspace(200), i64 }, align 16, addrspace(200)
  call void @_ZN1AC1Ev(ptr addrspace(200) nonnull align 16 dereferenceable(16) %a)
  store { ptr addrspace(200), i64 } { ptr addrspace(200) getelementptr (i8, ptr addrspace(200) null, i64 17), i64 0 }, ptr addrspace(200) %indirect-arg-temp, align 16
  %call = call i64 @call_member_fn_ptr_indirect_arg(ptr addrspace(200) %a, ptr addrspace(200) %indirect-arg-temp)
  ret i64 %call
}

define internal i64 @call_member_fn_ptr_direct_arg(ptr addrspace(200) %a, { ptr addrspace(200), i64 } %fp) addrspace(200) {
  %memptr.adj = extractvalue { ptr addrspace(200), i64 } %fp, 1
  %1 = bitcast ptr addrspace(200) %a to ptr addrspace(200)
  %2 = getelementptr inbounds i8, ptr addrspace(200) %1, i64 %memptr.adj
  %this.adjusted = bitcast ptr addrspace(200) %2 to ptr addrspace(200)
  %memptr.ptr = extractvalue { ptr addrspace(200), i64 } %fp, 0
  %memptr.ptr.addr = call i64 @llvm.cheri.cap.address.get.i64(ptr addrspace(200) %memptr.ptr)
  %3 = and i64 %memptr.ptr.addr, 1
  %memptr.isvirtual = icmp ne i64 %3, 0
  br i1 %memptr.isvirtual, label %memptr.virtual, label %memptr.nonvirtual

memptr.virtual:                                   ; preds = %0
  %4 = bitcast ptr addrspace(200) %2 to ptr addrspace(200)
  %vtable = load ptr addrspace(200), ptr addrspace(200) %4, align 16
  %memptr.vtable.offset = ptrtoint ptr addrspace(200) %memptr.ptr to i64
  %5 = sub i64 %memptr.vtable.offset, 1
  %6 = getelementptr i8, ptr addrspace(200) %vtable, i64 %5
  %7 = bitcast ptr addrspace(200) %6 to ptr addrspace(200)
  %memptr.virtualfn = load ptr addrspace(200), ptr addrspace(200) %7, align 16
  br label %memptr.end

memptr.nonvirtual:                                ; preds = %0
  %memptr.nonvirtualfn = bitcast ptr addrspace(200) %memptr.ptr to ptr addrspace(200)
  br label %memptr.end

memptr.end:                                       ; preds = %memptr.nonvirtual, %memptr.virtual
  %8 = phi ptr addrspace(200) [ %memptr.virtualfn, %memptr.virtual ], [ %memptr.nonvirtualfn, %memptr.nonvirtual ]
  %call = call i64 %8(ptr addrspace(200) nonnull align 16 dereferenceable(16) %this.adjusted)
  ret i64 %call
}

define dso_local i64 @call_f1_via_member_ptr_direct_arg() addrspace(200) {
; INLINE-ONLY-LABEL: define {{[^@]+}}@call_f1_via_member_ptr_direct_arg() addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    [[A:%.*]] = alloca [[STRUCT_A:%.*]], align 16, addrspace(200)
; INLINE-ONLY-NEXT:    store ptr addrspace(200) getelementptr inbounds ({ [4 x ptr addrspace(200)] }, ptr addrspace(200) @_ZTV1A, i32 0, inrange i32 0, i32 2), ptr addrspace(200) [[A]], align 16
; INLINE-ONLY-NEXT:    [[VTABLE_I:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[A]], align 16
; INLINE-ONLY-NEXT:    [[MEMPTR_VIRTUALFN_I:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[VTABLE_I]], align 16
; INLINE-ONLY-NEXT:    ret i64 1
;
; FULL-LABEL: define {{[^@]+}}@call_f1_via_member_ptr_direct_arg
; FULL-SAME: () local_unnamed_addr addrspace(200) #[[ATTR1:[0-9]+]] {
; FULL-NEXT:  entry:
; FULL-NEXT:    ret i64 1
;
entry:
  %a = alloca %struct.A, align 16, addrspace(200)
  call void @_ZN1AC1Ev(ptr addrspace(200) nonnull align 16 dereferenceable(16) %a)
  %call = call i64 @call_member_fn_ptr_direct_arg(ptr addrspace(200) %a, { ptr addrspace(200), i64 } { ptr addrspace(200) getelementptr (i8, ptr addrspace(200) null, i64 1), i64 0 })
  ret i64 %call
}

define dso_local i64 @call_f2_via_member_ptr_direct_arg() addrspace(200) {
; INLINE-ONLY-LABEL: define {{[^@]+}}@call_f2_via_member_ptr_direct_arg() addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    [[A:%.*]] = alloca [[STRUCT_A:%.*]], align 16, addrspace(200)
; INLINE-ONLY-NEXT:    store ptr addrspace(200) getelementptr inbounds ({ [4 x ptr addrspace(200)] }, ptr addrspace(200) @_ZTV1A, i32 0, inrange i32 0, i32 2), ptr addrspace(200) [[A]], align 16
; INLINE-ONLY-NEXT:    [[VTABLE_I:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[A]], align 16
; INLINE-ONLY-NEXT:    [[TMP0:%.*]] = getelementptr i8, ptr addrspace(200) [[VTABLE_I]], i64 16
; INLINE-ONLY-NEXT:    [[MEMPTR_VIRTUALFN_I:%.*]] = load ptr addrspace(200), ptr addrspace(200) [[TMP0]], align 16
; INLINE-ONLY-NEXT:    ret i64 2
;
; FULL-LABEL: define {{[^@]+}}@call_f2_via_member_ptr_direct_arg
; FULL-SAME: () local_unnamed_addr addrspace(200) #[[ATTR1]] {
; FULL-NEXT:  entry:
; FULL-NEXT:    ret i64 2
;
entry:
  %a = alloca %struct.A, align 16, addrspace(200)
  call void @_ZN1AC1Ev(ptr addrspace(200) nonnull align 16 dereferenceable(16) %a)
  %call = call i64 @call_member_fn_ptr_direct_arg(ptr addrspace(200) %a, { ptr addrspace(200), i64 } { ptr addrspace(200) getelementptr (i8, ptr addrspace(200) null, i64 17), i64 0 })
  ret i64 %call
}

define internal void @_ZN1AC2Ev(ptr addrspace(200) nonnull align 16 dereferenceable(16) %this) addrspace(200) {
entry:
  %0 = bitcast ptr addrspace(200) %this to ptr addrspace(200)
  store ptr addrspace(200) getelementptr inbounds ({ [4 x ptr addrspace(200)] }, ptr addrspace(200) @_ZTV1A, i32 0, inrange i32 0, i32 2), ptr addrspace(200) %0, align 16
  ret void
}

define internal void @_ZN1AC1Ev(ptr addrspace(200) nonnull align 16 dereferenceable(16) %this) unnamed_addr addrspace(200) {
entry:
  call void @_ZN1AC2Ev(ptr addrspace(200) nonnull align 16 dereferenceable(16) %this)
  ret void
}

define internal i64 @member_function_1(ptr addrspace(200) nocapture nonnull readnone align 16 dereferenceable(16) %this) addrspace(200) {
; INLINE-ONLY-LABEL: define {{[^@]+}}@member_function_1
; INLINE-ONLY-SAME: (ptr addrspace(200) nocapture nonnull readnone align 16 dereferenceable(16) [[THIS:%.*]]) addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    ret i64 1
;
entry:
  ret i64 1
}

define internal i64 @member_function_2(ptr addrspace(200) nocapture nonnull readnone align 16 dereferenceable(16) %this) addrspace(200) {
; INLINE-ONLY-LABEL: define {{[^@]+}}@member_function_2
; INLINE-ONLY-SAME: (ptr addrspace(200) nocapture nonnull readnone align 16 dereferenceable(16) [[THIS:%.*]]) addrspace(200) {
; INLINE-ONLY-NEXT:  entry:
; INLINE-ONLY-NEXT:    ret i64 2
;
entry:
  ret i64 2
}
