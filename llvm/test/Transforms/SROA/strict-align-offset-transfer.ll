; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes
; RUN: sed -e 's/@PTR_AS@/200/g' -e 's/@PTR_PAIR_SIZE@/32/g' %s \
; RUN:   | opt -S -passes=sroa | FileCheck %s
; RUN: sed -e 's/@PTR_AS@/200/g' -e 's/@PTR_PAIR_SIZE@/32/g' %s \
; RUN:   | opt -S -O2 | FileCheck %s --check-prefix CHECK-O2
; RUN: sed -e 's/@PTR_AS@/0/g' -e 's/@PTR_PAIR_SIZE@/16/g' -e 's/-pf200:128:128:128:64//g' %s \
; RUN:   | opt -S -passes=sroa -o - | FileCheck %s --check-prefix NOCHERI
; RUN: sed -e 's/@PTR_AS@/0/g' -e 's/@PTR_PAIR_SIZE@/16/g' -e 's/-pf200:128:128:128:64//g' %s \
; RUN:   | opt -S -O2  | FileCheck %s --check-prefix NOCHERI-O2
target datalayout = "e-m:e-pf200:128:128:128:64-p:64:64-i64:64-i128:128-n64-S128-A@PTR_AS@-P@PTR_AS@-G@PTR_AS@"
target triple = "riscv64"

; Regression test for an SROA assertion caused by the "strict alignment slices" being inserted before
; the actual slice for the memtransfer instruction. This then resulted in SROA marking the wrong slice
; (the first strict alignment one instead of the one spanning the whole memcpy) as unsplittable and then
; asserting later on.
; TODO: While opt -O2 generates the same code for CHERI/non-CHERI the SROA output is a lot worse for CHERI

; Regression test for an assertion while compiling the synctex parser in okular for CHERI-RISC-V
; Assertion failed: (AI != &OldAI && AI != &NewAI && "Splittable transfers cannot reach the same alloca on both ends."), function visitMemTransferInst
;
; Original reduced C test case :
;
; typedef struct {
;   int *a;
;   int b;
; } c;
; typedef struct {
;   c d;
;   c e;
; } f;
; void use(c arg);
; void g() {
;   f h = {{0, 1}, {0, 2}};
;   h.d = h.e;
;   use(h.d);
; }

%struct.f = type { %struct.c, %struct.c }
%struct.c = type { i32 addrspace(@PTR_AS@)*, i32 }

declare void @llvm.memset.p@PTR_AS@i8.i64(i8 addrspace(@PTR_AS@)* nocapture writeonly %0, i8 %1, i64 %2, i1 immarg %3)

declare void @llvm.memcpy.p@PTR_AS@i8.p@PTR_AS@i8.i64(i8 addrspace(@PTR_AS@)* noalias nocapture writeonly, i8 addrspace(@PTR_AS@)* noalias nocapture readonly, i64, i1 immarg)

declare void @read(%struct.c addrspace(@PTR_AS@)* noalias nocapture readonly)

define void @test() nounwind {
; CHECK-LABEL: define {{[^@]+}}@test
; CHECK-SAME: () addrspace(200) #[[ATTR2:[0-9]+]] {
; CHECK-NEXT:  bb:
; CHECK-NEXT:    [[H_SROA_0_SROA_0:%.*]] = alloca i32 addrspace(200)*, align 16, addrspace(200)
; CHECK-NEXT:    [[H_SROA_0_SROA_2:%.*]] = alloca [16 x i8], align 16, addrspace(200)
; CHECK-NEXT:    [[H_SROA_6:%.*]] = alloca [[STRUCT_C:%.*]], align 16, addrspace(200)
; CHECK-NEXT:    [[H_D_BYVAL:%.*]] = alloca [[STRUCT_C]], align 16, addrspace(200)
; CHECK-NEXT:    [[H_SROA_0_SROA_0_0_H_I8_SROA_CAST11:%.*]] = bitcast i32 addrspace(200)* addrspace(200)* [[H_SROA_0_SROA_0]] to i8 addrspace(200)*
; CHECK-NEXT:    call void @llvm.memset.p200i8.i64(i8 addrspace(200)* align 16 [[H_SROA_0_SROA_0_0_H_I8_SROA_CAST11]], i8 1, i64 16, i1 false)
; CHECK-NEXT:    [[H_SROA_0_SROA_2_0_H_I8_SROA_IDX10:%.*]] = getelementptr inbounds [16 x i8], [16 x i8] addrspace(200)* [[H_SROA_0_SROA_2]], i64 0, i64 0
; CHECK-NEXT:    call void @llvm.memset.p200i8.i64(i8 addrspace(200)* align 16 [[H_SROA_0_SROA_2_0_H_I8_SROA_IDX10]], i8 1, i64 16, i1 false)
; CHECK-NEXT:    [[H_SROA_6_0_H_I8_SROA_CAST:%.*]] = bitcast [[STRUCT_C]] addrspace(200)* [[H_SROA_6]] to i8 addrspace(200)*
; CHECK-NEXT:    call void @llvm.memset.p200i8.i64(i8 addrspace(200)* align 16 [[H_SROA_6_0_H_I8_SROA_CAST]], i8 1, i64 32, i1 false)
; CHECK-NEXT:    [[H_SROA_0_SROA_2_16_H_SROA_6_32_H_E_I8_SROA_CAST_SROA_CAST:%.*]] = bitcast [[STRUCT_C]] addrspace(200)* [[H_SROA_6]] to i8 addrspace(200)*
; CHECK-NEXT:    [[H_SROA_0_SROA_2_0_H_D_I8_SROA_IDX8:%.*]] = getelementptr inbounds [16 x i8], [16 x i8] addrspace(200)* [[H_SROA_0_SROA_2]], i64 0, i64 0
; CHECK-NEXT:    call void @llvm.memcpy.p200i8.p200i8.i64(i8 addrspace(200)* align 16 [[H_SROA_0_SROA_2_0_H_D_I8_SROA_IDX8]], i8 addrspace(200)* align 16 [[H_SROA_0_SROA_2_16_H_SROA_6_32_H_E_I8_SROA_CAST_SROA_CAST]], i64 16, i1 false)
; CHECK-NEXT:    [[H_SROA_0_SROA_0_0_H_SROA_0_0_H_D_BYVAL_I8_SROA_CAST_SROA_IDX:%.*]] = getelementptr inbounds [[STRUCT_C]], [[STRUCT_C]] addrspace(200)* [[H_D_BYVAL]], i64 0, i32 0
; CHECK-NEXT:    [[H_SROA_0_SROA_0_0_H_SROA_0_SROA_0_0_COPYLOAD:%.*]] = load i32 addrspace(200)*, i32 addrspace(200)* addrspace(200)* [[H_SROA_0_SROA_0]], align 16
; CHECK-NEXT:    store i32 addrspace(200)* [[H_SROA_0_SROA_0_0_H_SROA_0_SROA_0_0_COPYLOAD]], i32 addrspace(200)* addrspace(200)* [[H_SROA_0_SROA_0_0_H_SROA_0_0_H_D_BYVAL_I8_SROA_CAST_SROA_IDX]], align 16
; CHECK-NEXT:    [[H_SROA_0_SROA_2_0_H_SROA_0_0_H_D_BYVAL_I8_SROA_CAST_SROA_IDX:%.*]] = getelementptr inbounds [[STRUCT_C]], [[STRUCT_C]] addrspace(200)* [[H_D_BYVAL]], i64 0, i32 1
; CHECK-NEXT:    [[H_SROA_0_SROA_2_0_H_SROA_0_0_H_D_BYVAL_I8_SROA_CAST_SROA_CAST:%.*]] = bitcast i32 addrspace(200)* [[H_SROA_0_SROA_2_0_H_SROA_0_0_H_D_BYVAL_I8_SROA_CAST_SROA_IDX]] to i8 addrspace(200)*
; CHECK-NEXT:    [[H_SROA_0_SROA_2_0_H_D_I8_SROA_IDX9:%.*]] = getelementptr inbounds [16 x i8], [16 x i8] addrspace(200)* [[H_SROA_0_SROA_2]], i64 0, i64 0
; CHECK-NEXT:    call void @llvm.memcpy.p200i8.p200i8.i64(i8 addrspace(200)* align 16 [[H_SROA_0_SROA_2_0_H_SROA_0_0_H_D_BYVAL_I8_SROA_CAST_SROA_CAST]], i8 addrspace(200)* align 16 [[H_SROA_0_SROA_2_0_H_D_I8_SROA_IDX9]], i64 16, i1 false)
; CHECK-NEXT:    call void @read([[STRUCT_C]] addrspace(200)* [[H_D_BYVAL]])
; CHECK-NEXT:    ret void
;
; CHECK-O2-LABEL: define {{[^@]+}}@test
; CHECK-O2-SAME: () local_unnamed_addr addrspace(200) #[[ATTR1:[0-9]+]] {
; CHECK-O2-NEXT:  bb:
; CHECK-O2-NEXT:    [[H_D_BYVAL:%.*]] = alloca [[STRUCT_C:%.*]], align 16, addrspace(200)
; CHECK-O2-NEXT:    [[TMP0:%.*]] = bitcast [[STRUCT_C]] addrspace(200)* [[H_D_BYVAL]] to i8 addrspace(200)*
; CHECK-O2-NEXT:    call void @llvm.memset.p200i8.i64(i8 addrspace(200)* noundef nonnull align 16 dereferenceable(32) [[TMP0]], i8 1, i64 32, i1 false)
; CHECK-O2-NEXT:    call void @read([[STRUCT_C]] addrspace(200)* nonnull [[H_D_BYVAL]])
; CHECK-O2-NEXT:    ret void
;
; NOCHERI-LABEL: define {{[^@]+}}@test
; NOCHERI-SAME: () #[[ATTR2:[0-9]+]] {
; NOCHERI-NEXT:  bb:
; NOCHERI-NEXT:    [[H_SROA_0:%.*]] = alloca [[STRUCT_C:%.*]], align 16
; NOCHERI-NEXT:    [[H_SROA_3:%.*]] = alloca [[STRUCT_C]], align 16
; NOCHERI-NEXT:    [[H_D_BYVAL:%.*]] = alloca [[STRUCT_C]], align 16
; NOCHERI-NEXT:    [[H_SROA_0_0_H_I8_SROA_CAST3:%.*]] = bitcast %struct.c* [[H_SROA_0]] to i8*
; NOCHERI-NEXT:    call void @llvm.memset.p0i8.i64(i8* align 16 [[H_SROA_0_0_H_I8_SROA_CAST3]], i8 1, i64 16, i1 false)
; NOCHERI-NEXT:    [[H_SROA_3_0_H_I8_SROA_CAST2:%.*]] = bitcast %struct.c* [[H_SROA_3]] to i8*
; NOCHERI-NEXT:    call void @llvm.memset.p0i8.i64(i8* align 16 [[H_SROA_3_0_H_I8_SROA_CAST2]], i8 1, i64 16, i1 false)
; NOCHERI-NEXT:    [[H_SROA_0_0_H_D_I8_SROA_CAST:%.*]] = bitcast %struct.c* [[H_SROA_0]] to i8*
; NOCHERI-NEXT:    [[H_SROA_3_16_H_E_I8_SROA_CAST:%.*]] = bitcast %struct.c* [[H_SROA_3]] to i8*
; NOCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[H_SROA_0_0_H_D_I8_SROA_CAST]], i8* align 16 [[H_SROA_3_16_H_E_I8_SROA_CAST]], i64 16, i1 false)
; NOCHERI-NEXT:    [[H_SROA_0_0_H_D_BYVAL_I8_SROA_CAST:%.*]] = bitcast %struct.c* [[H_D_BYVAL]] to i8*
; NOCHERI-NEXT:    [[H_SROA_0_0_H_D_I8_SROA_CAST1:%.*]] = bitcast %struct.c* [[H_SROA_0]] to i8*
; NOCHERI-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 [[H_SROA_0_0_H_D_BYVAL_I8_SROA_CAST]], i8* align 16 [[H_SROA_0_0_H_D_I8_SROA_CAST1]], i64 16, i1 false)
; NOCHERI-NEXT:    call void @read(%struct.c* [[H_D_BYVAL]])
; NOCHERI-NEXT:    ret void
;
; NOCHERI-O2-LABEL: define {{[^@]+}}@test
; NOCHERI-O2-SAME: () local_unnamed_addr #[[ATTR1:[0-9]+]] {
; NOCHERI-O2-NEXT:  bb:
; NOCHERI-O2-NEXT:    [[H_D_BYVAL:%.*]] = alloca [[STRUCT_C:%.*]], align 16
; NOCHERI-O2-NEXT:    [[H_D_BYVAL5:%.*]] = bitcast %struct.c* [[H_D_BYVAL]] to i8*
; NOCHERI-O2-NEXT:    call void @llvm.memset.p0i8.i64(i8* noundef nonnull align 16 dereferenceable(16) [[H_D_BYVAL5]], i8 1, i64 16, i1 false)
; NOCHERI-O2-NEXT:    call void @read(%struct.c* nonnull [[H_D_BYVAL]])
; NOCHERI-O2-NEXT:    ret void
;
bb:
  %h = alloca %struct.f, align 16, addrspace(@PTR_AS@)
  %h.d.byval = alloca %struct.c, align 16, addrspace(@PTR_AS@)
  ; Initialize the alloca to ensure that it can't be optimized away (UB due to uninitialized load/store).
  %h.i8 = bitcast %struct.f addrspace(@PTR_AS@)* %h to i8 addrspace(@PTR_AS@)*
  call void @llvm.memset.p@PTR_AS@i8.i64(i8 addrspace(@PTR_AS@)* align 16 %h.i8, i8 1, i64 64, i1 false)
  %h.d = getelementptr inbounds %struct.f, %struct.f addrspace(@PTR_AS@)* %h, i32 0, i32 0
  %h.e = getelementptr inbounds %struct.f, %struct.f addrspace(@PTR_AS@)* %h, i32 0, i32 1
  %h.d.i8 = bitcast %struct.c addrspace(@PTR_AS@)* %h.d to i8 addrspace(@PTR_AS@)*
  %h.e.i8 = bitcast %struct.c addrspace(@PTR_AS@)* %h.e to i8 addrspace(@PTR_AS@)*
  call void @llvm.memcpy.p@PTR_AS@i8.p@PTR_AS@i8.i64(i8 addrspace(@PTR_AS@)* align 16 %h.d.i8, i8 addrspace(@PTR_AS@)* align 16 %h.e.i8, i64 @PTR_PAIR_SIZE@, i1 false)
  ; Actually use the copied value to stop the function from being completely optimized away
  %h.d.byval.i8 = bitcast %struct.c addrspace(@PTR_AS@)* %h.d.byval to i8 addrspace(@PTR_AS@)*
  call void @llvm.memcpy.p@PTR_AS@i8.p@PTR_AS@i8.i64(i8 addrspace(@PTR_AS@)* align 16 %h.d.byval.i8, i8 addrspace(@PTR_AS@)* align 16 %h.d.i8, i64 @PTR_PAIR_SIZE@, i1 false)
  call void @read(%struct.c addrspace(@PTR_AS@)* %h.d.byval)
  ret void
}
