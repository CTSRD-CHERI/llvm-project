; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes --force-update
; DO NOT EDIT -- This file was generated from test/CodeGen/CHERI-Generic/Inputs/c11-atomic-caps-hybrid.ll
; RUN: %riscv64_cheri_llc %s -o - -mattr=+a | FileCheck %s --check-prefixes=CHECK,ATOMICS
; RUN: %riscv64_cheri_llc %s -o - -mattr=-a | FileCheck %s --check-prefixes=CHECK,LIBCALLS
; target datalayout = "e-m:e-pf200:128:128:128:64-p:64:64-i64:64-i128:128-n64-S128"

; Function Attrs: nofree norecurse nounwind
define i8 addrspace(200)* @test_load(i8 addrspace(200)** nocapture readonly %f) local_unnamed_addr #0 {
; ATOMICS-LABEL: test_load:
; ATOMICS:       # %bb.0: # %entry
; ATOMICS-NEXT:    fence rw, rw
; ATOMICS-NEXT:    lc ca0, 0(a0)
; ATOMICS-NEXT:    fence r, rw
; ATOMICS-NEXT:    ret
;
; LIBCALLS-LABEL: test_load:
; LIBCALLS:       # %bb.0: # %entry
; LIBCALLS-NEXT:    addi sp, sp, -16
; LIBCALLS-NEXT:    .cfi_def_cfa_offset 16
; LIBCALLS-NEXT:    sd ra, 8(sp)
; LIBCALLS-NEXT:    .cfi_offset ra, -8
; LIBCALLS-NEXT:    addi a1, zero, 5
; LIBCALLS-NEXT:    call __atomic_load_cap
; LIBCALLS-NEXT:    ld ra, 8(sp)
; LIBCALLS-NEXT:    addi sp, sp, 16
; LIBCALLS-NEXT:    ret
entry:
  %0 = load atomic i8 addrspace(200)*, i8 addrspace(200)** %f seq_cst, align 16
  ret i8 addrspace(200)* %0
}

; Function Attrs: nofree norecurse nounwind
define void @test_store(i8 addrspace(200)** nocapture %f, i8 addrspace(200)* %value) local_unnamed_addr #0 {
; ATOMICS-LABEL: test_store:
; ATOMICS:       # %bb.0: # %entry
; ATOMICS-NEXT:    fence rw, w
; ATOMICS-NEXT:    sc ca1, 0(a0)
; ATOMICS-NEXT:    ret
;
; LIBCALLS-LABEL: test_store:
; LIBCALLS:       # %bb.0: # %entry
; LIBCALLS-NEXT:    addi sp, sp, -16
; LIBCALLS-NEXT:    .cfi_def_cfa_offset 16
; LIBCALLS-NEXT:    sd ra, 8(sp)
; LIBCALLS-NEXT:    .cfi_offset ra, -8
; LIBCALLS-NEXT:    addi a2, zero, 5
; LIBCALLS-NEXT:    call __atomic_store_cap
; LIBCALLS-NEXT:    ld ra, 8(sp)
; LIBCALLS-NEXT:    addi sp, sp, 16
; LIBCALLS-NEXT:    ret
entry:
  store atomic i8 addrspace(200)* %value, i8 addrspace(200)** %f seq_cst, align 16
  ret void
}

; Function Attrs: nofree norecurse nounwind writeonly
define void @test_init(i8 addrspace(200)** nocapture %f, i8 addrspace(200)* %value) local_unnamed_addr #1 {
; CHECK-LABEL: test_init:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    sc ca1, 0(a0)
; CHECK-NEXT:    ret
entry:
  store i8 addrspace(200)* %value, i8 addrspace(200)** %f, align 16
  ret void
}

; Function Attrs: nofree norecurse nounwind
define i8 addrspace(200)* @test_xchg(i8 addrspace(200)** nocapture %f, i8 addrspace(200)* %value) local_unnamed_addr #0 {
; ATOMICS-LABEL: test_xchg:
; ATOMICS:       # %bb.0: # %entry
; ATOMICS-NEXT:    amoswap.c.aqrl ca0, ca1, (a0)
; ATOMICS-NEXT:    ret
;
; LIBCALLS-LABEL: test_xchg:
; LIBCALLS:       # %bb.0: # %entry
; LIBCALLS-NEXT:    addi sp, sp, -16
; LIBCALLS-NEXT:    .cfi_def_cfa_offset 16
; LIBCALLS-NEXT:    sd ra, 8(sp)
; LIBCALLS-NEXT:    .cfi_offset ra, -8
; LIBCALLS-NEXT:    addi a2, zero, 5
; LIBCALLS-NEXT:    call __atomic_exchange_cap
; LIBCALLS-NEXT:    ld ra, 8(sp)
; LIBCALLS-NEXT:    addi sp, sp, 16
; LIBCALLS-NEXT:    ret
entry:
  %0 = atomicrmw xchg i8 addrspace(200)** %f, i8 addrspace(200)* %value seq_cst
  ret i8 addrspace(200)* %0
}

; Function Attrs: nofree norecurse nounwind
define i64 addrspace(200)* @test_xchg_long_ptr(i64 addrspace(200)** nocapture %f, i64 addrspace(200)* %value) local_unnamed_addr #0 {
; ATOMICS-LABEL: test_xchg_long_ptr:
; ATOMICS:       # %bb.0: # %entry
; ATOMICS-NEXT:    amoswap.c.aqrl ca0, ca1, (a0)
; ATOMICS-NEXT:    ret
;
; LIBCALLS-LABEL: test_xchg_long_ptr:
; LIBCALLS:       # %bb.0: # %entry
; LIBCALLS-NEXT:    addi sp, sp, -16
; LIBCALLS-NEXT:    .cfi_def_cfa_offset 16
; LIBCALLS-NEXT:    sd ra, 8(sp)
; LIBCALLS-NEXT:    .cfi_offset ra, -8
; LIBCALLS-NEXT:    addi a2, zero, 5
; LIBCALLS-NEXT:    call __atomic_exchange_cap
; LIBCALLS-NEXT:    ld ra, 8(sp)
; LIBCALLS-NEXT:    addi sp, sp, 16
; LIBCALLS-NEXT:    ret
entry:
  %0 = bitcast i64 addrspace(200)** %f to i8 addrspace(200)**
  %1 = bitcast i64 addrspace(200)* %value to i8 addrspace(200)*
  %2 = atomicrmw xchg i8 addrspace(200)** %0, i8 addrspace(200)* %1 seq_cst
  %3 = bitcast i8 addrspace(200)* %2 to i64 addrspace(200)*
  ret i64 addrspace(200)* %3
}

; Function Attrs: nofree norecurse nounwind
define zeroext i1 @test_cmpxchg_weak(i8 addrspace(200)** nocapture %f, i8 addrspace(200)** nocapture %exp, i8 addrspace(200)* %new) local_unnamed_addr #0 {
; ATOMICS-LABEL: test_cmpxchg_weak:
; ATOMICS:       # %bb.0: # %entry
; ATOMICS-NEXT:    lc ca4, 0(a1)
; ATOMICS-NEXT:  .LBB5_3: # %entry
; ATOMICS-NEXT:    # =>This Inner Loop Header: Depth=1
; ATOMICS-NEXT:    lr.c ca3, (a0)
; ATOMICS-NEXT:    bne a3, a4, .LBB5_5
; ATOMICS-NEXT:  # %bb.4: # %entry
; ATOMICS-NEXT:    # in Loop: Header=BB5_3 Depth=1
; ATOMICS-NEXT:    sc.c a5, ca2, (a0)
; ATOMICS-NEXT:    bnez a5, .LBB5_3
; ATOMICS-NEXT:  .LBB5_5: # %entry
; ATOMICS-NEXT:    xor a0, a3, a4
; ATOMICS-NEXT:    seqz a0, a0
; ATOMICS-NEXT:    beq a3, a4, .LBB5_2
; ATOMICS-NEXT:  # %bb.1: # %cmpxchg.store_expected
; ATOMICS-NEXT:    sc ca3, 0(a1)
; ATOMICS-NEXT:  .LBB5_2: # %cmpxchg.continue
; ATOMICS-NEXT:    ret
;
; LIBCALLS-LABEL: test_cmpxchg_weak:
; LIBCALLS:       # %bb.0: # %entry
; LIBCALLS-NEXT:    addi sp, sp, -32
; LIBCALLS-NEXT:    .cfi_def_cfa_offset 32
; LIBCALLS-NEXT:    sd ra, 24(sp)
; LIBCALLS-NEXT:    sd s0, 16(sp)
; LIBCALLS-NEXT:    .cfi_offset ra, -8
; LIBCALLS-NEXT:    .cfi_offset s0, -16
; LIBCALLS-NEXT:    mv s0, a1
; LIBCALLS-NEXT:    lc ca1, 0(a1)
; LIBCALLS-NEXT:    sc ca1, 0(sp)
; LIBCALLS-NEXT:    mv a1, sp
; LIBCALLS-NEXT:    mv a3, zero
; LIBCALLS-NEXT:    mv a4, zero
; LIBCALLS-NEXT:    call __atomic_compare_exchange_cap
; LIBCALLS-NEXT:    bnez a0, .LBB5_2
; LIBCALLS-NEXT:  # %bb.1: # %cmpxchg.store_expected
; LIBCALLS-NEXT:    lc ca1, 0(sp)
; LIBCALLS-NEXT:    sc ca1, 0(s0)
; LIBCALLS-NEXT:  .LBB5_2: # %cmpxchg.continue
; LIBCALLS-NEXT:    ld s0, 16(sp)
; LIBCALLS-NEXT:    ld ra, 24(sp)
; LIBCALLS-NEXT:    addi sp, sp, 32
; LIBCALLS-NEXT:    ret
entry:
  %0 = load i8 addrspace(200)*, i8 addrspace(200)** %exp, align 16
  %1 = cmpxchg weak i8 addrspace(200)** %f, i8 addrspace(200)* %0, i8 addrspace(200)* %new monotonic monotonic
  %2 = extractvalue { i8 addrspace(200)*, i1 } %1, 1
  br i1 %2, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  %3 = extractvalue { i8 addrspace(200)*, i1 } %1, 0
  store i8 addrspace(200)* %3, i8 addrspace(200)** %exp, align 16
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  ret i1 %2
}

; Function Attrs: nofree norecurse nounwind
define zeroext i1 @test_cmpxchg_strong(i8 addrspace(200)** nocapture %f, i8 addrspace(200)** nocapture %exp, i8 addrspace(200)* %new) local_unnamed_addr #0 {
; ATOMICS-LABEL: test_cmpxchg_strong:
; ATOMICS:       # %bb.0: # %entry
; ATOMICS-NEXT:    lc ca4, 0(a1)
; ATOMICS-NEXT:  .LBB6_3: # %entry
; ATOMICS-NEXT:    # =>This Inner Loop Header: Depth=1
; ATOMICS-NEXT:    lr.c ca3, (a0)
; ATOMICS-NEXT:    bne a3, a4, .LBB6_5
; ATOMICS-NEXT:  # %bb.4: # %entry
; ATOMICS-NEXT:    # in Loop: Header=BB6_3 Depth=1
; ATOMICS-NEXT:    sc.c a5, ca2, (a0)
; ATOMICS-NEXT:    bnez a5, .LBB6_3
; ATOMICS-NEXT:  .LBB6_5: # %entry
; ATOMICS-NEXT:    xor a0, a3, a4
; ATOMICS-NEXT:    seqz a0, a0
; ATOMICS-NEXT:    beq a3, a4, .LBB6_2
; ATOMICS-NEXT:  # %bb.1: # %cmpxchg.store_expected
; ATOMICS-NEXT:    sc ca3, 0(a1)
; ATOMICS-NEXT:  .LBB6_2: # %cmpxchg.continue
; ATOMICS-NEXT:    ret
;
; LIBCALLS-LABEL: test_cmpxchg_strong:
; LIBCALLS:       # %bb.0: # %entry
; LIBCALLS-NEXT:    addi sp, sp, -32
; LIBCALLS-NEXT:    .cfi_def_cfa_offset 32
; LIBCALLS-NEXT:    sd ra, 24(sp)
; LIBCALLS-NEXT:    sd s0, 16(sp)
; LIBCALLS-NEXT:    .cfi_offset ra, -8
; LIBCALLS-NEXT:    .cfi_offset s0, -16
; LIBCALLS-NEXT:    mv s0, a1
; LIBCALLS-NEXT:    lc ca1, 0(a1)
; LIBCALLS-NEXT:    sc ca1, 0(sp)
; LIBCALLS-NEXT:    mv a1, sp
; LIBCALLS-NEXT:    mv a3, zero
; LIBCALLS-NEXT:    mv a4, zero
; LIBCALLS-NEXT:    call __atomic_compare_exchange_cap
; LIBCALLS-NEXT:    bnez a0, .LBB6_2
; LIBCALLS-NEXT:  # %bb.1: # %cmpxchg.store_expected
; LIBCALLS-NEXT:    lc ca1, 0(sp)
; LIBCALLS-NEXT:    sc ca1, 0(s0)
; LIBCALLS-NEXT:  .LBB6_2: # %cmpxchg.continue
; LIBCALLS-NEXT:    ld s0, 16(sp)
; LIBCALLS-NEXT:    ld ra, 24(sp)
; LIBCALLS-NEXT:    addi sp, sp, 32
; LIBCALLS-NEXT:    ret
entry:
  %0 = load i8 addrspace(200)*, i8 addrspace(200)** %exp, align 16
  %1 = cmpxchg i8 addrspace(200)** %f, i8 addrspace(200)* %0, i8 addrspace(200)* %new monotonic monotonic
  %2 = extractvalue { i8 addrspace(200)*, i1 } %1, 1
  br i1 %2, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  %3 = extractvalue { i8 addrspace(200)*, i1 } %1, 0
  store i8 addrspace(200)* %3, i8 addrspace(200)** %exp, align 16
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  ret i1 %2
}

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_add_uintcap(i8 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_add_uintcap:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_add_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_add_cap(i8* %0, i8 addrspace(200)* %value, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

declare i8 addrspace(200)* @__atomic_fetch_add_cap(i8*, i8 addrspace(200)*, i32) local_unnamed_addr

; Function Attrs: nounwind
define i64 addrspace(200)* @test_fetch_add_longptr(i64 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_add_longptr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    cgetaddr a1, ca1
; CHECK-NEXT:    slli a1, a1, 3
; CHECK-NEXT:    cincoffset ca1, cnull, a1
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_add_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* %value)
  %1 = shl i64 %0, 3
  %2 = getelementptr i8, i8 addrspace(200)* null, i64 %1
  %3 = bitcast i64 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_add_cap(i8* %3, i8 addrspace(200)* %2, i32 signext 5) #4
  %4 = bitcast i8 addrspace(200)* %call to i64 addrspace(200)*
  ret i64 addrspace(200)* %4
}

; Function Attrs: nounwind readnone willreturn
declare i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)*) #3

; Function Attrs: nounwind
define i64 addrspace(200)* @test_fetch_add_longptr_and_short(i64 addrspace(200)** %ptr, i16 signext %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_add_longptr_and_short:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    slli a1, a1, 3
; CHECK-NEXT:    cincoffset ca1, cnull, a1
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_add_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %conv = sext i16 %value to i64
  %0 = shl nsw i64 %conv, 3
  %1 = getelementptr i8, i8 addrspace(200)* null, i64 %0
  %2 = bitcast i64 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_add_cap(i8* %2, i8 addrspace(200)* %1, i32 signext 5) #4
  %3 = bitcast i8 addrspace(200)* %call to i64 addrspace(200)*
  ret i64 addrspace(200)* %3
}

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_add_charptr(i8 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_add_charptr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    cgetaddr a1, ca1
; CHECK-NEXT:    cincoffset ca1, cnull, a1
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_add_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* %value)
  %1 = getelementptr i8, i8 addrspace(200)* null, i64 %0
  %2 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_add_cap(i8* %2, i8 addrspace(200)* %1, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_add_charptr_and_short(i8 addrspace(200)** %ptr, i16 signext %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_add_charptr_and_short:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    cincoffset ca1, cnull, a1
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_add_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %conv = sext i16 %value to i64
  %0 = getelementptr i8, i8 addrspace(200)* null, i64 %conv
  %1 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_add_cap(i8* %1, i8 addrspace(200)* %0, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_sub_uintcap(i8 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_sub_uintcap:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_sub_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_sub_cap(i8* %0, i8 addrspace(200)* %value, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

declare i8 addrspace(200)* @__atomic_fetch_sub_cap(i8*, i8 addrspace(200)*, i32) local_unnamed_addr

; Function Attrs: nounwind
define i64 addrspace(200)* @test_fetch_sub_longptr(i64 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_sub_longptr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    cgetaddr a1, ca1
; CHECK-NEXT:    slli a1, a1, 3
; CHECK-NEXT:    cincoffset ca1, cnull, a1
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_sub_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* %value)
  %1 = shl i64 %0, 3
  %2 = getelementptr i8, i8 addrspace(200)* null, i64 %1
  %3 = bitcast i64 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_sub_cap(i8* %3, i8 addrspace(200)* %2, i32 signext 5) #4
  %4 = bitcast i8 addrspace(200)* %call to i64 addrspace(200)*
  ret i64 addrspace(200)* %4
}

; Function Attrs: nounwind
define i64 addrspace(200)* @test_fetch_sub_longptr_and_short(i64 addrspace(200)** %ptr, i16 signext %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_sub_longptr_and_short:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    slli a1, a1, 3
; CHECK-NEXT:    cincoffset ca1, cnull, a1
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_sub_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %conv = sext i16 %value to i64
  %0 = shl nsw i64 %conv, 3
  %1 = getelementptr i8, i8 addrspace(200)* null, i64 %0
  %2 = bitcast i64 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_sub_cap(i8* %2, i8 addrspace(200)* %1, i32 signext 5) #4
  %3 = bitcast i8 addrspace(200)* %call to i64 addrspace(200)*
  ret i64 addrspace(200)* %3
}

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_sub_charptr(i8 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_sub_charptr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    cgetaddr a1, ca1
; CHECK-NEXT:    cincoffset ca1, cnull, a1
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_sub_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* %value)
  %1 = getelementptr i8, i8 addrspace(200)* null, i64 %0
  %2 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_sub_cap(i8* %2, i8 addrspace(200)* %1, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_sub_charptr_and_short(i8 addrspace(200)** %ptr, i16 signext %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_sub_charptr_and_short:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    cincoffset ca1, cnull, a1
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_sub_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %conv = sext i16 %value to i64
  %0 = getelementptr i8, i8 addrspace(200)* null, i64 %conv
  %1 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_sub_cap(i8* %1, i8 addrspace(200)* %0, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_and_uintcap(i8 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_and_uintcap:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_and_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_and_cap(i8* %0, i8 addrspace(200)* %value, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

declare i8 addrspace(200)* @__atomic_fetch_and_cap(i8*, i8 addrspace(200)*, i32) local_unnamed_addr

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_or_uintcap(i8 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_or_uintcap:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_or_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_or_cap(i8* %0, i8 addrspace(200)* %value, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

declare i8 addrspace(200)* @__atomic_fetch_or_cap(i8*, i8 addrspace(200)*, i32) local_unnamed_addr

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_xor_uintcap(i8 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_xor_uintcap:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_xor_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_xor_cap(i8* %0, i8 addrspace(200)* %value, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

declare i8 addrspace(200)* @__atomic_fetch_xor_cap(i8*, i8 addrspace(200)*, i32) local_unnamed_addr

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_max_uintcap(i8 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_max_uintcap:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_umax_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_umax_cap(i8* %0, i8 addrspace(200)* %value, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

declare i8 addrspace(200)* @__atomic_fetch_umax_cap(i8*, i8 addrspace(200)*, i32) local_unnamed_addr

; Function Attrs: nounwind
define i8 addrspace(200)* @test_fetch_min_uintcap(i8 addrspace(200)** %ptr, i8 addrspace(200)* %value) local_unnamed_addr #2 {
; CHECK-LABEL: test_fetch_min_uintcap:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, -16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    sd ra, 8(sp)
; CHECK-NEXT:    .cfi_offset ra, -8
; CHECK-NEXT:    addi a2, zero, 5
; CHECK-NEXT:    call __atomic_fetch_umin_cap
; CHECK-NEXT:    ld ra, 8(sp)
; CHECK-NEXT:    addi sp, sp, 16
; CHECK-NEXT:    ret
entry:
  %0 = bitcast i8 addrspace(200)** %ptr to i8*
  %call = call i8 addrspace(200)* @__atomic_fetch_umin_cap(i8* %0, i8 addrspace(200)* %value, i32 signext 5) #4
  ret i8 addrspace(200)* %call
}

declare i8 addrspace(200)* @__atomic_fetch_umin_cap(i8*, i8 addrspace(200)*, i32) local_unnamed_addr
