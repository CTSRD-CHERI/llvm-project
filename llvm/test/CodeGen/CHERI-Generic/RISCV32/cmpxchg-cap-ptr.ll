; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes --force-update
; DO NOT EDIT -- This file was generated from test/CodeGen/CHERI-Generic/Inputs/cmpxchg-cap-ptr.ll
; Check that we can generate sensible code for atomic operations using capability pointers on capabilities
; in both hybrid and purecap mode.
; See https://github.com/CTSRD-CHERI/llvm-project/issues/470
; RUN: llc -mtriple=riscv32 --relocation-model=pic -target-abi il32pc64f -mattr=+xcheri,+cap-mode,+f -mattr=+a < %s | FileCheck %s --check-prefixes=PURECAP,PURECAP-ATOMICS --allow-unused-prefixes
; RUN: llc -mtriple=riscv32 --relocation-model=pic -target-abi il32pc64f -mattr=+xcheri,+cap-mode,+f -mattr=-a < %s | FileCheck %s --check-prefixes=PURECAP,PURECAP-LIBCALLS --allow-unused-prefixes
; RUN: llc -mtriple=riscv32 --relocation-model=pic -target-abi ilp32f -mattr=+xcheri,+f -mattr=+a < %s | FileCheck %s --check-prefixes=HYBRID,HYBRID-ATOMICS --allow-unused-prefixes
; RUN: llc -mtriple=riscv32 --relocation-model=pic -target-abi ilp32f -mattr=+xcheri,+f -mattr=+a < %s | FileCheck %s --check-prefixes=HYBRID,HYBRID-LIBCALLS --allow-unused-prefixes

define { i8, i1 } @test_cmpxchg_strong_i8(i8 addrspace(200)* %ptr, i8 %exp, i8 %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_strong_i8:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    slli a1, a1, 24
; PURECAP-ATOMICS-NEXT:    srai a1, a1, 24
; PURECAP-ATOMICS-NEXT:  .LBB0_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.b.aq a3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB0_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB0_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.b.rl a4, a2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB0_1
; PURECAP-ATOMICS-NEXT:  .LBB0_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    mv a0, a3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_strong_i8:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csb a1, 7(csp)
; PURECAP-LIBCALLS-NEXT:    cincoffset ca1, csp, 7
; PURECAP-LIBCALLS-NEXT:    csetbounds ca1, ca1, 1
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_1
; PURECAP-LIBCALLS-NEXT:    clb a1, 7(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    mv a0, a1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_strong_i8:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sb a1, 11(sp)
; HYBRID-NEXT:    addi a1, sp, 11
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_1_c@plt
; HYBRID-NEXT:    lb a1, 11(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    mv a0, a1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg i8 addrspace(200)* %ptr, i8 %exp, i8 %new acq_rel acquire
  ret { i8, i1 } %1
}

define { i16, i1 } @test_cmpxchg_strong_i16(i16 addrspace(200)* %ptr, i16 %exp, i16 %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_strong_i16:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    slli a1, a1, 16
; PURECAP-ATOMICS-NEXT:    srai a1, a1, 16
; PURECAP-ATOMICS-NEXT:  .LBB1_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.h.aq a3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB1_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB1_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.h.rl a4, a2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB1_1
; PURECAP-ATOMICS-NEXT:  .LBB1_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    mv a0, a3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_strong_i16:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cincoffset ca3, csp, 6
; PURECAP-LIBCALLS-NEXT:    csetbounds ca5, ca3, 2
; PURECAP-LIBCALLS-NEXT:    csh a1, 6(csp)
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    cmove ca1, ca5
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_2
; PURECAP-LIBCALLS-NEXT:    clh a1, 6(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    mv a0, a1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_strong_i16:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sh a1, 10(sp)
; HYBRID-NEXT:    addi a1, sp, 10
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_2_c@plt
; HYBRID-NEXT:    lh a1, 10(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    mv a0, a1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg i16 addrspace(200)* %ptr, i16 %exp, i16 %new acq_rel acquire
  ret { i16, i1 } %1
}

define { i32, i1 } @test_cmpxchg_strong_i32(i32 addrspace(200)* %ptr, i32 %exp, i32 %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_strong_i32:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB2_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.w.aq a3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB2_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB2_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.w.rl a4, a2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB2_1
; PURECAP-ATOMICS-NEXT:  .LBB2_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    mv a0, a3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_strong_i32:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cincoffset ca3, csp, 4
; PURECAP-LIBCALLS-NEXT:    csetbounds ca5, ca3, 4
; PURECAP-LIBCALLS-NEXT:    csw a1, 4(csp)
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    cmove ca1, ca5
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_4
; PURECAP-LIBCALLS-NEXT:    clw a1, 4(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    mv a0, a1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_strong_i32:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sw a1, 8(sp)
; HYBRID-NEXT:    addi a1, sp, 8
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_4_c@plt
; HYBRID-NEXT:    lw a1, 8(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    mv a0, a1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg i32 addrspace(200)* %ptr, i32 %exp, i32 %new acq_rel acquire
  ret { i32, i1 } %1
}

define { i64, i1 } @test_cmpxchg_strong_i64(i64 addrspace(200)* %ptr, i64 %exp, i64 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_strong_i64:
; PURECAP:       # %bb.0:
; PURECAP-NEXT:    cincoffset csp, csp, -32
; PURECAP-NEXT:    csc cra, 24(csp) # 8-byte Folded Spill
; PURECAP-NEXT:    csc cs0, 16(csp) # 8-byte Folded Spill
; PURECAP-NEXT:    mv a6, a5
; PURECAP-NEXT:    mv a7, a4
; PURECAP-NEXT:    cmove ct0, ca1
; PURECAP-NEXT:    cmove cs0, ca0
; PURECAP-NEXT:    cincoffset ca0, csp, 8
; PURECAP-NEXT:    csetbounds ca1, ca0, 8
; PURECAP-NEXT:    csw a3, 12(csp)
; PURECAP-NEXT:    csw a2, 8(csp)
; PURECAP-NEXT:    li a4, 4
; PURECAP-NEXT:    li a5, 2
; PURECAP-NEXT:    cmove ca0, ct0
; PURECAP-NEXT:    mv a2, a7
; PURECAP-NEXT:    mv a3, a6
; PURECAP-NEXT:    ccall __atomic_compare_exchange_8
; PURECAP-NEXT:    clw a1, 12(csp)
; PURECAP-NEXT:    clw a2, 8(csp)
; PURECAP-NEXT:    csw a1, 4(cs0)
; PURECAP-NEXT:    csw a2, 0(cs0)
; PURECAP-NEXT:    csb a0, 8(cs0)
; PURECAP-NEXT:    clc cra, 24(csp) # 8-byte Folded Reload
; PURECAP-NEXT:    clc cs0, 16(csp) # 8-byte Folded Reload
; PURECAP-NEXT:    cincoffset csp, csp, 32
; PURECAP-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_strong_i64:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sw s0, 8(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    mv a6, a5
; HYBRID-NEXT:    mv a7, a4
; HYBRID-NEXT:    cmove ct0, ca1
; HYBRID-NEXT:    mv s0, a0
; HYBRID-NEXT:    sw a3, 4(sp)
; HYBRID-NEXT:    sw a2, 0(sp)
; HYBRID-NEXT:    mv a1, sp
; HYBRID-NEXT:    li a4, 4
; HYBRID-NEXT:    li a5, 2
; HYBRID-NEXT:    cmove ca0, ct0
; HYBRID-NEXT:    mv a2, a7
; HYBRID-NEXT:    mv a3, a6
; HYBRID-NEXT:    call __atomic_compare_exchange_8_c@plt
; HYBRID-NEXT:    lw a1, 4(sp)
; HYBRID-NEXT:    lw a2, 0(sp)
; HYBRID-NEXT:    sw a1, 4(s0)
; HYBRID-NEXT:    sw a2, 0(s0)
; HYBRID-NEXT:    sb a0, 8(s0)
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    lw s0, 8(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg i64 addrspace(200)* %ptr, i64 %exp, i64 %new acq_rel acquire
  ret { i64, i1 } %1
}

define { i8 addrspace(200)*, i1 } @test_cmpxchg_strong_cap(i8 addrspace(200)* addrspace(200)* %ptr, i8 addrspace(200)* %exp, i8 addrspace(200)* %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_strong_cap:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB4_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.c.aq ca3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB4_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB4_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.c.aq a4, ca2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB4_1
; PURECAP-ATOMICS-NEXT:  .LBB4_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    cmove ca0, ca3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_strong_cap:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cincoffset ca3, csp, 0
; PURECAP-LIBCALLS-NEXT:    csetbounds ca5, ca3, 8
; PURECAP-LIBCALLS-NEXT:    csc ca1, 0(csp)
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    cmove ca1, ca5
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc ca1, 0(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    cmove ca0, ca1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_strong_cap:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sc ca1, 0(sp)
; HYBRID-NEXT:    mv a1, sp
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_cap_c@plt
; HYBRID-NEXT:    lc ca1, 0(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    cmove ca0, ca1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg i8 addrspace(200)* addrspace(200)* %ptr, i8 addrspace(200)* %exp, i8 addrspace(200)* %new acq_rel acquire
  ret { i8 addrspace(200)*, i1 } %1
}

define { i32 addrspace(200)*, i1 } @test_cmpxchg_strong_cap_i32(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %exp, i32 addrspace(200)* %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_strong_cap_i32:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB5_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.c.aq ca3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB5_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB5_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.c.aq a4, ca2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB5_1
; PURECAP-ATOMICS-NEXT:  .LBB5_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    cmove ca0, ca3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_strong_cap_i32:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cincoffset ca3, csp, 0
; PURECAP-LIBCALLS-NEXT:    csetbounds ca5, ca3, 8
; PURECAP-LIBCALLS-NEXT:    csc ca1, 0(csp)
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    cmove ca1, ca5
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc ca1, 0(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    cmove ca0, ca1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_strong_cap_i32:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sc ca1, 0(sp)
; HYBRID-NEXT:    mv a1, sp
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_cap_c@plt
; HYBRID-NEXT:    lc ca1, 0(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    cmove ca0, ca1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %exp, i32 addrspace(200)* %new acq_rel acquire
  ret { i32 addrspace(200)*, i1 } %1
}


define { i8, i1 } @test_cmpxchg_weak_i8(i8 addrspace(200)* %ptr, i8 %exp, i8 %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_weak_i8:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    slli a1, a1, 24
; PURECAP-ATOMICS-NEXT:    srai a1, a1, 24
; PURECAP-ATOMICS-NEXT:  .LBB6_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.b.aq a3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB6_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB6_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.b.rl a4, a2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB6_1
; PURECAP-ATOMICS-NEXT:  .LBB6_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    mv a0, a3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_weak_i8:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    csb a1, 7(csp)
; PURECAP-LIBCALLS-NEXT:    cincoffset ca1, csp, 7
; PURECAP-LIBCALLS-NEXT:    csetbounds ca1, ca1, 1
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_1
; PURECAP-LIBCALLS-NEXT:    clb a1, 7(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    mv a0, a1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_weak_i8:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sb a1, 11(sp)
; HYBRID-NEXT:    addi a1, sp, 11
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_1_c@plt
; HYBRID-NEXT:    lb a1, 11(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    mv a0, a1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i8 addrspace(200)* %ptr, i8 %exp, i8 %new acq_rel acquire
  ret { i8, i1 } %1
}

define { i16, i1 } @test_cmpxchg_weak_i16(i16 addrspace(200)* %ptr, i16 %exp, i16 %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_weak_i16:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:    slli a1, a1, 16
; PURECAP-ATOMICS-NEXT:    srai a1, a1, 16
; PURECAP-ATOMICS-NEXT:  .LBB7_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.h.aq a3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB7_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB7_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.h.rl a4, a2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB7_1
; PURECAP-ATOMICS-NEXT:  .LBB7_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    mv a0, a3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_weak_i16:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cincoffset ca3, csp, 6
; PURECAP-LIBCALLS-NEXT:    csetbounds ca5, ca3, 2
; PURECAP-LIBCALLS-NEXT:    csh a1, 6(csp)
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    cmove ca1, ca5
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_2
; PURECAP-LIBCALLS-NEXT:    clh a1, 6(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    mv a0, a1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_weak_i16:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sh a1, 10(sp)
; HYBRID-NEXT:    addi a1, sp, 10
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_2_c@plt
; HYBRID-NEXT:    lh a1, 10(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    mv a0, a1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i16 addrspace(200)* %ptr, i16 %exp, i16 %new acq_rel acquire
  ret { i16, i1 } %1
}

define { i32, i1 } @test_cmpxchg_weak_i32(i32 addrspace(200)* %ptr, i32 %exp, i32 %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_weak_i32:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB8_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.w.aq a3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB8_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB8_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.w.rl a4, a2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB8_1
; PURECAP-ATOMICS-NEXT:  .LBB8_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    mv a0, a3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_weak_i32:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cincoffset ca3, csp, 4
; PURECAP-LIBCALLS-NEXT:    csetbounds ca5, ca3, 4
; PURECAP-LIBCALLS-NEXT:    csw a1, 4(csp)
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    cmove ca1, ca5
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_4
; PURECAP-LIBCALLS-NEXT:    clw a1, 4(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    mv a0, a1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_weak_i32:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sw a1, 8(sp)
; HYBRID-NEXT:    addi a1, sp, 8
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_4_c@plt
; HYBRID-NEXT:    lw a1, 8(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    mv a0, a1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i32 addrspace(200)* %ptr, i32 %exp, i32 %new acq_rel acquire
  ret { i32, i1 } %1
}

define { i64, i1 } @test_cmpxchg_weak_i64(i64 addrspace(200)* %ptr, i64 %exp, i64 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_weak_i64:
; PURECAP:       # %bb.0:
; PURECAP-NEXT:    cincoffset csp, csp, -32
; PURECAP-NEXT:    csc cra, 24(csp) # 8-byte Folded Spill
; PURECAP-NEXT:    csc cs0, 16(csp) # 8-byte Folded Spill
; PURECAP-NEXT:    mv a6, a5
; PURECAP-NEXT:    mv a7, a4
; PURECAP-NEXT:    cmove ct0, ca1
; PURECAP-NEXT:    cmove cs0, ca0
; PURECAP-NEXT:    cincoffset ca0, csp, 8
; PURECAP-NEXT:    csetbounds ca1, ca0, 8
; PURECAP-NEXT:    csw a3, 12(csp)
; PURECAP-NEXT:    csw a2, 8(csp)
; PURECAP-NEXT:    li a4, 4
; PURECAP-NEXT:    li a5, 2
; PURECAP-NEXT:    cmove ca0, ct0
; PURECAP-NEXT:    mv a2, a7
; PURECAP-NEXT:    mv a3, a6
; PURECAP-NEXT:    ccall __atomic_compare_exchange_8
; PURECAP-NEXT:    clw a1, 12(csp)
; PURECAP-NEXT:    clw a2, 8(csp)
; PURECAP-NEXT:    csw a1, 4(cs0)
; PURECAP-NEXT:    csw a2, 0(cs0)
; PURECAP-NEXT:    csb a0, 8(cs0)
; PURECAP-NEXT:    clc cra, 24(csp) # 8-byte Folded Reload
; PURECAP-NEXT:    clc cs0, 16(csp) # 8-byte Folded Reload
; PURECAP-NEXT:    cincoffset csp, csp, 32
; PURECAP-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_weak_i64:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sw s0, 8(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    mv a6, a5
; HYBRID-NEXT:    mv a7, a4
; HYBRID-NEXT:    cmove ct0, ca1
; HYBRID-NEXT:    mv s0, a0
; HYBRID-NEXT:    sw a3, 4(sp)
; HYBRID-NEXT:    sw a2, 0(sp)
; HYBRID-NEXT:    mv a1, sp
; HYBRID-NEXT:    li a4, 4
; HYBRID-NEXT:    li a5, 2
; HYBRID-NEXT:    cmove ca0, ct0
; HYBRID-NEXT:    mv a2, a7
; HYBRID-NEXT:    mv a3, a6
; HYBRID-NEXT:    call __atomic_compare_exchange_8_c@plt
; HYBRID-NEXT:    lw a1, 4(sp)
; HYBRID-NEXT:    lw a2, 0(sp)
; HYBRID-NEXT:    sw a1, 4(s0)
; HYBRID-NEXT:    sw a2, 0(s0)
; HYBRID-NEXT:    sb a0, 8(s0)
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    lw s0, 8(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i64 addrspace(200)* %ptr, i64 %exp, i64 %new acq_rel acquire
  ret { i64, i1 } %1
}

define { i8 addrspace(200)*, i1 } @test_cmpxchg_weak_cap(i8 addrspace(200)* addrspace(200)* %ptr, i8 addrspace(200)* %exp, i8 addrspace(200)* %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_weak_cap:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB10_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.c.aq ca3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB10_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB10_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.c.aq a4, ca2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB10_1
; PURECAP-ATOMICS-NEXT:  .LBB10_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    cmove ca0, ca3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_weak_cap:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cincoffset ca3, csp, 0
; PURECAP-LIBCALLS-NEXT:    csetbounds ca5, ca3, 8
; PURECAP-LIBCALLS-NEXT:    csc ca1, 0(csp)
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    cmove ca1, ca5
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc ca1, 0(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    cmove ca0, ca1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_weak_cap:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sc ca1, 0(sp)
; HYBRID-NEXT:    mv a1, sp
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_cap_c@plt
; HYBRID-NEXT:    lc ca1, 0(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    cmove ca0, ca1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i8 addrspace(200)* addrspace(200)* %ptr, i8 addrspace(200)* %exp, i8 addrspace(200)* %new acq_rel acquire
  ret { i8 addrspace(200)*, i1 } %1
}

define { i32 addrspace(200)*, i1 } @test_cmpxchg_weak_cap_i32(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %exp, i32 addrspace(200)* %new) nounwind {
; PURECAP-ATOMICS-LABEL: test_cmpxchg_weak_cap_i32:
; PURECAP-ATOMICS:       # %bb.0:
; PURECAP-ATOMICS-NEXT:  .LBB11_1: # =>This Inner Loop Header: Depth=1
; PURECAP-ATOMICS-NEXT:    clr.c.aq ca3, (ca0)
; PURECAP-ATOMICS-NEXT:    bne a3, a1, .LBB11_3
; PURECAP-ATOMICS-NEXT:  # %bb.2: # in Loop: Header=BB11_1 Depth=1
; PURECAP-ATOMICS-NEXT:    csc.c.aq a4, ca2, (ca0)
; PURECAP-ATOMICS-NEXT:    bnez a4, .LBB11_1
; PURECAP-ATOMICS-NEXT:  .LBB11_3:
; PURECAP-ATOMICS-NEXT:    xor a0, a3, a1
; PURECAP-ATOMICS-NEXT:    seqz a1, a0
; PURECAP-ATOMICS-NEXT:    cmove ca0, ca3
; PURECAP-ATOMICS-NEXT:    cret
;
; PURECAP-LIBCALLS-LABEL: test_cmpxchg_weak_cap_i32:
; PURECAP-LIBCALLS:       # %bb.0:
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, -16
; PURECAP-LIBCALLS-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; PURECAP-LIBCALLS-NEXT:    cincoffset ca3, csp, 0
; PURECAP-LIBCALLS-NEXT:    csetbounds ca5, ca3, 8
; PURECAP-LIBCALLS-NEXT:    csc ca1, 0(csp)
; PURECAP-LIBCALLS-NEXT:    li a3, 4
; PURECAP-LIBCALLS-NEXT:    li a4, 2
; PURECAP-LIBCALLS-NEXT:    cmove ca1, ca5
; PURECAP-LIBCALLS-NEXT:    ccall __atomic_compare_exchange_cap
; PURECAP-LIBCALLS-NEXT:    clc ca1, 0(csp)
; PURECAP-LIBCALLS-NEXT:    mv a2, a0
; PURECAP-LIBCALLS-NEXT:    cmove ca0, ca1
; PURECAP-LIBCALLS-NEXT:    mv a1, a2
; PURECAP-LIBCALLS-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; PURECAP-LIBCALLS-NEXT:    cincoffset csp, csp, 16
; PURECAP-LIBCALLS-NEXT:    cret
;
; HYBRID-LABEL: test_cmpxchg_weak_cap_i32:
; HYBRID:       # %bb.0:
; HYBRID-NEXT:    addi sp, sp, -16
; HYBRID-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; HYBRID-NEXT:    sc ca1, 0(sp)
; HYBRID-NEXT:    mv a1, sp
; HYBRID-NEXT:    li a3, 4
; HYBRID-NEXT:    li a4, 2
; HYBRID-NEXT:    call __atomic_compare_exchange_cap_c@plt
; HYBRID-NEXT:    lc ca1, 0(sp)
; HYBRID-NEXT:    mv a2, a0
; HYBRID-NEXT:    cmove ca0, ca1
; HYBRID-NEXT:    mv a1, a2
; HYBRID-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; HYBRID-NEXT:    addi sp, sp, 16
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %exp, i32 addrspace(200)* %new acq_rel acquire
  ret { i32 addrspace(200)*, i1 } %1
}
