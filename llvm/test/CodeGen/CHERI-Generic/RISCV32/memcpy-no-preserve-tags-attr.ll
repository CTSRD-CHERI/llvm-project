; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes --force-update
; DO NOT EDIT -- This file was generated from test/CodeGen/CHERI-Generic/Inputs/memcpy-no-preserve-tags-attr.ll
; Check that the no_preserve_tags annotation on memcpy/memmove intrinsics allows
; use to inline struct copies >= capability size.
; RUN: llc -mtriple=riscv32 --relocation-model=pic -target-abi il32pc64f -mattr=+xcheri,+cap-mode,+f -o - < %s | FileCheck %s

%struct.pair = type { i32, i32 }

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p200i8.p200i8.i64(i8 addrspace(200)* nocapture writeonly, i8 addrspace(200)* nocapture readonly, i64, i1)
declare void @llvm.memmove.p200i8.p200i8.i64(i8 addrspace(200)* nocapture writeonly, i8 addrspace(200)* nocapture readonly, i64, i1)

; Without a no_preserve_tags attribute we always call memcpy. In this case we
; don't know whether the type might actually contain capabilities (e.g. unions).
define void @memcpy_no_attr(%struct.pair addrspace(200)* %a, %struct.pair addrspace(200)* %b) addrspace(200) nounwind {
; CHECK-LABEL: memcpy_no_attr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    cincoffset csp, csp, -16
; CHECK-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; CHECK-NEXT:    addi a2, zero, 16
; CHECK-NEXT:    mv a3, zero
; CHECK-NEXT:    ccall memcpy
; CHECK-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; CHECK-NEXT:    cincoffset csp, csp, 16
; CHECK-NEXT:    cret
entry:
  %a_i8 = bitcast %struct.pair addrspace(200)* %a to i8 addrspace(200)*
  %b_i8 = bitcast %struct.pair addrspace(200)* %b to i8 addrspace(200)*
  call void @llvm.memcpy.p200i8.p200i8.i64(i8 addrspace(200)* align 4 %a_i8, i8 addrspace(200)* align 4 %b_i8, i64 16, i1 false)
  ret void
}

define void @memmove_no_attr(%struct.pair addrspace(200)* %a, %struct.pair addrspace(200)* %b) addrspace(200) nounwind {
; CHECK-LABEL: memmove_no_attr:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    cincoffset csp, csp, -16
; CHECK-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; CHECK-NEXT:    addi a2, zero, 16
; CHECK-NEXT:    mv a3, zero
; CHECK-NEXT:    ccall memmove
; CHECK-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; CHECK-NEXT:    cincoffset csp, csp, 16
; CHECK-NEXT:    cret
entry:
  %a_i8 = bitcast %struct.pair addrspace(200)* %a to i8 addrspace(200)*
  %b_i8 = bitcast %struct.pair addrspace(200)* %b to i8 addrspace(200)*
  call void @llvm.memmove.p200i8.p200i8.i64(i8 addrspace(200)* align 4 %a_i8, i8 addrspace(200)* align 4 %b_i8, i64 16, i1 false)
  ret void
}

; We have to emit a call if the intrinsic has must_preserve_cheri_tags:
define void @memcpy_must_preserve(%struct.pair addrspace(200)* %a, %struct.pair addrspace(200)* %b) addrspace(200) nounwind {
; CHECK-LABEL: memcpy_must_preserve:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    cincoffset csp, csp, -16
; CHECK-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; CHECK-NEXT:    addi a2, zero, 16
; CHECK-NEXT:    mv a3, zero
; CHECK-NEXT:    ccall memcpy
; CHECK-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; CHECK-NEXT:    cincoffset csp, csp, 16
; CHECK-NEXT:    cret
entry:
  %a_i8 = bitcast %struct.pair addrspace(200)* %a to i8 addrspace(200)*
  %b_i8 = bitcast %struct.pair addrspace(200)* %b to i8 addrspace(200)*
  call void @llvm.memcpy.p200i8.p200i8.i64(i8 addrspace(200)* align 4 %a_i8, i8 addrspace(200)* align 4 %b_i8, i64 16, i1 false) must_preserve_cheri_tags
  ret void
}

define void @memmove_must_preserve(%struct.pair addrspace(200)* %a, %struct.pair addrspace(200)* %b) addrspace(200) nounwind {
; CHECK-LABEL: memmove_must_preserve:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    cincoffset csp, csp, -16
; CHECK-NEXT:    csc cra, 8(csp) # 8-byte Folded Spill
; CHECK-NEXT:    addi a2, zero, 16
; CHECK-NEXT:    mv a3, zero
; CHECK-NEXT:    ccall memmove
; CHECK-NEXT:    clc cra, 8(csp) # 8-byte Folded Reload
; CHECK-NEXT:    cincoffset csp, csp, 16
; CHECK-NEXT:    cret
entry:
  %a_i8 = bitcast %struct.pair addrspace(200)* %a to i8 addrspace(200)*
  %b_i8 = bitcast %struct.pair addrspace(200)* %b to i8 addrspace(200)*
  call void @llvm.memmove.p200i8.p200i8.i64(i8 addrspace(200)* align 4 %a_i8, i8 addrspace(200)* align 4 %b_i8, i64 16, i1 false) must_preserve_cheri_tags
  ret void
}

; We should be able to inline the call memcpy/memmove if the intrinsic has no_preserve_cheri_tags:
define void @memcpy_no_preserve(%struct.pair addrspace(200)* %a, %struct.pair addrspace(200)* %b) addrspace(200) nounwind {
; CHECK-LABEL: memcpy_no_preserve:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    clw a2, 12(ca1)
; CHECK-NEXT:    csw a2, 12(ca0)
; CHECK-NEXT:    clw a2, 8(ca1)
; CHECK-NEXT:    csw a2, 8(ca0)
; CHECK-NEXT:    clw a2, 4(ca1)
; CHECK-NEXT:    csw a2, 4(ca0)
; CHECK-NEXT:    clw a1, 0(ca1)
; CHECK-NEXT:    csw a1, 0(ca0)
; CHECK-NEXT:    cret
entry:
  %a_i8 = bitcast %struct.pair addrspace(200)* %a to i8 addrspace(200)*
  %b_i8 = bitcast %struct.pair addrspace(200)* %b to i8 addrspace(200)*
  call void @llvm.memcpy.p200i8.p200i8.i64(i8 addrspace(200)* align 4 %a_i8, i8 addrspace(200)* align 4 %b_i8, i64 16, i1 false) no_preserve_cheri_tags
  ret void
}

define void @memmove_no_preserve(%struct.pair addrspace(200)* %a, %struct.pair addrspace(200)* %b) addrspace(200) nounwind {
; CHECK-LABEL: memmove_no_preserve:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    clw a2, 12(ca1)
; CHECK-NEXT:    clw a3, 8(ca1)
; CHECK-NEXT:    clw a4, 4(ca1)
; CHECK-NEXT:    clw a1, 0(ca1)
; CHECK-NEXT:    csw a2, 12(ca0)
; CHECK-NEXT:    csw a3, 8(ca0)
; CHECK-NEXT:    csw a4, 4(ca0)
; CHECK-NEXT:    csw a1, 0(ca0)
; CHECK-NEXT:    cret
entry:
  %a_i8 = bitcast %struct.pair addrspace(200)* %a to i8 addrspace(200)*
  %b_i8 = bitcast %struct.pair addrspace(200)* %b to i8 addrspace(200)*
  call void @llvm.memmove.p200i8.p200i8.i64(i8 addrspace(200)* align 4 %a_i8, i8 addrspace(200)* align 4 %b_i8, i64 16, i1 false) no_preserve_cheri_tags
  ret void
}
