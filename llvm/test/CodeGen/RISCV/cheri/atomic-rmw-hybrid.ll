; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: %riscv32_cheri_llc -verify-machineinstrs < %s \
; RUN:   | FileCheck -check-prefix=RV32IXCHERI %s
; RUN: %riscv32_cheri_llc -mattr=+a -verify-machineinstrs < %s \
; RUN:   | FileCheck -check-prefix=RV32IAXCHERI %s
; RUN: %riscv64_cheri_llc -verify-machineinstrs < %s \
; RUN:   | FileCheck -check-prefix=RV64IXCHERI %s
; RUN: %riscv64_cheri_llc -mattr=+a -verify-machineinstrs < %s \
; RUN:   | FileCheck -check-prefix=RV64IAXCHERI %s

define i8 addrspace(200)* @atomicrmw_xchg_cap_monotonic(i8 addrspace(200)** %a, i8 addrspace(200)* %b) nounwind {
; RV32IXCHERI-LABEL: atomicrmw_xchg_cap_monotonic:
; RV32IXCHERI:       # %bb.0:
; RV32IXCHERI-NEXT:    addi sp, sp, -16
; RV32IXCHERI-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; RV32IXCHERI-NEXT:    mv a2, zero
; RV32IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV32IXCHERI-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; RV32IXCHERI-NEXT:    addi sp, sp, 16
; RV32IXCHERI-NEXT:    ret
;
; RV32IAXCHERI-LABEL: atomicrmw_xchg_cap_monotonic:
; RV32IAXCHERI:       # %bb.0:
; RV32IAXCHERI-NEXT:    amoswap.c ca0, ca1, (a0)
; RV32IAXCHERI-NEXT:    ret
;
; RV64IXCHERI-LABEL: atomicrmw_xchg_cap_monotonic:
; RV64IXCHERI:       # %bb.0:
; RV64IXCHERI-NEXT:    addi sp, sp, -16
; RV64IXCHERI-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; RV64IXCHERI-NEXT:    mv a2, zero
; RV64IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV64IXCHERI-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; RV64IXCHERI-NEXT:    addi sp, sp, 16
; RV64IXCHERI-NEXT:    ret
;
; RV64IAXCHERI-LABEL: atomicrmw_xchg_cap_monotonic:
; RV64IAXCHERI:       # %bb.0:
; RV64IAXCHERI-NEXT:    amoswap.c ca0, ca1, (a0)
; RV64IAXCHERI-NEXT:    ret
  %1 = atomicrmw xchg i8 addrspace(200)** %a, i8 addrspace(200)* %b monotonic
  ret i8 addrspace(200)* %1
}

define i8 addrspace(200)* @atomicrmw_xchg_cap_acquire(i8 addrspace(200)** %a, i8 addrspace(200)* %b) nounwind {
; RV32IXCHERI-LABEL: atomicrmw_xchg_cap_acquire:
; RV32IXCHERI:       # %bb.0:
; RV32IXCHERI-NEXT:    addi sp, sp, -16
; RV32IXCHERI-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; RV32IXCHERI-NEXT:    addi a2, zero, 2
; RV32IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV32IXCHERI-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; RV32IXCHERI-NEXT:    addi sp, sp, 16
; RV32IXCHERI-NEXT:    ret
;
; RV32IAXCHERI-LABEL: atomicrmw_xchg_cap_acquire:
; RV32IAXCHERI:       # %bb.0:
; RV32IAXCHERI-NEXT:    amoswap.c.aq ca0, ca1, (a0)
; RV32IAXCHERI-NEXT:    ret
;
; RV64IXCHERI-LABEL: atomicrmw_xchg_cap_acquire:
; RV64IXCHERI:       # %bb.0:
; RV64IXCHERI-NEXT:    addi sp, sp, -16
; RV64IXCHERI-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; RV64IXCHERI-NEXT:    addi a2, zero, 2
; RV64IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV64IXCHERI-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; RV64IXCHERI-NEXT:    addi sp, sp, 16
; RV64IXCHERI-NEXT:    ret
;
; RV64IAXCHERI-LABEL: atomicrmw_xchg_cap_acquire:
; RV64IAXCHERI:       # %bb.0:
; RV64IAXCHERI-NEXT:    amoswap.c.aq ca0, ca1, (a0)
; RV64IAXCHERI-NEXT:    ret
  %1 = atomicrmw xchg i8 addrspace(200)** %a, i8 addrspace(200)* %b acquire
  ret i8 addrspace(200)* %1
}

define i8 addrspace(200)* @atomicrmw_xchg_cap_release(i8 addrspace(200)** %a, i8 addrspace(200)* %b) nounwind {
; RV32IXCHERI-LABEL: atomicrmw_xchg_cap_release:
; RV32IXCHERI:       # %bb.0:
; RV32IXCHERI-NEXT:    addi sp, sp, -16
; RV32IXCHERI-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; RV32IXCHERI-NEXT:    addi a2, zero, 3
; RV32IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV32IXCHERI-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; RV32IXCHERI-NEXT:    addi sp, sp, 16
; RV32IXCHERI-NEXT:    ret
;
; RV32IAXCHERI-LABEL: atomicrmw_xchg_cap_release:
; RV32IAXCHERI:       # %bb.0:
; RV32IAXCHERI-NEXT:    amoswap.c.rl ca0, ca1, (a0)
; RV32IAXCHERI-NEXT:    ret
;
; RV64IXCHERI-LABEL: atomicrmw_xchg_cap_release:
; RV64IXCHERI:       # %bb.0:
; RV64IXCHERI-NEXT:    addi sp, sp, -16
; RV64IXCHERI-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; RV64IXCHERI-NEXT:    addi a2, zero, 3
; RV64IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV64IXCHERI-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; RV64IXCHERI-NEXT:    addi sp, sp, 16
; RV64IXCHERI-NEXT:    ret
;
; RV64IAXCHERI-LABEL: atomicrmw_xchg_cap_release:
; RV64IAXCHERI:       # %bb.0:
; RV64IAXCHERI-NEXT:    amoswap.c.rl ca0, ca1, (a0)
; RV64IAXCHERI-NEXT:    ret
  %1 = atomicrmw xchg i8 addrspace(200)** %a, i8 addrspace(200)* %b release
  ret i8 addrspace(200)* %1
}

define i8 addrspace(200)* @atomicrmw_xchg_cap_acq_rel(i8 addrspace(200)** %a, i8 addrspace(200)* %b) nounwind {
; RV32IXCHERI-LABEL: atomicrmw_xchg_cap_acq_rel:
; RV32IXCHERI:       # %bb.0:
; RV32IXCHERI-NEXT:    addi sp, sp, -16
; RV32IXCHERI-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; RV32IXCHERI-NEXT:    addi a2, zero, 4
; RV32IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV32IXCHERI-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; RV32IXCHERI-NEXT:    addi sp, sp, 16
; RV32IXCHERI-NEXT:    ret
;
; RV32IAXCHERI-LABEL: atomicrmw_xchg_cap_acq_rel:
; RV32IAXCHERI:       # %bb.0:
; RV32IAXCHERI-NEXT:    amoswap.c.aqrl ca0, ca1, (a0)
; RV32IAXCHERI-NEXT:    ret
;
; RV64IXCHERI-LABEL: atomicrmw_xchg_cap_acq_rel:
; RV64IXCHERI:       # %bb.0:
; RV64IXCHERI-NEXT:    addi sp, sp, -16
; RV64IXCHERI-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; RV64IXCHERI-NEXT:    addi a2, zero, 4
; RV64IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV64IXCHERI-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; RV64IXCHERI-NEXT:    addi sp, sp, 16
; RV64IXCHERI-NEXT:    ret
;
; RV64IAXCHERI-LABEL: atomicrmw_xchg_cap_acq_rel:
; RV64IAXCHERI:       # %bb.0:
; RV64IAXCHERI-NEXT:    amoswap.c.aqrl ca0, ca1, (a0)
; RV64IAXCHERI-NEXT:    ret
  %1 = atomicrmw xchg i8 addrspace(200)** %a, i8 addrspace(200)* %b acq_rel
  ret i8 addrspace(200)* %1
}

define i8 addrspace(200)* @atomicrmw_xchg_cap_seq_cst(i8 addrspace(200)** %a, i8 addrspace(200)* %b) nounwind {
; RV32IXCHERI-LABEL: atomicrmw_xchg_cap_seq_cst:
; RV32IXCHERI:       # %bb.0:
; RV32IXCHERI-NEXT:    addi sp, sp, -16
; RV32IXCHERI-NEXT:    sw ra, 12(sp) # 4-byte Folded Spill
; RV32IXCHERI-NEXT:    addi a2, zero, 5
; RV32IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV32IXCHERI-NEXT:    lw ra, 12(sp) # 4-byte Folded Reload
; RV32IXCHERI-NEXT:    addi sp, sp, 16
; RV32IXCHERI-NEXT:    ret
;
; RV32IAXCHERI-LABEL: atomicrmw_xchg_cap_seq_cst:
; RV32IAXCHERI:       # %bb.0:
; RV32IAXCHERI-NEXT:    amoswap.c.aqrl ca0, ca1, (a0)
; RV32IAXCHERI-NEXT:    ret
;
; RV64IXCHERI-LABEL: atomicrmw_xchg_cap_seq_cst:
; RV64IXCHERI:       # %bb.0:
; RV64IXCHERI-NEXT:    addi sp, sp, -16
; RV64IXCHERI-NEXT:    sd ra, 8(sp) # 8-byte Folded Spill
; RV64IXCHERI-NEXT:    addi a2, zero, 5
; RV64IXCHERI-NEXT:    call __atomic_exchange_cap@plt
; RV64IXCHERI-NEXT:    ld ra, 8(sp) # 8-byte Folded Reload
; RV64IXCHERI-NEXT:    addi sp, sp, 16
; RV64IXCHERI-NEXT:    ret
;
; RV64IAXCHERI-LABEL: atomicrmw_xchg_cap_seq_cst:
; RV64IAXCHERI:       # %bb.0:
; RV64IAXCHERI-NEXT:    amoswap.c.aqrl ca0, ca1, (a0)
; RV64IAXCHERI-NEXT:    ret
  %1 = atomicrmw xchg i8 addrspace(200)** %a, i8 addrspace(200)* %b seq_cst
  ret i8 addrspace(200)* %1
}
